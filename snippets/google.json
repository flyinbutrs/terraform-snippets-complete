{
    "google-app-engine-application": {
        "body": "resource \"google_app_engine_application\" \"$1\" {\n    # location_id - (Required) The [location](https://cloud.google.com/appengine/docs/locations)  to serve the app from.\n    location_id = \"\"\n\n    # auth_domain - (Optional) The domain to authenticate users with when using App Engine's User API.\n    auth_domain = \"\"\n\n    # serving_status - (Optional) The serving status of the app.\n    serving_status = \"\"\n\n    # feature_settings - (Optional) A block of optional settings to configure specific App Engine features: `split_health_checks` - (Optional) Set to false to use the legacy health check instead of the readiness and liveness checks.\n    feature_settings = \"\"\n\n    # feature_settings - (Optional) A block of optional settings to configure specific App Engine features: `split_health_checks` - (Optional) Set to false to use the legacy health check instead of the readiness and liveness checks.\n    feature_settings = \"\"\n\n    # Exported Attributes\n    # \"name\" - Unique name of the app, usually \"apps/{PROJECT_ID}\"\n    # \"url_dispatch_rule\" - A list of dispatch rule blocks. Each block has a \"domain\", \"path\", and \"service\" field.\n    # \"code_bucket\" - The GCS bucket code is being stored in for this app.\n    # \"default_hostname\" - The default hostname for this app.\n    # \"default_bucket\" - The GCS bucket content is being stored in for this app.\n    # \"gcr_domain\" - The GCR domain used for storing managed Docker images for this app.\n}",
        "description": "Allows creation and management of an App Engine application. ~> App Engine applications cannot be deleted once they're created; you have to delete the\n   entire project to delete the application. Terraform will report the application has been\n   successfully deleted; this is a limitation of Terraform, and will go away in the future.\n   Terraform is not able to delete App Engine applications.",
        "prefix": "google-app-engine-application"
    },
    "google-bigquery-dataset": {
        "body": "resource \"google_bigquery_dataset\" \"$1\" {\n    # table_id - (Required) The ID of the table.\n    table_id = \"\"\n\n    # project_id - (Required) The ID of the project containing this table.\n    project_id = \"\"\n\n    # dataset_id - (Required) The ID of the dataset containing this table.\n    dataset_id = \"\"\n\n    # dataset_id - (Required) A unique ID for the resource.   Changing this forces a new resource to be created.\n    dataset_id = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # friendly_name - (Optional) A descriptive name for the dataset.\n    friendly_name = \"\"\n\n    # description - (Optional) A user-friendly description of the dataset.\n    description = \"\"\n\n    # location - (Optional) The geographic location where the dataset should reside.   See [official docs](https://cloud.google.com/bigquery/docs/dataset-locations).   There are two types of locations, regional or multi-regional.   A regional location is a specific geographic place, such as Tokyo, and a   multi-regional location is a large geographic area, such as the United States,   that contains at least two geographic places   Possible regional values include: `asia-northeast1`   Possible multi-regional values:`EU` and `US`.   The default value is multi-regional location `US`.   Changing this forces a new resource to be created.\n    location = \"\"\n\n    # default_table_expiration_ms - (Optional) The default lifetime of all   tables in the dataset, in milliseconds. The minimum value is 3600000   milliseconds (one hour).   Once this property is set, all newly-created   tables in the dataset will have an expirationTime property set to the   creation time plus the value in this property, and changing the value   will only affect new tables, not existing ones. When the   expirationTime for a given table is reached, that table will be   deleted automatically. If a table's expirationTime is modified or   removed before the table expires, or if you provide an explicit   expirationTime when creating a table, that value takes precedence   over the default expiration time indicated by this property.\n    default_table_expiration_ms = \"\"\n\n    # labels - (Optional) A mapping of labels to assign to the resource.\n    labels = \"\"\n\n    # access - (Optional) An array of objects that define dataset access for   one or more entities. Structure is documented below.\n    access = \"\"\n\n    # role - (Optional) (Required unless `view` is set) Describes the rights granted to   the user specified by the other member of the access object. The following   string values are supported: `READER`, `WRITER`, `OWNER`.\n    role = \"\"\n\n    # domain - (Optional) A domain to grant access to.\n    domain = \"\"\n\n    # group_by_email - (Optional) An email address of a Google Group to grant   access to.\n    group_by_email = \"\"\n\n    # special_group - (Optional) A special group to grant access to. Possible values include: `projectOwners`: Owners of the enclosing project.\n    special_group = \"\"\n\n    # special_group - (Optional) A special group to grant access to. Possible values include: `projectOwners`: Owners of the enclosing project.\n    special_group = \"\"\n\n    # special_group - (Optional) A special group to grant access to. Possible values include: `projectOwners`: Owners of the enclosing project.\n    special_group = \"\"\n\n    # special_group - (Optional) A special group to grant access to. Possible values include: `projectOwners`: Owners of the enclosing project.\n    special_group = \"\"\n\n    # special_group - (Optional) A special group to grant access to. Possible values include: `projectOwners`: Owners of the enclosing project.\n    special_group = \"\"\n\n    # user_by_email - (Optional) An email address of a user to grant access to.\n    user_by_email = \"\"\n\n    # view - (Optional) A view from a different dataset to grant access to.   Queries executed against that view will have read access to tables in this   dataset. The role field is not required when this field is set. If that   view is updated by any user, access to the view needs to be granted again   via an update operation. Structure is documented below.\n    view = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The URI of the created resource.\n    # \"etag\" - A hash of the resource.\n    # \"creation_time\" - The time when this dataset was created, in milliseconds since the epoch.\n    # \"last_modified_time\" -  The date when this dataset or any of its tables was last modified, in milliseconds since the epoch.\n}",
        "description": "Creates a dataset resource for Google BigQuery. For more information see\n[the official documentation](https://cloud.google.com/bigquery/docs/) and\n[API](https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets).",
        "prefix": "google-bigquery-dataset"
    },
    "google-bigquery-table": {
        "body": "resource \"google_bigquery_table\" \"$1\" {\n    # query - (Required) A query that BigQuery executes when the view is referenced.\n    query = \"\"\n\n    # type - (Required) The only type supported is DAY, which will generate   one partition per day based on data loading time.\n    type = \"\"\n\n    # table_id - (Required) A unique ID for the resource.   Changing this forces a new resource to be created.\n    table_id = \"\"\n\n    # dataset_id - (Required) The dataset ID to create the table in.   Changing this forces a new resource to be created.\n    dataset_id = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # description - (Optional) The field description.\n    description = \"\"\n\n    # expiration_time - (Optional) The time when this table expires, in   milliseconds since the epoch. If not present, the table will persist   indefinitely. Expired tables will be deleted and their storage   reclaimed.\n    expiration_time = \"\"\n\n    # friendly_name - (Optional) A descriptive name for the table.\n    friendly_name = \"\"\n\n    # labels - (Optional) A mapping of labels to assign to the resource.\n    labels = \"\"\n\n    # schema - (Optional) A JSON schema for the table.\n    schema = \"\"\n\n    # time_partitioning - (Optional) If specified, configures time-based   partitioning for this table. Structure is documented below.\n    time_partitioning = \"\"\n\n    # view - (Optional) If specified, configures this table as a view.   Structure is documented below.\n    view = \"\"\n\n    # expiration_ms - (Optional) Number of milliseconds for which to keep the   storage for a partition.\n    expiration_ms = \"\"\n\n    # field - (Optional) The field used to determine how to create a time-based   partition. If time-based partitioning is enabled without this value, the   table is partitioned based on the load time.\n    field = \"\"\n\n    # use_legacy_sql - (Optional) Specifies whether to use BigQuery's legacy SQL for this view.   The default value is true. If set to false, the view will use BigQuery's standard SQL.\n    use_legacy_sql = \"\"\n\n    # Exported Attributes\n    # \"creation_time\" - The time when this table was created, in milliseconds since the epoch.\n    # \"etag\" - A hash of the resource.\n    # \"last_modified_time\" - The time when this table was last modified, in milliseconds since the epoch.\n    # \"location\" - The geographic location where the table resides. This value is inherited from the dataset.\n    # \"num_bytes\" - The size of this table in bytes, excluding any data in the streaming buffer.\n    # \"num_long_term_bytes\" - The number of bytes in the table that are considered \"long-term storage\".\n    # \"num_rows\" - The number of rows of data in this table, excluding any data in the streaming buffer.\n    # \"self_link\" - The URI of the created resource.\n    # \"type\" - Describes the table type.\n}",
        "description": "Creates a table resource in a dataset for Google BigQuery. For more information see\n[the official documentation](https://cloud.google.com/bigquery/docs/) and\n[API](https://cloud.google.com/bigquery/docs/reference/rest/v2/tables).",
        "prefix": "google-bigquery-table"
    },
    "google-bigtable-instance": {
        "body": "resource \"google_bigtable_instance\" \"$1\" {\n    # cluster_id - (Required) The ID of the Cloud Bigtable cluster.\n    cluster_id = \"\"\n\n    # name - (Required) The name of the Cloud Bigtable instance.\n    name = \"\"\n\n    # instance_type - (Optional) The instance type to create. One of `\"DEVELOPMENT\"` or `\"PRODUCTION\"`. Defaults to `\"PRODUCTION\"`.\n    instance_type = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # display_name - (Optional) The human-readable display name of the Bigtable instance. Defaults to the instance `name`.\n    display_name = \"\"\n\n    # cluster - (Optional) A block of cluster configuration options. Either `cluster` or `cluster_id` must be used. Only one cluster may be specified. See structure below.\n    cluster = \"\"\n\n    # cluster_id - (Optional) (Optional, Deprecated) The ID of the Cloud Bigtable cluster. Use `cluster.cluster_id` instead.\n    cluster_id = \"\"\n\n    # zone - (Optional) (Optional, Deprecated) The zone to create the Cloud Bigtable cluster in. Zones that support Bigtable instances are noted on the [Cloud Bigtable locations page](https://cloud.google.com/bigtable/docs/locations). Use `cluster.zone` instead.\n    zone = \"\"\n\n    # num_nodes - (Optional) (Optional, Deprecated) The number of nodes in your Cloud Bigtable cluster. Minimum of `3` for a `PRODUCTION` instance. Cannot be set for a `DEVELOPMENT` instance. Use `cluster.num_nodes` instead.\n    num_nodes = \"\"\n\n    # storage_type - (Optional) (Optional, Deprecated) The storage type to use. One of `\"SSD\"` or `\"HDD\"`. Defaults to `\"SSD\"`. Use `cluster.storage_type` instead.\n    storage_type = \"\"\n\n    # cluster - (Optional) `cluster` supports the following arguments:\n    cluster = \"\"\n\n    # zone - (Optional) The zone to create the Cloud Bigtable cluster in. Zones that support Bigtable instances are noted on the [Cloud Bigtable locations page](https://cloud.google.com/bigtable/docs/locations).\n    zone = \"\"\n\n    # num_nodes - (Optional) The number of nodes in your Cloud Bigtable cluster. Minimum of `3` for a `PRODUCTION` instance. Cannot be set for a `DEVELOPMENT` instance.\n    num_nodes = \"\"\n\n    # storage_type - (Optional) The storage type to use. One of `\"SSD\"` or `\"HDD\"`. Defaults to `\"SSD\"`.\n    storage_type = \"\"\n\n    # Exported Attributes\n}",
        "description": "Creates a Google Bigtable instance. For more information see\n[the official documentation](https://cloud.google.com/bigtable/) and\n[API](https://cloud.google.com/bigtable/docs/go/reference).",
        "prefix": "google-bigtable-instance"
    },
    "google-bigtable-table": {
        "body": "resource \"google_bigtable_table\" \"$1\" {\n    # instance_name - (Required) The name of the Bigtable instance.\n    instance_name = \"\"\n\n    # name - (Required) The name of the table.\n    name = \"\"\n\n    # split_keys - (Optional) A list of predefined keys to split the table on.\n    split_keys = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Creates a Google Bigtable table inside an instance. For more information see\n[the official documentation](https://cloud.google.com/bigtable/) and\n[API](https://cloud.google.com/bigtable/docs/go/reference).",
        "prefix": "google-bigtable-table"
    },
    "google-billing-account-iam-binding": {
        "body": "resource \"google_billing_account_iam_binding\" \"$1\" {\n    # members - (Required) A list of users that the role should apply to.\n    members = \"\"\n\n    # role - (Required) The role that should be applied.\n    role = \"\"\n\n    # billing_account_id - (Required) The billing account id.\n    billing_account_id = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the billing account's IAM policy.\n    # \"members\" - (Required) A list of users that the role should apply to.\n}",
        "description": "Allows creation and management of a single binding within IAM policy for\nan existing Google Cloud Platform Billing Account. ~> **Note:** This resource __must not__ be used in conjunction with\n   `google_billing_account_iam_member` for the __same role__ or they will fight over\n   what your policy should be.",
        "prefix": "google-billing-account-iam-binding"
    },
    "google-billing-account-iam-member": {
        "body": "resource \"google_billing_account_iam_member\" \"$1\" {\n    # member - (Required) The user that the role should apply to.    ## Attributes Reference\n    member = \"\"\n\n    # member - (Required) The user that the role should apply to.    ## Attributes Reference\n    member = \"\"\n\n    # role - (Required) The role that should be applied.\n    role = \"\"\n\n    # billing_account_id - (Required) The billing account id.\n    billing_account_id = \"\"\n\n    # etag - (Optional) (Computed) The etag of the billing account's IAM policy.\n    etag = \"\"\n\n    # Exported Attributes\n}",
        "description": "Allows creation and management of a single member for a single binding within\nthe IAM policy for an existing Google Cloud Platform Billing Account. ~> **Note:** This resource __must not__ be used in conjunction with\n   `google_billing_account_iam_binding` for the __same role__ or they will fight over\n   what your policy should be.",
        "prefix": "google-billing-account-iam-member"
    },
    "google-billing-account-iam-policy": {
        "body": "resource \"google_billing_account_iam_policy\" \"$1\" {\n    # policy_data - (Required) The `google_iam_policy` data source that represents   the IAM policy that will be applied to the billing account. This policy overrides any existing   policy applied to the billing account.\n    policy_data = \"\"\n\n    # billing_account_id - (Required) The billing account id.\n    billing_account_id = \"\"\n\n    # Exported Attributes\n}",
        "description": "Allows management of the entire IAM policy for an existing Google Cloud Platform Billing Account. ~> **Warning:** Billing accounts have a default user that can be **overwritten**\nby use of this resource. The safest alternative is to use multiple `google_billing_account_iam_binding`\n   resources. If you do use this resource, the best way to be sure that you are\n   not making dangerous changes is to start by importing your existing policy,\n   and examining the diff very closely. ~> **Note:** This resource __must not__ be used in conjunction with\n   `google_billing_account_iam_member` or `google_billing_account_iam_binding`\n   or they will fight over what your policy should be.",
        "prefix": "google-billing-account-iam-policy"
    },
    "google-cloudbuild-trigger": {
        "body": "resource \"google_cloudbuild_trigger\" \"$1\" {\n    # build - (Optional) A build resource in the Container Builder API. Structure is documented below. At a high level, a `build` describes where to find source code, how to build it (for example, the builder image to run on the source), and where to store the built artifacts. Fields can include the following variables, which will be expanded when the build is created: `$PROJECT_ID`: the project ID of the build.\n    build = \"\"\n\n    # build - (Optional) A build resource in the Container Builder API. Structure is documented below. At a high level, a `build` describes where to find source code, how to build it (for example, the builder image to run on the source), and where to store the built artifacts. Fields can include the following variables, which will be expanded when the build is created: `$PROJECT_ID`: the project ID of the build.\n    build = \"\"\n\n    # build - (Optional) A build resource in the Container Builder API. Structure is documented below. At a high level, a `build` describes where to find source code, how to build it (for example, the builder image to run on the source), and where to store the built artifacts. Fields can include the following variables, which will be expanded when the build is created: `$PROJECT_ID`: the project ID of the build.\n    build = \"\"\n\n    # build - (Optional) A build resource in the Container Builder API. Structure is documented below. At a high level, a `build` describes where to find source code, how to build it (for example, the builder image to run on the source), and where to store the built artifacts. Fields can include the following variables, which will be expanded when the build is created: `$PROJECT_ID`: the project ID of the build.\n    build = \"\"\n\n    # build - (Optional) A build resource in the Container Builder API. Structure is documented below. At a high level, a `build` describes where to find source code, how to build it (for example, the builder image to run on the source), and where to store the built artifacts. Fields can include the following variables, which will be expanded when the build is created: `$PROJECT_ID`: the project ID of the build.\n    build = \"\"\n\n    # build - (Optional) A build resource in the Container Builder API. Structure is documented below. At a high level, a `build` describes where to find source code, how to build it (for example, the builder image to run on the source), and where to store the built artifacts. Fields can include the following variables, which will be expanded when the build is created: `$PROJECT_ID`: the project ID of the build.\n    build = \"\"\n\n    # build - (Optional) A build resource in the Container Builder API. Structure is documented below. At a high level, a `build` describes where to find source code, how to build it (for example, the builder image to run on the source), and where to store the built artifacts. Fields can include the following variables, which will be expanded when the build is created: `$PROJECT_ID`: the project ID of the build.\n    build = \"\"\n\n    # build - (Optional) A build resource in the Container Builder API. Structure is documented below. At a high level, a `build` describes where to find source code, how to build it (for example, the builder image to run on the source), and where to store the built artifacts. Fields can include the following variables, which will be expanded when the build is created: `$PROJECT_ID`: the project ID of the build.\n    build = \"\"\n\n    # description - (Optional) A brief description of this resource.\n    description = \"\"\n\n    # filename - (Optional) Specify the path to a Cloud Build configuration file in the Git repo. This is mutually exclusive with `build`. This is typically `cloudbuild.yaml` however it can be specified by the user.\n    filename = \"\"\n\n    # project - (Optional) The ID of the project that the trigger will be created in. Defaults to the provider project configuration.\n    project = \"\"\n\n    # substitutions - (Optional) User-defined substitutions. User-defined substitutions must conform to the following rules: Substitutions must begin with an underscore (`_`) and use only uppercase-letters and numbers (respecting the regular expression `_[A-Z0-9_]+`). This prevents conflicts with built-in substitutions.\n    substitutions = \"\"\n\n    # substitutions - (Optional) User-defined substitutions. User-defined substitutions must conform to the following rules: Substitutions must begin with an underscore (`_`) and use only uppercase-letters and numbers (respecting the regular expression `_[A-Z0-9_]+`). This prevents conflicts with built-in substitutions.\n    substitutions = \"\"\n\n    # substitutions - (Optional) User-defined substitutions. User-defined substitutions must conform to the following rules: Substitutions must begin with an underscore (`_`) and use only uppercase-letters and numbers (respecting the regular expression `_[A-Z0-9_]+`). This prevents conflicts with built-in substitutions.\n    substitutions = \"\"\n\n    # substitutions - (Optional) User-defined substitutions. User-defined substitutions must conform to the following rules: Substitutions must begin with an underscore (`_`) and use only uppercase-letters and numbers (respecting the regular expression `_[A-Z0-9_]+`). This prevents conflicts with built-in substitutions.\n    substitutions = \"\"\n\n    # substitutions - (Optional) User-defined substitutions. User-defined substitutions must conform to the following rules: Substitutions must begin with an underscore (`_`) and use only uppercase-letters and numbers (respecting the regular expression `_[A-Z0-9_]+`). This prevents conflicts with built-in substitutions.\n    substitutions = \"\"\n\n    # substitutions - (Optional) User-defined substitutions. User-defined substitutions must conform to the following rules: Substitutions must begin with an underscore (`_`) and use only uppercase-letters and numbers (respecting the regular expression `_[A-Z0-9_]+`). This prevents conflicts with built-in substitutions.\n    substitutions = \"\"\n\n    # substitutions - (Optional) User-defined substitutions. User-defined substitutions must conform to the following rules: Substitutions must begin with an underscore (`_`) and use only uppercase-letters and numbers (respecting the regular expression `_[A-Z0-9_]+`). This prevents conflicts with built-in substitutions.\n    substitutions = \"\"\n\n    # substitutions - (Optional) User-defined substitutions. User-defined substitutions must conform to the following rules: Substitutions must begin with an underscore (`_`) and use only uppercase-letters and numbers (respecting the regular expression `_[A-Z0-9_]+`). This prevents conflicts with built-in substitutions.\n    substitutions = \"\"\n\n    # trigger_template - (Optional) Location of the source in a Google Cloud Source Repository. Structure is documented below.\n    trigger_template = \"\"\n\n    # images - (Optional) A list of images to be pushed upon the successful completion of all build steps.\n    images = \"\"\n\n    # step - (Optional) The operations to be performed on the workspace. Structure is documented below.\n    step = \"\"\n\n    # tags - (Optional) Tags for annotation of a build. **These are not docker tags**\n    tags = \"\"\n\n    # name - (Optional) The name of the container image that will run this particular build step. If the image is available in the host's Docker daemon's cache, it will be run directly. If not, the host will attempt to pull the image first, using the builder service account's credentials if necessary. The Docker daemon's cache will already have the latest versions of all of the officially supported build steps (https://github.com/GoogleCloudPlatform/cloud-builders). The Docker daemon will also have cached many of the layers for some popular images, like \"ubuntu\", \"debian\", but they will be refreshed at the time you attempt to use them. If you built an image in a previous build step, it will be stored in the host's Docker daemon's cache and is available to use as the name for a later build step.\n    name = \"\"\n\n    # args - (Optional) A list of arguments that will be presented to the step when it is started. If the image used to run the step's container has an entrypoint, the `args` are used as arguments to that entrypoint. If the image does not define an entrypoint, the first element in args is used as the entrypoint, and the remainder will be used as arguments.\n    args = \"\"\n\n    # branch_name - (Optional) Name of the branch to build.\n    branch_name = \"\"\n\n    # commit_sha - (Optional) Explicit commit SHA to build.\n    commit_sha = \"\"\n\n    # dir - (Optional) Directory, relative to the source root, in which to run the build. This must be a relative path. If a step's `dir` is specified and is an absolute path, this value is ignored for that step's execution.\n    dir = \"\"\n\n    # project - (Optional) ID of the project that owns the Cloud Source Repository.\n    project = \"\"\n\n    # repo_name - (Optional) Name of the Cloud Source Repository.\n    repo_name = \"\"\n\n    # tag_name - (Optional) Name of the tag to build.\n    tag_name = \"\"\n\n    # Exported Attributes\n}",
        "description": "Creates a new build trigger within GCR. For more information, see\n[the official documentation](https://cloud.google.com/container-builder/docs/running-builds/automate-builds)\nand\n[API](https://godoc.org/google.golang.org/api/cloudbuild/v1#BuildTrigger).",
        "prefix": "google-cloudbuild-trigger"
    },
    "google-cloudfunctions-function": {
        "body": "resource \"google_cloudfunctions_function\" \"$1\" {\n    # retry - (Required) Whether the function should be retried on failure. Defaults to `false`.\n    retry = \"\"\n\n    # resource - (Required) Required. The name of the resource from which to observe events, for example, `\"myBucket\"`   \n    resource = \"\"\n\n    # event_type - (Required) The type of event to observe. For example: `\"google.storage.object.finalize\"`. See the documentation on [calling Cloud Functions](https://cloud.google.com/functions/docs/calling/) for a full reference. Only Cloud Storage and Cloud Pub/Sub triggers are supported at this time. Legacy Cloud Storage and Cloud Pub/Sub triggers are also supported, such as `\"providers/cloud.storage/eventTypes/object.change\"` and `\"providers/cloud.pubsub/eventTypes/topic.publish\"`.\n    event_type = \"\"\n\n    # source_archive_object - (Required) The source archive object (file) in archive bucket.\n    source_archive_object = \"\"\n\n    # source_archive_bucket - (Required) The GCS bucket containing the zip archive which contains the function.\n    source_archive_bucket = \"\"\n\n    # name - (Required) A user-defined name of the function. Function names must be unique globally.\n    name = \"\"\n\n    # description - (Optional) Description of the function.\n    description = \"\"\n\n    # available_memory_mb - (Optional) Memory (in MB), available to the function. Default value is 256MB. Allowed values are: 128MB, 256MB, 512MB, 1024MB, and 2048MB.\n    available_memory_mb = \"\"\n\n    # timeout - (Optional) Timeout (in seconds) for the function. Default value is 60 seconds. Cannot be more than 540 seconds.\n    timeout = \"\"\n\n    # entry_point - (Optional) Name of a JavaScript function that will be executed when the Google Cloud Function is triggered.\n    entry_point = \"\"\n\n    # event_trigger - (Optional) A source that fires events in response to a condition in another service. Structure is documented below. Cannot be used with `trigger_http`.\n    event_trigger = \"\"\n\n    # trigger_http - (Optional) Boolean variable. Any HTTP request (of a supported type) to the endpoint will trigger function execution. Supported HTTP request types are: POST, PUT, GET, DELETE, and OPTIONS. Endpoint is returned as `https_trigger_url`. Cannot be used with `trigger_bucket` and `trigger_topic`.\n    trigger_http = \"\"\n\n    # trigger_bucket - (Optional) Google Cloud Storage bucket name. Every change in files in this bucket will trigger function execution. Cannot be used with `trigger_http` and `trigger_topic`. Deprecated. Use `event_trigger` instead.\n    trigger_bucket = \"\"\n\n    # trigger_topic - (Optional) Name of Pub/Sub topic. Every message published in this topic will trigger function execution with message contents passed as input data. Cannot be used with `trigger_http` and `trigger_bucket`. Deprecated. Use `event_trigger` instead.\n    trigger_topic = \"\"\n\n    # labels - (Optional) A set of key/value label pairs to assign to the function.\n    labels = \"\"\n\n    # runtime - (Optional) The runtime in which the function is going to run. If empty, defaults to `\"nodejs6\"`.\n    runtime = \"\"\n\n    # environment_variables - (Optional) A set of key/value environment variable pairs to assign to the function.\n    environment_variables = \"\"\n\n    # retry_on_failure - (Optional) Whether the function should be retried on failure. This only applies to bucket and topic triggers, not HTTPS triggers. Deprecated. Use `event_trigger.failure_policy.retry` instead.\n    retry_on_failure = \"\"\n\n    # failure_policy - (Optional) Specifies policy for failed executions. Structure is documented below.\n    failure_policy = \"\"\n\n    # failure_policy - (Optional) Specifies policy for failed executions. Structure is documented below.\n    failure_policy = \"\"\n\n    # Exported Attributes\n    # \"https_trigger_url\" - URL which triggers function execution. Returned only if \"trigger_http\" is used.\n    # \"project\" - Project of the function. If it is not provided, the provider project is used.\n    # \"region\" - Region of function. Currently can be only \"us-central1\". If it is not provided, the provider region is used.\n}",
        "description": "Creates a new Cloud Function. For more information see\n[the official documentation](https://cloud.google.com/functions/docs/)\nand\n[API](https://cloud.google.com/functions/docs/apis).",
        "prefix": "google-cloudfunctions-function"
    },
    "google-cloudiot-registry-x": {
        "body": "resource \"google_cloudiot_registry\" \"$1\" {\n    # certificate - (Required) The certificate data.\n    certificate = \"\"\n\n    # format - (Required) The field allows only  `X509_CERTIFICATE_PEM`.\n    format = \"\"\n\n    # public_key_certificate - (Required) The certificate format and data.\n    public_key_certificate = \"\"\n\n    # http_enabled_state - (Required) The field allows `HTTP_ENABLED` or `HTTP_DISABLED`.\n    http_enabled_state = \"\"\n\n    # mqtt_enabled_state - (Required) The field allows `MQTT_ENABLED` or `MQTT_DISABLED`.\n    mqtt_enabled_state = \"\"\n\n    # pubsub_topic_name - (Required) PubSub topic name to publish device state updates.\n    pubsub_topic_name = \"\"\n\n    # pubsub_topic_name - (Required) PubSub topic name to publish device events.\n    pubsub_topic_name = \"\"\n\n    # name - (Required) A unique name for the resource, required by device registry.\n    name = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it is not provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) The Region in which the created address should reside. If it is not provided, the provider region is used.\n    region = \"\"\n\n    # event_notification_config - (Optional) A PubSub topics to publish device events. Structure is documented below.\n    event_notification_config = \"\"\n\n    # state_notification_config - (Optional) A PubSub topic to publish device state updates. Structure is documented below.\n    state_notification_config = \"\"\n\n    # mqtt_config - (Optional) Activate or deactivate MQTT. Structure is documented below.\n    mqtt_config = \"\"\n\n    # http_config - (Optional) Activate or deactivate HTTP. Structure is documented below.\n    http_config = \"\"\n\n    # credentials - (Optional) List of public key certificates to authenticate devices. Structure is documented below. \n    credentials = \"\"\n\n    # credentials - (Optional) List of public key certificates to authenticate devices. Structure is documented below. \n    credentials = \"\"\n\n    # credentials - (Optional) List of public key certificates to authenticate devices. Structure is documented below. \n    credentials = \"\"\n\n    # credentials - (Optional) List of public key certificates to authenticate devices. Structure is documented below. \n    credentials = \"\"\n\n    # credentials - (Optional) List of public key certificates to authenticate devices. Structure is documented below. \n    credentials = \"\"\n\n    # credentials - (Optional) List of public key certificates to authenticate devices. Structure is documented below. \n    credentials = \"\"\n\n    # credentials - (Optional) List of public key certificates to authenticate devices. Structure is documented below. \n    credentials = \"\"\n\n    # credentials - (Optional) List of public key certificates to authenticate devices. Structure is documented below. \n    credentials = \"\"\n\n    # Exported Attributes\n}",
        "description": " Creates a device registry in Google's Cloud IoT Core platform. For more information see\n[the official documentation](https://cloud.google.com/iot/docs/) and\n[API](https://cloud.google.com/iot/docs/reference/cloudiot/rest/v1/projects.locations.registries).",
        "prefix": "google-cloudiot-registry-x"
    },
    "google-composer-environment": {
        "body": "resource \"google_composer_environment\" \"$1\" {\n    # name - (Optional) `name` -\n    name = \"\"\n\n    # config - (Optional) Configuration parameters for this environment  Structure is documented below.\n    config = \"\"\n\n    # labels - (Optional) User-defined labels for this environment. The labels map can contain no more than 64 entries. Entries of the labels map are UTF8 strings that comply with the following restrictions: Label keys must be between 1 and 63 characters long and must conform to the following regular expression: `[a-z]([-a-z0-9]*[a-z0-9])?`. Label values must be between 0 and 63 characters long and must conform to the regular expression `([a-z]([-a-z0-9]*[a-z0-9])?)?`. No more than 64 labels can be associated with a given environment. Both keys and values must be <= 128 bytes in size.\n    labels = \"\"\n\n    # region - (Optional) The location or Compute Engine region for the environment.\n    region = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs.\n    project = \"\"\n\n    # region - (Optional) The location or Compute Engine region for the environment.\n    region = \"\"\n\n    # node_count - (Optional) The number of nodes in the Kubernetes Engine cluster that will be used to run this environment.\n    node_count = \"\"\n\n    # node_config - (Optional) The configuration used for the Kubernetes Engine cluster.  Structure is documented below.\n    node_config = \"\"\n\n    # software_config - (Optional) The configuration settings for software inside the environment.  Structure is documented below.\n    software_config = \"\"\n\n    # zone - (Optional) The Compute Engine zone in which to deploy the VMs running the Apache Airflow software, specified as the zone name or relative resource name (e.g. \"projects/{project}/zones/{zone}\"). Must belong to the enclosing environment's project  and region. If both zone and machineType are specified, machineType must belong to this zone. If neither is specified, the service  will pick default values in the specified resource's region. If only one of zone or machineType is specified, the  location information from the specified field will be used for the location-unspecified field.\n    zone = \"\"\n\n    # machine_type - (Optional) The Compute Engine machine type used for cluster instances, specified as a name or relative resource name. For example: \"projects/{project}/zones/{zone}/machineTypes/{machineType}\". Must belong to the enclosing environment's project and  region/zone. If both zone and machineType are specified, machineType must belong to this zone. If neither is specified, the service  will pick default values in the specified resource's region. If only one of zone or machineType is specified, the  location information from the specified field will be used for the location-unspecified field.\n    machine_type = \"\"\n\n    # network - (Optional) The Compute Engine network to be used for machine communications, specified as a self-link, relative resource name  (e.g. \"projects/{project}/global/networks/{network}\"), by name. The network must belong to the environment's project. If unspecified, the \"default\" network ID in the environment's  project is used. If a Custom Subnet Network is provided, subnetwork must also be provided.\n    network = \"\"\n\n    # subnetwork - (Optional) The Compute Engine subnetwork to be used for machine communications, , specified as a self-link, relative resource name (e.g. \"projects/{project}/regions/{region}/subnetworks/{subnetwork}\"), or by name. If subnetwork is provided,  network must also be provided and the subnetwork must belong to the enclosing environment's project and region.\n    subnetwork = \"\"\n\n    # disk_size_gb - (Optional) The disk size in GB used for node VMs. Minimum size is 20GB. If unspecified, defaults to 100GB. Cannot be updated.\n    disk_size_gb = \"\"\n\n    # oauth_scopes - (Optional) The set of Google API scopes to be made available on all node VMs. Cannot be updated. If empty, defaults to `[\"https://www.googleapis.com/auth/cloud-platform\"]`\n    oauth_scopes = \"\"\n\n    # service_account - (Optional) The Google Cloud Platform Service Account to be used by the node VMs. If a service account is not specified, the \"default\" Compute Engine service account is used. Cannot be updated. If given, note that the service account must have `roles/composer.worker`  for any GCP resources created under the Cloud Composer Environment.\n    service_account = \"\"\n\n    # tags - (Optional) The list of instance tags applied to all node VMs. Tags are used to identify valid sources or targets for network firewalls. Each tag within the list must comply with RFC1035. Cannot be updated.\n    tags = \"\"\n\n    # airflow_config_overrides - (Optional) Apache Airflow configuration properties to override. Property keys contain the section and property names,  separated by a hyphen, for example \"core-dags_are_paused_at_creation\". Section names must not contain hyphens (\"-\"), opening square brackets (\"[\"), or closing square brackets (\"]\").  The property name must not be empty and cannot contain \"=\" or \";\". Section and property names cannot contain  characters: \".\" Apache Airflow configuration property names must be written in snake_case. Property values can  contain any character, and can be written in any lower/upper case format. Certain Apache Airflow configuration  property values are [blacklisted](https://cloud.google.com/composer/docs/concepts/airflow-configurations#airflow_configuration_blacklists),  and cannot be overridden.\n    airflow_config_overrides = \"\"\n\n    # pypi_packages - (Optional) Custom Python Package Index (PyPI) packages to be installed in the environment. Keys refer to the lowercase package name (e.g. \"numpy\"). Values are the lowercase extras and  version specifier (e.g. \"==1.12.0\", \"[devel,gcp_api]\", \"[devel]>=1.8.2, <1.9.2\"). To specify a package without  pinning it to a version specifier, use the empty string as the value.\n    pypi_packages = \"\"\n\n    # env_variables - (Optional) Additional environment variables to provide to the Apache Airflow scheduler, worker, and webserver processes.  Environment variable names must match the regular expression `[a-zA-Z_][a-zA-Z0-9_]*`.  They cannot specify Apache Airflow software configuration overrides (they cannot match the regular expression  `AIRFLOW__[A-Z0-9_]+__[A-Z0-9_]+`), and they cannot match any of the following reserved names: AIRFLOW_HOME\n    env_variables = \"\"\n\n    # Exported Attributes\n    # \"config.gke_cluster\" - The Kubernetes Engine cluster used to run this environment.\n    # \"config.dag_gcs_prefix\" - The Cloud Storage prefix of the DAGs for this environment. Although Cloud Storage objects reside in a flat namespace, a hierarchical file tree can be simulated using '/'-delimited object name prefixes. DAG objects for this environment reside in a simulated directory with this prefix.\n    # \"config.airflow_uri\" - The URI of the Apache Airflow Web UI hosted within this environment.\n    # \"config.software_config.image_version\" - The version of the software running in the environment. This encapsulates both the version of Cloud Composer functionality and the version of Apache Airflow. It must match the regular expression  \"composer-[0-9]+\\.[0-9]+(\\.[0-9]+)?-airflow-[0-9]+\\.[0-9]+(\\.[0-9]+.*)?\". The Cloud Composer portion of the version is a semantic version.  The portion of the image version following 'airflow-' is an official Apache Airflow repository release name.\n}",
        "description": "An environment for running orchestration tasks. Environments run Apache Airflow software on Google infrastructure. To get more information about Environments, see: [API documentation](https://cloud.google.com/composer/docs/reference/rest/)  How-to Guides [Official Documentation](https://cloud.google.com/composer/docs)  [Configuring Shared VPC for Composer Environments](https://cloud.google.com/composer/docs/how-to/managing/configuring-shared-vpc)   [Apache Airflow Documentation](http://airflow.apache.org/)  ~> **Warning:** We **STRONGLY** recommend  you read the [GCP guides](https://cloud.google.com/composer/docs/how-to)\n  as the Environment resource requires a long deployment process and involves several layers of GCP infrastructure, \n  including a Kubernetes Engine cluster, Cloud Storage, and Compute networking resources. Due to limitations of the API,\n  Terraform will not be able to automatically find or manage many of these underlying resources. In particular: It can take up to one hour to create or update an environment resource. In addition, GCP may only detect some  errors in configuration when they are used (e.g. ~40-50 minutes into the creation process), and is prone to limited error reporting. If you encounter confusing or uninformative errors, please verify your configuration is valid  against GCP Cloud Composer before filing bugs against the Terraform provider.   **Environments create Google Cloud Storage buckets that do not get cleaned up automatically** on environment  deletion. [More about Composer's use of Cloud Storage](https://cloud.google.com/composer/docs/concepts/cloud-storage). ",
        "prefix": "google-composer-environment"
    },
    "google-compute-attached-disk": {
        "body": "resource \"google_compute_attached_disk\" \"$1\" {\n    # disk - (Required) `name` or `self_link` of the disk that will be attached.\n    disk = \"\"\n\n    # instance - (Required) `name` or `self_link` of the compute instance that the disk will be attached to. If the `self_link` is provided then `zone` and `project` are extracted from the self link. If only the name is used then `zone` and `project` must be defined as properties on the resource or provider.\n    instance = \"\"\n\n    # project - (Optional) The project that the referenced compute instance is a part of. If `instance` is referenced by its `self_link` the project defined in the link will take precedence.\n    project = \"\"\n\n    # zone - (Optional) The zone that the referenced compute instance is located within. If `instance` is referenced by its `self_link` the zone defined in the link will take precedence.\n    zone = \"\"\n\n    # device_name - (Optional) Specifies a unique device name of your choice that is \treflected into the /dev/disk/by-id/google-* tree of a Linux operating \tsystem running within the instance. This name can be used to \treference the device for mounting, resizing, and so on, from within \tthe instance.\n    device_name = \"\"\n\n    # mode - (Optional) `mode` -\n    mode = \"\"\n\n    # device_name - (Optional) Specifies a unique device name of your choice that is \treflected into the /dev/disk/by-id/google-* tree of a Linux operating \tsystem running within the instance. This name can be used to \treference the device for mounting, resizing, and so on, from within \tthe instance.\n    device_name = \"\"\n\n    # Exported Attributes\n}",
        "description": "Persistent disks can be attached to a compute instance using [the `attached_disk`\nsection within the compute instance configuration](https://www.terraform.io/docs/providers/google/r/compute_instance.html#attached_disk).\nHowever there may be situations where managing the attached disks via the compute\ninstance config isn't preferable or possible, such as attaching dynamic\nnumbers of disks using the `count` variable. To get more information about attaching disks, see: [API documentation](https://cloud.google.com/compute/docs/reference/rest/v1/instances/attachDisk)  [Resource: google_compute_disk](https://www.terraform.io/docs/providers/google/r/compute_disk.html)  How-to Guides [Adding a persistent disk](https://cloud.google.com/compute/docs/disks/add-persistent-disk)  ",
        "prefix": "google-compute-attached-disk"
    },
    "google-compute-backend-service": {
        "body": "resource \"google_compute_backend_service\" \"$1\" {\n    # group - (Required) The name or URI of a Compute Engine instance group   (`google_compute_instance_group_manager.xyz.instance_group`) that can   receive traffic.\n    group = \"\"\n\n    # health_checks - (Required) Specifies a list of HTTP/HTTPS health checks   for checking the health of the backend service. Currently at most one health   check can be specified, and a health check is required.\n    health_checks = \"\"\n\n    # name - (Required) The name of the backend service.\n    name = \"\"\n\n    # backend - (Optional) The list of backends that serve this BackendService. Structure is documented below.\n    backend = \"\"\n\n    # iap - (Optional) Specification for the Identity-Aware proxy. Disabled if not specified. Structure is documented below.\n    iap = \"\"\n\n    # cdn_policy - (Optional) Cloud CDN configuration for this BackendService. Structure is documented below.\n    cdn_policy = \"\"\n\n    # connection_draining_timeout_sec - (Optional) Time for which instance will be drained (not accept new connections, but still work to finish started ones). Defaults to `300`.\n    connection_draining_timeout_sec = \"\"\n\n    # custom_request_headers - (Optional) Headers that the   HTTP/S load balancer should add to proxied requests. See [guide](https://cloud.google.com/compute/docs/load-balancing/http/backend-service#user-defined-request-headers) for details.   This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    custom_request_headers = \"\"\n\n    # description - (Optional) The textual description for the backend service.\n    description = \"\"\n\n    # enable_cdn - (Optional) Whether or not to enable the Cloud CDN on the backend service.\n    enable_cdn = \"\"\n\n    # port_name - (Optional) The name of a service that has been added to an   instance group in this backend. See [related docs](https://cloud.google.com/compute/docs/instance-groups/#specifying_service_endpoints) for details. Defaults to http.\n    port_name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # protocol - (Optional) The protocol for incoming requests. Defaults to   `HTTP`.\n    protocol = \"\"\n\n    # security_policy - (Optional) Name or URI of a   [security policy](https://cloud.google.com/armor/docs/security-policy-concepts) to add to the backend service.\n    security_policy = \"\"\n\n    # session_affinity - (Optional) How to distribute load. Options are `NONE` (no   affinity), `CLIENT_IP` (hash of the source/dest addresses / ports), and   `GENERATED_COOKIE` (distribute load using a generated session cookie).\n    session_affinity = \"\"\n\n    # timeout_sec - (Optional) The number of secs to wait for a backend to respond   to a request before considering the request failed. Defaults to `30`.\n    timeout_sec = \"\"\n\n    # balancing_mode - (Optional) Defines the strategy for balancing load.   Defaults to `UTILIZATION`\n    balancing_mode = \"\"\n\n    # capacity_scaler - (Optional) A float in the range [0, 1.0] that scales the   maximum parameters for the group (e.g., max rate). A value of 0.0 will cause   no requests to be sent to the group (i.e., it adds the group in a drained   state). The default is 1.0.\n    capacity_scaler = \"\"\n\n    # description - (Optional) Textual description for the backend.\n    description = \"\"\n\n    # max_rate - (Optional) Maximum requests per second (RPS) that the group can   handle.\n    max_rate = \"\"\n\n    # max_rate_per_instance - (Optional) The maximum per-instance requests per   second (RPS).\n    max_rate_per_instance = \"\"\n\n    # max_connections - (Optional) The max number of simultaneous connections for the   group. Can be used with either CONNECTION or UTILIZATION balancing   modes. For CONNECTION mode, either maxConnections or   maxConnectionsPerInstance must be set.\n    max_connections = \"\"\n\n    # max_connections_per_instance - (Optional) The max number of simultaneous connections   that a single backend instance can handle. This is used to calculate   the capacity of the group. Can be used in either CONNECTION or   UTILIZATION balancing modes. For CONNECTION mode, either   maxConnections or maxConnectionsPerInstance must be set.\n    max_connections_per_instance = \"\"\n\n    # max_utilization - (Optional) The target CPU utilization for the group as a   float in the range [0.0, 1.0]. This flag can only be provided when the   balancing mode is `UTILIZATION`. Defaults to `0.8`.\n    max_utilization = \"\"\n\n    # cache_key_policy - (Optional) The CacheKeyPolicy for this CdnPolicy.\n    cache_key_policy = \"\"\n\n    # max_utilization - (Optional) The target CPU utilization for the group as a   float in the range [0.0, 1.0]. This flag can only be provided when the   balancing mode is `UTILIZATION`. Defaults to `0.8`.\n    max_utilization = \"\"\n\n    # include_host - (Optional) If true, requests to different hosts will be cached separately.\n    include_host = \"\"\n\n    # include_protocol - (Optional) If true, http and https requests will be cached separately.\n    include_protocol = \"\"\n\n    # include_query_string - (Optional) If true, include query string parameters in the cache key   according to `query_string_whitelist` and `query_string_blacklist`. If neither is set, the entire   query string will be included. If false, the query string will be excluded from the cache key entirely.\n    include_query_string = \"\"\n\n    # query_string_blacklist - (Optional) Names of query string parameters to exclude in cache keys.   All other parameters will be included. Either specify `query_string_whitelist` or   `query_string_blacklist`, not both. '&' and '=' will be percent encoded and not treated as delimiters.\n    query_string_blacklist = \"\"\n\n    # query_string_whitelist - (Optional) Names of query string parameters to include in cache keys.   All other parameters will be excluded. Either specify `query_string_whitelist` or   `query_string_blacklist`, not both. '&' and '=' will be percent encoded and not treated as delimiters.\n    query_string_whitelist = \"\"\n\n    # Exported Attributes\n    # \"fingerprint\" - The fingerprint of the backend service.\n    # \"self_link\" - The URI of the created resource.\n}",
        "description": "A Backend Service defines a group of virtual machines that will serve traffic for load balancing. For more information\nsee [the official documentation](https://cloud.google.com/compute/docs/load-balancing/http/backend-service)\nand the [API](https://cloud.google.com/compute/docs/reference/latest/backendServices). For internal load balancing, use a [google_compute_region_backend_service](/docs/providers/google/r/compute_region_backend_service.html).",
        "prefix": "google-compute-backend-service"
    },
    "google-compute-global-forwarding-rule": {
        "body": "resource \"google_compute_global_forwarding_rule\" \"$1\" {\n    # target - (Required) URL of target HTTP or HTTPS proxy.\n    target = \"\"\n\n    # name - (Required) A unique name for the resource, required by GCE. Changing this forces a new resource to be created.\n    name = \"\"\n\n    # description - (Optional) Textual description field.\n    description = \"\"\n\n    # ip_address - (Optional) The static IP. (if not set, an ephemeral IP is   used). This should be the literal IP address to be used, not the `self_link`   to a `google_compute_global_address` resource. (If using a `google_compute_global_address`   resource, use the `address` property instead of the `self_link` property.)\n    ip_address = \"\"\n\n    # ip_protocol - (Optional) The IP protocol to route, one of \"TCP\" \"UDP\" \"AH\"   \"ESP\" or \"SCTP\". (default \"TCP\").\n    ip_protocol = \"\"\n\n    # port_range - (Optional) A range e.g. \"1024-2048\" or a single port \"1024\"   (defaults to all ports!). Some types of forwarding targets have constraints on the acceptable ports: Target HTTP proxy: 80, 8080\n    port_range = \"\"\n\n    # port_range - (Optional) A range e.g. \"1024-2048\" or a single port \"1024\"   (defaults to all ports!). Some types of forwarding targets have constraints on the acceptable ports: Target HTTP proxy: 80, 8080\n    port_range = \"\"\n\n    # port_range - (Optional) A range e.g. \"1024-2048\" or a single port \"1024\"   (defaults to all ports!). Some types of forwarding targets have constraints on the acceptable ports: Target HTTP proxy: 80, 8080\n    port_range = \"\"\n\n    # port_range - (Optional) A range e.g. \"1024-2048\" or a single port \"1024\"   (defaults to all ports!). Some types of forwarding targets have constraints on the acceptable ports: Target HTTP proxy: 80, 8080\n    port_range = \"\"\n\n    # port_range - (Optional) A range e.g. \"1024-2048\" or a single port \"1024\"   (defaults to all ports!). Some types of forwarding targets have constraints on the acceptable ports: Target HTTP proxy: 80, 8080\n    port_range = \"\"\n\n    # port_range - (Optional) A range e.g. \"1024-2048\" or a single port \"1024\"   (defaults to all ports!). Some types of forwarding targets have constraints on the acceptable ports: Target HTTP proxy: 80, 8080\n    port_range = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # ip_version - (Optional) The IP Version that will be used by this resource's address. One of `\"IPV4\"` or `\"IPV6\"`. You cannot provide this and `ip_address`.\n    ip_version = \"\"\n\n    # labels - (Optional) \n    labels = \"\"\n\n    # ip_version - (Optional) The IP Version that will be used by this resource's address. One of `\"IPV4\"` or `\"IPV6\"`. You cannot provide this and `ip_address`.\n    ip_version = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The URI of the created resource.\n    # \"label_fingerprint\" - The current label fingerprint. This property is in beta, and should be used with the terraform-provider-google-beta provider. See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n}",
        "description": "Manages a Global Forwarding Rule within GCE. This binds an ip and port to a target HTTP(s) proxy. For more\ninformation see [the official\ndocumentation](https://cloud.google.com/compute/docs/load-balancing/http/global-forwarding-rules) and\n[API](https://cloud.google.com/compute/docs/reference/latest/globalForwardingRules).",
        "prefix": "google-compute-global-forwarding-rule"
    },
    "google-compute-image": {
        "body": "resource \"google_compute_image\" \"$1\" {\n    # source - (Required) The full Google Cloud Storage URL where the disk   image is stored.\n    source = \"\"\n\n    # name - (Required) A unique name for the resource, required by GCE.\n    name = \"\"\n\n    # description - (Optional) The description of the image to be created\n    description = \"\"\n\n    # family - (Optional) The name of the image family to which this image belongs.\n    family = \"\"\n\n    # labels - (Optional) A set of key/value label pairs to assign to the image.\n    labels = \"\"\n\n    # source_disk - (Optional) The URL of a disk that will be used as the source of the   image. Changing this forces a new resource to be created.\n    source_disk = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # raw_disk - (Optional) The raw disk that will be used as the source of the image.   Changing this forces a new resource to be created. Structure is documented   below.\n    raw_disk = \"\"\n\n    # licenses - (Optional) A list of license URIs to apply to this image. Changing this   forces a new resource to be created.\n    licenses = \"\"\n\n    # create_timeout - (Optional) (Deprecated) Configurable timeout in minutes for creating images. Default is 4 minutes.\n    create_timeout = \"\"\n\n    # container_type - (Optional) The format used to encode and transmit the   block device. TAR is the only supported type and is the default.\n    container_type = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The URI of the created resource.\n    # \"label_fingerprint\" - The fingerprint of the assigned labels.\n}",
        "description": "Creates a bootable VM image resource for Google Compute Engine from an existing\ntarball. For more information see [the official documentation](https://cloud.google.com/compute/docs/images) and\n[API](https://cloud.google.com/compute/docs/reference/latest/images).",
        "prefix": "google-compute-image"
    },
    "google-compute-instance-from-template": {
        "body": "resource \"google_compute_instance_from_template\" \"$1\" {\n    # source_instance_template - (Required) Name or self link of an instance template to create the instance based on.\n    source_instance_template = \"\"\n\n    # source_instance_template - (Required) Name or self link of an instance template to create the instance based on.\n    source_instance_template = \"\"\n\n    # name - (Required) A unique name for the resource, required by GCE.   Changing this forces a new resource to be created.\n    name = \"\"\n\n    # zone - (Optional) The zone that the machine should be created in. If not\n    zone = \"\"\n\n    # Exported Attributes\n}",
        "description": "Manages a VM instance resource within GCE. For more information see\n[the official documentation](https://cloud.google.com/compute/docs/instances)\nand\n[API](https://cloud.google.com/compute/docs/reference/latest/instances). This resource is specifically to create a compute instance from a given\n`source_instance_template`. To create an instance without a template, use the\n`google_compute_instance` resource.",
        "prefix": "google-compute-instance-from-template"
    },
    "google-compute-instance-group-manager": {
        "body": "resource \"google_compute_instance_group_manager\" \"$1\" {\n    # instance_template - (Required) - The full URL to an instance template from which all new instances of this version will be created.\n    instance_template = \"\"\n\n    # name - (Required) - Version name.\n    name = \"\"\n\n    # initial_delay_sec - (Required) The number of seconds that the managed instance group waits before it applies autohealing policies to new instances or recently recreated instances. Between 0 and 3600.\n    initial_delay_sec = \"\"\n\n    # health_check - (Required) The health check resource that signals autohealing.\n    health_check = \"\"\n\n    # port - (Required) The port number.\n    port = \"\"\n\n    # name - (Required) The name of the port.\n    name = \"\"\n\n    # type - (Required) - The type of update. Valid values are `\"OPPORTUNISTIC\"`, `\"PROACTIVE\"`\n    type = \"\"\n\n    # minimal_action - (Required) - Minimal action to be taken on an instance. Valid values are `\"RESTART\"`, `\"REPLACE\"`\n    minimal_action = \"\"\n\n    # zone - (Required) The zone that instances in this group should be created   in.\n    zone = \"\"\n\n    # name - (Required) The name of the instance group manager. Must be 1-63   characters long and comply with   [RFC1035](https://www.ietf.org/rfc/rfc1035.txt). Supported characters   include lowercase letters, numbers, and hyphens.\n    name = \"\"\n\n    # base_instance_name - (Required) The base instance name to use for   instances in this group. The value must be a valid   [RFC1035](https://www.ietf.org/rfc/rfc1035.txt) name. Supported characters   are lowercase letters, numbers, and hyphens (-). Instances are named by   appending a hyphen and a random four-character string to the base instance   name.\n    base_instance_name = \"\"\n\n    # instance_template - (Optional) The full URL to an instance template from   which all new instances will be created. Conflicts with `version` (see [documentation](https://cloud.google.com/compute/docs/instance-groups/updating-managed-instance-groups#relationship_between_instancetemplate_properties_for_a_managed_instance_group))\n    instance_template = \"\"\n\n    # version - (Optional) Application versions managed by this instance group. Each   version deals with a specific instance template, allowing canary release scenarios.   Conflicts with `instance_template`. Structure is documented below. Beware that   exactly one version must not specify a target size. It means that versions with   a target size will respect the setting, and the one without target size will   be applied to all remaining Instances (top level target_size - each version target_size).   This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    version = \"\"\n\n    # description - (Optional) An optional textual description of the instance   group manager.\n    description = \"\"\n\n    # named_port - (Optional) The named port configuration. See the section below   for details on configuration.\n    named_port = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # update_strategy - (Optional) (Optional, Default `\"REPLACE\"`) If the `instance_template`   resource is modified, a value of `\"NONE\"` will prevent any of the managed   instances from being restarted by Terraform. A value of `\"REPLACE\"` will   restart all of the instances at once. `\"ROLLING_UPDATE\"` is supported as a beta feature.   A value of `\"ROLLING_UPDATE\"` requires `rolling_update_policy` block to be set\n    update_strategy = \"\"\n\n    # target_size - (Optional) The target number of running instances for this managed   instance group. This value should always be explicitly set unless this resource is attached to    an autoscaler, in which case it should never be set. Defaults to `0`.\n    target_size = \"\"\n\n    # target_pools - (Optional) The full URL of all target pools to which new   instances in the group are added. Updating the target pools attribute does   not affect existing instances.\n    target_pools = \"\"\n\n    # wait_for_instances - (Optional) Whether to wait for all instances to be created/updated before   returning. Note that if this is set to true and the operation does not succeed, Terraform will   continue trying until it times out.\n    wait_for_instances = \"\"\n\n    # auto_healing_policies - (Optional) The autohealing policies for this managed instance group. You can specify only one value. Structure is documented below. For more information, see the [official documentation](https://cloud.google.com/compute/docs/instance-groups/creating-groups-of-managed-instances#monitoring_groups). This property is in beta, and should be used with the terraform-provider-google-beta provider. See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    auto_healing_policies = \"\"\n\n    # rolling_update_policy - (Optional) The update policy for this managed instance group. Structure is documented below. For more information, see the [official documentation](https://cloud.google.com/compute/docs/instance-groups/updating-managed-instance-groups) and [API](https://cloud.google.com/compute/docs/reference/rest/beta/instanceGroupManagers/patch) This property is in beta, and should be used with the terraform-provider-google-beta provider. See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    rolling_update_policy = \"\"\n\n    # max_surge_fixed - (Optional) \n    max_surge_fixed = \"\"\n\n    # max_surge_percent - (Optional) \n    max_surge_percent = \"\"\n\n    # max_unavailable_fixed - (Optional) \n    max_unavailable_fixed = \"\"\n\n    # max_unavailable_percent - (Optional) \n    max_unavailable_percent = \"\"\n\n    # min_ready_sec - (Optional) \n    min_ready_sec = \"\"\n\n    # target_size - (Optional) - The number of instances calculated as a fixed number or a percentage depending on the settings. Structure is documented below.\n    target_size = \"\"\n\n    # fixed - (Optional) \n    fixed = \"\"\n\n    # percent - (Optional) \n    percent = \"\"\n\n    # Exported Attributes\n    # \"fingerprint\" - The fingerprint of the instance group manager.\n    # \"instance_group\" - The full URL of the instance group created by the manager.\n    # \"self_link\" - The URL of the created resource.\n}",
        "description": "The Google Compute Engine Instance Group Manager API creates and manages pools\nof homogeneous Compute Engine virtual machine instances from a common instance\ntemplate. For more information, see [the official documentation](https://cloud.google.com/compute/docs/instance-groups/manager)\nand [API](https://cloud.google.com/compute/docs/reference/latest/instanceGroupManagers) ~> **Note:** Use [google_compute_region_instance_group_manager](/docs/providers/google/r/compute_region_instance_group_manager.html) to create a regional (multi-zone) instance group manager.",
        "prefix": "google-compute-instance-group-manager"
    },
    "google-compute-instance-group-x": {
        "body": "resource \"google_compute_instance_group\" \"$1\" {\n    # port - (Required) The port number to map the name to.\n    port = \"\"\n\n    # name - (Required) The name which the port will be mapped to.\n    name = \"\"\n\n    # zone - (Required) The zone that this instance group should be created in.\n    zone = \"\"\n\n    # name - (Required) The name of the instance group. Must be 1-63   characters long and comply with   [RFC1035](https://www.ietf.org/rfc/rfc1035.txt). Supported characters   include lowercase letters, numbers, and hyphens.\n    name = \"\"\n\n    # description - (Optional) An optional textual description of the instance   group.\n    description = \"\"\n\n    # instances - (Optional) List of instances in the group. They should be given   as self_link URLs. When adding instances they must all be in the same   network and zone as the instance group.\n    instances = \"\"\n\n    # named_port - (Optional) The named port configuration. See the section below   for details on configuration.\n    named_port = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # network - (Optional) The URL of the network the instance group is in. If   this is different from the network where the instances are in, the creation   fails. Defaults to the network where the instances are in (if neither   `network` nor `instances` is specified, this field will be blank).\n    network = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The URI of the created resource.\n    # \"size\" - The number of instances in the group.\n}",
        "description": "Creates a group of dissimilar Compute Engine virtual machine instances.\nFor more information, see [the official documentation](https://cloud.google.com/compute/docs/instance-groups/#unmanaged_instance_groups)\nand [API](https://cloud.google.com/compute/docs/reference/latest/instanceGroups)",
        "prefix": "google-compute-instance-group-x"
    },
    "google-compute-instance-template": {
        "body": "resource \"google_compute_instance_template\" \"$1\" {\n    # count - (Required) - The number of the guest accelerator cards exposed to this instance.\n    count = \"\"\n\n    # type - (Required) - The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.\n    type = \"\"\n\n    # scopes - (Required) A list of service scopes. Both OAuth2 URLs and gcloud   short names are supported. To allow full access to all Cloud APIs, use the   `cloud-platform` scope. See a complete list of scopes [here](https://cloud.google.com/sdk/gcloud/reference/alpha/compute/instances/set-scopes#--scopes).\n    scopes = \"\"\n\n    # network_interface - (Required) Networks to attach to instances created from   this template. This can be specified multiple times for multiple networks.   Structure is documented below.\n    network_interface = \"\"\n\n    # machine_type - (Required) The machine type to create.   **Note:** If you want to update this value (resize the VM) after initial creation, you must set [`allow_stopping_for_update`](#allow_stopping_for_update) to `true`.   To create a machine with a [custom type][custom-vm-types] (such as extended memory), format the value like `custom-VCPUS-MEM_IN_MB` like `custom-6-20480` for 6 vCPU and 20GB of RAM.\n    machine_type = \"\"\n\n    # disk - (Required) Disks to attach to instances created from this template.   This can be specified multiple times for multiple disks. Structure is   documented below.\n    disk = \"\"\n\n    # name - (Optional) The name of the instance template. If you leave this blank, Terraform will auto-generate a unique name.\n    name = \"\"\n\n    # name_prefix - (Optional) Creates a unique name beginning with the specified prefix. Conflicts with `name`.\n    name_prefix = \"\"\n\n    # can_ip_forward - (Optional) Whether to allow sending and receiving of   packets with non-matching source or destination IPs. This defaults to false.\n    can_ip_forward = \"\"\n\n    # description - (Optional) A brief description of this resource.\n    description = \"\"\n\n    # instance_description - (Optional) A brief description to use for instances   created from this template.\n    instance_description = \"\"\n\n    # labels - (Optional) A set of key/value label pairs to assign to instances   created from this template,\n    labels = \"\"\n\n    # metadata - (Optional) Metadata key/value pairs to make available from   within instances created from this template.\n    metadata = \"\"\n\n    # metadata_startup_script - (Optional) An alternative to using the   startup-script metadata key, mostly to match the compute_instance resource.   This replaces the startup-script metadata key on the created instance and   thus the two mechanisms are not allowed to be used simultaneously.\n    metadata_startup_script = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) An instance template is a global resource that is not   bound to a zone or a region. However, you can still specify some regional   resources in an instance template, which restricts the template to the   region where that resource resides. For example, a custom `subnetwork`   resource is tied to a specific region. Defaults to the region of the   Provider if no value is given.\n    region = \"\"\n\n    # scheduling - (Optional) The scheduling strategy to use. More details about   this configuration option are detailed below.\n    scheduling = \"\"\n\n    # service_account - (Optional) Service account to attach to the instance. Structure is documented below.\n    service_account = \"\"\n\n    # tags - (Optional) Tags to attach to the instance.\n    tags = \"\"\n\n    # guest_accelerator - (Optional) List of the type and count of accelerator cards attached to the instance. Structure documented below.\n    guest_accelerator = \"\"\n\n    # min_cpu_platform - (Optional) Specifies a minimum CPU platform. Applicable values are the friendly names of CPU platforms, such as `Intel Haswell` or `Intel Skylake`. See the complete list [here](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform).\n    min_cpu_platform = \"\"\n\n    # auto_delete - (Optional) Whether or not the disk should be auto-deleted.   This defaults to true.\n    auto_delete = \"\"\n\n    # boot - (Optional) Indicates that this is a boot disk.\n    boot = \"\"\n\n    # device_name - (Optional) A unique device name that is reflected into the   /dev/  tree of a Linux operating system running within the instance. If not   specified, the server chooses a default device name to apply to this disk.\n    device_name = \"\"\n\n    # disk_name - (Optional) Name of the disk. When not provided, this defaults   to the name of the instance.\n    disk_name = \"\"\n\n    # source_image - (Optional) (Required if source not set) The image from which to   initialize this disk. This can be one of: the image's `self_link`,   `projects/{project}/global/images/{image}`,   `projects/{project}/global/images/family/{family}`, `global/images/{image}`,   `global/images/family/{family}`, `family/{family}`, `{project}/{family}`,   `{project}/{image}`, `{family}`, or `{image}`.\n    source_image = \"\"\n\n    # interface - (Optional) Specifies the disk interface to use for attaching   this disk.\n    interface = \"\"\n\n    # mode - (Optional) The mode in which to attach this disk, either READ_WRITE   or READ_ONLY. If you are attaching or creating a boot disk, this must   read-write mode.\n    mode = \"\"\n\n    # source - (Optional) (Required if source_image not set) The name (**not self_link**)   of the disk (such as those managed by `google_compute_disk`) to attach. \n    source = \"\"\n\n    # disk_type - (Optional) The GCE disk type. Can be either `\"pd-ssd\"`,   `\"local-ssd\"`, or `\"pd-standard\"`.\n    disk_type = \"\"\n\n    # disk_size_gb - (Optional) The size of the image in gigabytes. If not   specified, it will inherit the size of its base image.\n    disk_size_gb = \"\"\n\n    # type - (Optional) The type of GCE disk, can be either `\"SCRATCH\"` or   `\"PERSISTENT\"`.\n    type = \"\"\n\n    # disk_encryption_key - (Optional) Encrypts or decrypts a disk using a customer-supplied encryption key.   If you are creating a new disk, this field encrypts the new disk using an encryption key that you provide. If you are attaching an existing disk that is already encrypted, this field decrypts the disk using the customer-supplied encryption key.   If you encrypt a disk using a customer-supplied key, you must provide the same key again when you attempt to use this resource at a later time. For example, you must provide the key when you create a snapshot or an image from the disk or when you attach the disk to a virtual machine instance.   If you do not provide an encryption key, then the disk will be encrypted using an automatically generated key and you do not need to provide a key to use the disk later.   Instance templates do not store customer-supplied encryption keys, so you cannot use your own keys to encrypt disks in a managed instance group.\n    disk_encryption_key = \"\"\n\n    # kms_key_self_link - (Optional) The self link of the encryption key that is stored in Google Cloud KMS\n    kms_key_self_link = \"\"\n\n    # disk_encryption_key - (Optional) Encrypts or decrypts a disk using a customer-supplied encryption key.   If you are creating a new disk, this field encrypts the new disk using an encryption key that you provide. If you are attaching an existing disk that is already encrypted, this field decrypts the disk using the customer-supplied encryption key.   If you encrypt a disk using a customer-supplied key, you must provide the same key again when you attempt to use this resource at a later time. For example, you must provide the key when you create a snapshot or an image from the disk or when you attach the disk to a virtual machine instance.   If you do not provide an encryption key, then the disk will be encrypted using an automatically generated key and you do not need to provide a key to use the disk later.   Instance templates do not store customer-supplied encryption keys, so you cannot use your own keys to encrypt disks in a managed instance group.\n    disk_encryption_key = \"\"\n\n    # network - (Optional) The name or self_link of the network to attach this interface to.   Use `network` attribute for Legacy or Auto subnetted networks and   `subnetwork` for custom subnetted networks.\n    network = \"\"\n\n    # subnetwork - (Optional) the name of the subnetwork to attach this interface   to. The subnetwork must exist in the same `region` this instance will be   created in. Either `network` or `subnetwork` must be provided.\n    subnetwork = \"\"\n\n    # subnetwork_project - (Optional) The ID of the project in which the subnetwork belongs.   If it is not provided, the provider project is used.\n    subnetwork_project = \"\"\n\n    # address - (Optional) (Optional, Deprecated) The private IP address to assign to the instance. If   empty, the address will be automatically assigned. This attribute has been deprecated.   Use `network_interface.network_ip` instead.\n    address = \"\"\n\n    # network_ip - (Optional) The private IP address to assign to the instance. If   empty, the address will be automatically assigned.\n    network_ip = \"\"\n\n    # access_config - (Optional) Access configurations, i.e. IPs via which this   instance can be accessed via the Internet. Omit to ensure that the instance   is not accessible from the Internet (this means that ssh provisioners will   not work unless you are running Terraform can send traffic to the instance's   network (e.g. via tunnel or because it is running on another cloud instance   on that network). This block can be repeated multiple times. Structure documented below.\n    access_config = \"\"\n\n    # alias_ip_range - (Optional) An   array of alias IP ranges for this network interface. Can only be specified for network   interfaces on subnet-mode networks. Structure documented below.\n    alias_ip_range = \"\"\n\n    # nat_ip - (Optional) The IP address that will be 1:1 mapped to the instance's   network ip. If not given, one will be generated.\n    nat_ip = \"\"\n\n    # network_tier - (Optional) The [networking tier][network-tier] used for configuring   this instance template. This field can take the following values: PREMIUM or   STANDARD. If this field is not specified, it is assumed to be PREMIUM.\n    network_tier = \"\"\n\n    # ip_cidr_range - (Optional) The IP CIDR range represented by this alias IP range. This IP CIDR range   must belong to the specified subnetwork and cannot contain IP addresses reserved by   system or used by other network interfaces. At the time of writing only a   netmask (e.g. /24) may be supplied, with a CIDR format resulting in an API   error.\n    ip_cidr_range = \"\"\n\n    # subnetwork_range_name - (Optional) The subnetwork secondary range name specifying   the secondary range from which to allocate the IP CIDR range for this alias IP   range. If left unspecified, the primary range of the subnetwork will be used.\n    subnetwork_range_name = \"\"\n\n    # email - (Optional) The service account e-mail address. If not given, the   default Google Compute Engine service account is used.\n    email = \"\"\n\n    # automatic_restart - (Optional) Specifies whether the instance should be   automatically restarted if it is terminated by Compute Engine (not   terminated by a user). This defaults to true.\n    automatic_restart = \"\"\n\n    # on_host_maintenance - (Optional) Defines the maintenance behavior for this   instance.\n    on_host_maintenance = \"\"\n\n    # preemptible - (Optional) Allows instance to be preempted. This defaults to   false. Read more on this   [here](https://cloud.google.com/compute/docs/instances/preemptible).\n    preemptible = \"\"\n\n    # Exported Attributes\n    # \"metadata_fingerprint\" - The unique fingerprint of the metadata.\n    # \"self_link\" - The URI of the created resource.\n    # \"tags_fingerprint\" - The unique fingerprint of the tags.\n}",
        "description": "Manages a VM instance template resource within GCE. For more information see\n[the official documentation](https://cloud.google.com/compute/docs/instance-templates)\nand\n[API](https://cloud.google.com/compute/docs/reference/latest/instanceTemplates).",
        "prefix": "google-compute-instance-template"
    },
    "google-compute-instance-x": {
        "body": "resource \"google_compute_instance\" \"$1\" {\n    # count - (Required) - The number of the guest accelerator cards exposed to this instance.\n    count = \"\"\n\n    # type - (Required) - The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.\n    type = \"\"\n\n    # scopes - (Required) A list of service scopes. Both OAuth2 URLs and gcloud   short names are supported. To allow full access to all Cloud APIs, use the   `cloud-platform` scope. See a complete list of scopes [here](https://cloud.google.com/sdk/gcloud/reference/alpha/compute/instances/set-scopes#--scopes).   **Note**: [`allow_stopping_for_update`](#allow_stopping_for_update) must be set to true in order to update this field.\n    scopes = \"\"\n\n    # source - (Required) The name or self_link of the disk to attach to this instance.\n    source = \"\"\n\n    # network_interface - (Required) Networks to attach to the instance. This can   be specified multiple times. Structure is documented below.\n    network_interface = \"\"\n\n    # zone - (Required) The zone that the machine should be created in.\n    zone = \"\"\n\n    # name - (Required) A unique name for the resource, required by GCE.   Changing this forces a new resource to be created.\n    name = \"\"\n\n    # machine_type - (Required) The machine type to create.   **Note:** If you want to update this value (resize the VM) after initial creation, you must set [`allow_stopping_for_update`](#allow_stopping_for_update) to `true`.   To create a machine with a [custom type][custom-vm-types] (such as extended memory), format the value like `custom-VCPUS-MEM_IN_MB` like `custom-6-20480` for 6 vCPU and 20GB of RAM.\n    machine_type = \"\"\n\n    # boot_disk - (Required) The boot disk for the instance.   Structure is documented below.\n    boot_disk = \"\"\n\n    # allow_stopping_for_update - (Optional) If true, allows Terraform to stop the instance to update its properties. If you try to update a property that requires stopping the instance without setting this field, the update will fail.\n    allow_stopping_for_update = \"\"\n\n    # attached_disk - (Optional) List of disks to attach to the instance. Structure is documented below.\n    attached_disk = \"\"\n\n    # can_ip_forward - (Optional) Whether to allow sending and receiving of   packets with non-matching source or destination IPs.   This defaults to false.\n    can_ip_forward = \"\"\n\n    # create_timeout - (Optional) Configurable timeout in minutes for creating instances. Default is 4 minutes.   Changing this forces a new resource to be created.\n    create_timeout = \"\"\n\n    # description - (Optional) A brief description of this resource.\n    description = \"\"\n\n    # deletion_protection - (Optional) Enable deletion protection on this instance. Defaults to false.   **Note:** you must disable deletion protection before removing the resource (e.g., via `terraform destroy`), or the instance cannot be deleted and the Terraform run will not complete successfully.\n    deletion_protection = \"\"\n\n    # guest_accelerator - (Optional) List of the type and count of accelerator cards attached to the instance. Structure documented below.   **Note:** GPU accelerators can only be used with [`on_host_maintenance`](#on_host_maintenance) option set to TERMINATE.\n    guest_accelerator = \"\"\n\n    # labels - (Optional) A set of key/value label pairs to assign to the instance.\n    labels = \"\"\n\n    # metadata - (Optional) Metadata key/value pairs to make available from   within the instance.\n    metadata = \"\"\n\n    # metadata_startup_script - (Optional) An alternative to using the   startup-script metadata key, except this one forces the instance to be   recreated (thus re-running the script) if it is changed. This replaces the   startup-script metadata key on the created instance and thus the two   mechanisms are not allowed to be used simultaneously.\n    metadata_startup_script = \"\"\n\n    # min_cpu_platform - (Optional) Specifies a minimum CPU platform for the VM instance. Applicable values are the friendly names of CPU platforms, such as `Intel Haswell` or `Intel Skylake`. See the complete list [here](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform).   **Note**: [`allow_stopping_for_update`](#allow_stopping_for_update) must be set to true in order to update this field.\n    min_cpu_platform = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # scheduling - (Optional) The scheduling strategy to use. More details about   this configuration option are detailed below.\n    scheduling = \"\"\n\n    # scratch_disk - (Optional) Scratch disks to attach to the instance. This can be   specified multiple times for multiple scratch disks. Structure is documented below.\n    scratch_disk = \"\"\n\n    # service_account - (Optional) Service account to attach to the instance.   Structure is documented below.   **Note**: [`allow_stopping_for_update`](#allow_stopping_for_update) must be set to true in order to update this field.\n    service_account = \"\"\n\n    # tags - (Optional) A list of tags to attach to the instance.\n    tags = \"\"\n\n    # auto_delete - (Optional) Whether the disk will be auto-deleted when the instance   is deleted. Defaults to true.\n    auto_delete = \"\"\n\n    # device_name - (Optional) Name with which attached disk will be accessible.   On the instance, this device will be `/dev/disk/by-id/google-{{device_name}}`.\n    device_name = \"\"\n\n    # disk_encryption_key_raw - (Optional) A 256-bit [customer-supplied encryption key]   (https://cloud.google.com/compute/docs/disks/customer-supplied-encryption),   encoded in [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)   to encrypt this disk.\n    disk_encryption_key_raw = \"\"\n\n    # initialize_params - (Optional) Parameters for a new disk that will be created   alongside the new instance. Either `initialize_params` or `source` must be set.   Structure is documented below.\n    initialize_params = \"\"\n\n    # source - (Optional) The name or self_link of the existing disk (such as those managed by   `google_compute_disk`) to attach.\n    source = \"\"\n\n    # size - (Optional) The size of the image in gigabytes. If not specified, it   will inherit the size of its base image.\n    size = \"\"\n\n    # type - (Optional) The GCE disk type. May be set to pd-standard or pd-ssd.\n    type = \"\"\n\n    # image - (Optional) The image from which to initialize this disk. This can be   one of: the image's `self_link`, `projects/{project}/global/images/{image}`,   `projects/{project}/global/images/family/{family}`, `global/images/{image}`,   `global/images/family/{family}`, `family/{family}`, `{project}/{family}`,   `{project}/{image}`, `{family}`, or `{image}`. If referred by family, the   images names must include the family name. If they don't, use the   [google_compute_image data source](/docs/providers/google/d/datasource_compute_image.html).   For instance, the image `centos-6-v20180104` includes its family name `centos-6`.   These images can be referred by family name here.\n    image = \"\"\n\n    # interface - (Optional) The disk interface to use for attaching this disk; either SCSI or NVME.\n    interface = \"\"\n\n    # image - (Optional) The image from which to initialize this disk. This can be   one of: the image's `self_link`, `projects/{project}/global/images/{image}`,   `projects/{project}/global/images/family/{family}`, `global/images/{image}`,   `global/images/family/{family}`, `family/{family}`, `{project}/{family}`,   `{project}/{image}`, `{family}`, or `{image}`. If referred by family, the   images names must include the family name. If they don't, use the   [google_compute_image data source](/docs/providers/google/d/datasource_compute_image.html).   For instance, the image `centos-6-v20180104` includes its family name `centos-6`.   These images can be referred by family name here.\n    image = \"\"\n\n    # device_name - (Optional) Name with which the attached disk will be accessible   under `/dev/disk/by-id/`\n    device_name = \"\"\n\n    # mode - (Optional) Either \"READ_ONLY\" or \"READ_WRITE\", defaults to \"READ_WRITE\"   If you have a persistent disk with data that you want to share   between multiple instances, detach it from any read-write instances and   attach it to one or more instances in read-only mode.\n    mode = \"\"\n\n    # disk_encryption_key_raw - (Optional) A 256-bit [customer-supplied encryption key]   (https://cloud.google.com/compute/docs/disks/customer-supplied-encryption),   encoded in [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)   to encrypt this disk.\n    disk_encryption_key_raw = \"\"\n\n    # network - (Optional) The name or self_link of the network to attach this interface to.   Either `network` or `subnetwork` must be provided.\n    network = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the subnetwork to attach this  interface to. The subnetwork must exist in the same region this instance will be  created in. Either `network` or `subnetwork` must be provided.\n    subnetwork = \"\"\n\n    # subnetwork_project - (Optional) The project in which the subnetwork belongs. If the `subnetwork` is a self_link, this field is ignored in favor of the project defined in the subnetwork self_link. If the `subnetwork` is a name and this field is not provided, the provider project is used.\n    subnetwork_project = \"\"\n\n    # address - (Optional) (Optional, Deprecated) The private IP address to assign to the instance. If   empty, the address will be automatically assigned. This attribute has been deprecated.   Use `network_interface.network_ip` instead.\n    address = \"\"\n\n    # network_ip - (Optional) The private IP address to assign to the instance. If   empty, the address will be automatically assigned.\n    network_ip = \"\"\n\n    # access_config - (Optional) Access configurations, i.e. IPs via which this   instance can be accessed via the Internet. Omit to ensure that the instance   is not accessible from the Internet (this means that ssh provisioners will   not work unless you are running Terraform can send traffic to the instance's   network (e.g. via tunnel or because it is running on another cloud instance   on that network). This block can be repeated multiple times. Structure   documented below.\n    access_config = \"\"\n\n    # alias_ip_range - (Optional) An   array of alias IP ranges for this network interface. Can only be specified for network   interfaces on subnet-mode networks. Structure documented below.\n    alias_ip_range = \"\"\n\n    # nat_ip - (Optional) The IP address that will be 1:1 mapped to the instance's   network ip. If not given, one will be generated.\n    nat_ip = \"\"\n\n    # public_ptr_domain_name - (Optional) The DNS domain name for the public PTR record.   To set this field on an instance, you must be verified as the owner of the domain.   See [the docs](https://cloud.google.com/compute/docs/instances/create-ptr-record) for how   to become verified as a domain owner.\n    public_ptr_domain_name = \"\"\n\n    # network_tier - (Optional) The [networking tier][network-tier] used for configuring this instance.   This field can take the following values: PREMIUM or STANDARD. If this field is   not specified, it is assumed to be PREMIUM.\n    network_tier = \"\"\n\n    # ip_cidr_range - (Optional) The IP CIDR range represented by this alias IP range. This IP CIDR range   must belong to the specified subnetwork and cannot contain IP addresses reserved by   system or used by other network interfaces. This range may be a single IP address   (e.g. 10.2.3.4), a netmask (e.g. /24) or a CIDR format string (e.g. 10.1.2.0/24).\n    ip_cidr_range = \"\"\n\n    # subnetwork_range_name - (Optional) The subnetwork secondary range name specifying   the secondary range from which to allocate the IP CIDR range for this alias IP   range. If left unspecified, the primary range of the subnetwork will be used.\n    subnetwork_range_name = \"\"\n\n    # email - (Optional) The service account e-mail address. If not given, the   default Google Compute Engine service account is used.   **Note**: [`allow_stopping_for_update`](#allow_stopping_for_update) must be set to true in order to update this field.\n    email = \"\"\n\n    # preemptible - (Optional) Is the instance preemptible.\n    preemptible = \"\"\n\n    # on_host_maintenance - (Optional) Describes maintenance behavior for the   instance. Can be MIGRATE or TERMINATE, for more info, read   [here](https://cloud.google.com/compute/docs/instances/setting-instance-scheduling-options)\n    on_host_maintenance = \"\"\n\n    # automatic_restart - (Optional) Specifies if the instance should be   restarted if it was terminated by Compute Engine (not a user).\n    automatic_restart = \"\"\n\n    # Exported Attributes\n    # \"instance_id\" - The server-assigned unique identifier of this instance.\n    # \"metadata_fingerprint\" - The unique fingerprint of the metadata.\n    # \"self_link\" - The URI of the created resource.\n    # \"tags_fingerprint\" - The unique fingerprint of the tags.\n    # \"label_fingerprint\" - The unique fingerprint of the labels.\n    # \"cpu_platform\" - The CPU platform used by this instance.\n    # \"network_interface.0.address\" - (Deprecated) The internal ip address of the instance, either manually or dynamically assigned. This attribute has been deprecated. Use \"network_interface.0.network_ip\"instead.\n    # \"network_interface.0.network_ip\" - The internal ip address of the instance, either manually or dynamically assigned.\n    # \"network_interface.0.access_config.0.nat_ip\" - If the instance has an access config, either the given external ip (in the \"nat_ip\" field) or the ephemeral (generated) ip (if you didn't provide one).\n    # \"network_interface.0.access_config.0.assigned_nat_ip\" -  (Deprecated)  If the instance has an access config, either the given external ip (in the \"nat_ip\" field) or the ephemeral (generated) ip (if you didn't provide one). This attribute has been deprecated. Use \"network_interface.0.access_config.0.nat_ip\" instead.\n    # \"attached_disk.0.disk_encryption_key_sha256\" - The [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)   encoded SHA-256 hash of the [customer-supplied encryption key]   (https://cloud.google.com/compute/docs/disks/customer-supplied-encryption) that protects this resource.\n    # \"boot_disk.disk_encryption_key_sha256\" - The [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)   encoded SHA-256 hash of the [customer-supplied encryption key]   (https://cloud.google.com/compute/docs/disks/customer-supplied-encryption) that protects this resource.\n    # \"disk.0.disk_encryption_key_sha256\" - The [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)   encoded SHA-256 hash of the [customer-supplied encryption key]   (https://cloud.google.com/compute/docs/disks/customer-supplied-encryption) that protects this resource.\n}",
        "description": "Manages a VM instance resource within GCE. For more information see\n[the official documentation](https://cloud.google.com/compute/docs/instances)\nand\n[API](https://cloud.google.com/compute/docs/reference/latest/instances).",
        "prefix": "google-compute-instance-x"
    },
    "google-compute-network-peering": {
        "body": "resource \"google_compute_network_peering\" \"$1\" {\n    # peer_network - (Required) Resource link of the peer network.\n    peer_network = \"\"\n\n    # network - (Required) Resource link of the network to add a peering to.\n    network = \"\"\n\n    # name - (Required) Name of the peering.\n    name = \"\"\n\n    # auto_create_routes - (Optional) If set to `true`, the routes between the two networks will be created and managed automatically. Defaults to `true`.\n    auto_create_routes = \"\"\n\n    # Exported Attributes\n    # \"state\" - State for the peering.\n    # \"state_details\" - Details about the current state of the peering.\n}",
        "description": "Manages a network peering within GCE. For more information see\n[the official documentation](https://cloud.google.com/compute/docs/vpc/vpc-peering)\nand\n[API](https://cloud.google.com/compute/docs/reference/latest/networks). ~> **Note:** Both network must create a peering with each other for the peering to be functional. ~> **Note:** Subnets IP ranges across peered VPC networks cannot overlap.",
        "prefix": "google-compute-network-peering"
    },
    "google-compute-network-x": {
        "body": "resource \"google_compute_network\" \"$1\" {\n    # name - (Required) A unique name for the resource, required by GCE.\n    name = \"\"\n\n    # auto_create_subnetworks - (Optional) If set to true, this network will be   created in auto subnet mode, and Google will create a subnet for each region   automatically. If set to false, a custom subnetted network will be created that   can support `google_compute_subnetwork` resources. Defaults to true.\n    auto_create_subnetworks = \"\"\n\n    # routing_mode - (Optional) Sets the network-wide routing mode for Cloud Routers to use. Accepted values are `\"GLOBAL\"` or `\"REGIONAL\"`. Defaults to `\"REGIONAL\"`. Refer to the [Cloud Router documentation](https://cloud.google.com/router/docs/concepts/overview#dynamic-routing-mode) for more details.\n    routing_mode = \"\"\n\n    # description - (Optional) A brief description of this resource.\n    description = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # Exported Attributes\n    # \"gateway_ipv4\" - The IPv4 address of the gateway.\n    # \"name\" - The unique name of the network.\n    # \"self_link\" - The URI of the created resource.\n}",
        "description": "Manages a network within GCE. For more information see\n[the official documentation](https://cloud.google.com/compute/docs/vpc)\nand\n[API](https://cloud.google.com/compute/docs/reference/latest/networks).",
        "prefix": "google-compute-network-x"
    },
    "google-compute-project-metadata": {
        "body": "resource \"google_compute_project_metadata\" \"$1\" {\n    # metadata - (Required) A series of key value pairs. Changing this resource\n    metadata = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it\n    project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Manages metadata common to all instances for a project in GCE. For more information see\n[the official documentation](https://cloud.google.com/compute/docs/storing-retrieving-metadata)\nand\n[API](https://cloud.google.com/compute/docs/reference/latest/projects/setCommonInstanceMetadata). ~> **Note:**  If you want to manage only single key/value pairs within the project metadata\nrather than the entire set, then use\n[google_compute_project_metadata_item](compute_project_metadata_item.html).",
        "prefix": "google-compute-project-metadata"
    },
    "google-compute-project-metadata-item": {
        "body": "resource \"google_compute_project_metadata_item\" \"$1\" {\n    # value - (Required) The value to set for the given metadata key.\n    value = \"\"\n\n    # value - (Required) The value to set for the given metadata key.\n    value = \"\"\n\n    # key - (Required) The metadata key to set.\n    key = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it\n    project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Manages a single key/value pair on metadata common to all instances for\na project in GCE. Using `google_compute_project_metadata_item` lets you\nmanage a single key/value setting in Terraform rather than the entire\nproject metadata map.",
        "prefix": "google-compute-project-metadata-item"
    },
    "google-compute-region-backend-service": {
        "body": "resource \"google_compute_region_backend_service\" \"$1\" {\n    # group - (Required) The name or URI of a Compute Engine instance group   (`google_compute_region_instance_group_manager.xyz.instance_group`) that can   receive traffic. Instance groups must contain at least one instance.\n    group = \"\"\n\n    # health_checks - (Required) Specifies a list of health checks   for checking the health of the backend service. Currently at most   one health check can be specified, and a health check is required.\n    health_checks = \"\"\n\n    # name - (Required) The name of the backend service.\n    name = \"\"\n\n    # backend - (Optional) The list of backends that serve this BackendService.   Structure is documented below.\n    backend = \"\"\n\n    # description - (Optional) The textual description for the backend service.\n    description = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # protocol - (Optional) The protocol for incoming requests. Defaults to   `TCP`.\n    protocol = \"\"\n\n    # session_affinity - (Optional) How to distribute load. Options are `NONE` (no   affinity), `CLIENT_IP`, `CLIENT_IP_PROTO`, or `CLIENT_IP_PORT_PROTO`.   Defaults to `NONE`.\n    session_affinity = \"\"\n\n    # region - (Optional) The Region in which the created address should reside.   If it is not provided, the provider region is used.\n    region = \"\"\n\n    # timeout_sec - (Optional) The number of secs to wait for a backend to respond   to a request before considering the request failed. Defaults to `30`.\n    timeout_sec = \"\"\n\n    # connection_draining_timeout_sec - (Optional) Time for which instance will be drained (not accept new connections, but still work to finish started ones). Defaults to `0`.\n    connection_draining_timeout_sec = \"\"\n\n    # description - (Optional) Textual description for the backend.\n    description = \"\"\n\n    # Exported Attributes\n    # \"fingerprint\" - The fingerprint of the backend service.\n    # \"self_link\" - The URI of the created resource.\n}",
        "description": "A Region Backend Service defines a regionally-scoped group of virtual machines that will serve traffic for load balancing.\nFor more information see [the official documentation](https://cloud.google.com/compute/docs/load-balancing/internal/)\nand [API](https://cloud.google.com/compute/docs/reference/latest/regionBackendServices). ~> **Note**: Region backend services can only be used when using internal load balancing. For external load balancing, use\n  [`google_compute_backend_service`](compute_backend_service.html) instead.",
        "prefix": "google-compute-region-backend-service"
    },
    "google-compute-region_instance-group-manager": {
        "body": "resource \"google_compute_region_instance_group_manager\" \"$1\" {\n    # instance_template - (Required) - The full URL to an instance template from which all new instances of this version will be created.\n    instance_template = \"\"\n\n    # name - (Required) - Version name.\n    name = \"\"\n\n    # initial_delay_sec - (Required) The number of seconds that the managed instance group waits before it applies autohealing policies to new instances or recently recreated instances. Between 0 and 3600.\n    initial_delay_sec = \"\"\n\n    # health_check - (Required) The health check resource that signals autohealing.\n    health_check = \"\"\n\n    # port - (Required) The port number.\n    port = \"\"\n\n    # name - (Required) The name of the port.\n    name = \"\"\n\n    # type - (Required) - The type of update. Valid values are `\"OPPORTUNISTIC\"`, `\"PROACTIVE\"`\n    type = \"\"\n\n    # minimal_action - (Required) - Minimal action to be taken on an instance. Valid values are `\"RESTART\"`, `\"REPLACE\"`\n    minimal_action = \"\"\n\n    # region - (Required) The region where the managed instance group resides.\n    region = \"\"\n\n    # name - (Required) The name of the instance group manager. Must be 1-63   characters long and comply with   [RFC1035](https://www.ietf.org/rfc/rfc1035.txt). Supported characters   include lowercase letters, numbers, and hyphens.\n    name = \"\"\n\n    # base_instance_name - (Required) The base instance name to use for   instances in this group. The value must be a valid   [RFC1035](https://www.ietf.org/rfc/rfc1035.txt) name. Supported characters   are lowercase letters, numbers, and hyphens (-). Instances are named by   appending a hyphen and a random four-character string to the base instance   name.\n    base_instance_name = \"\"\n\n    # instance_template - (Optional) The full URL to an instance template from   which all new instances will be created. Conflicts with `version` (see [documentation](https://cloud.google.com/compute/docs/instance-groups/updating-managed-instance-groups#relationship_between_instancetemplate_properties_for_a_managed_instance_group))\n    instance_template = \"\"\n\n    # version - (Optional) Application versions managed by this instance group. Each   version deals with a specific instance template, allowing canary release scenarios.   Conflicts with `instance_template`. Structure is documented below. Beware that   exactly one version must not specify a target size. It means that versions with   a target size will respect the setting, and the one without target size will   be applied to all remaining Instances (top level target_size - each version target_size).   This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    version = \"\"\n\n    # description - (Optional) An optional textual description of the instance   group manager.\n    description = \"\"\n\n    # named_port - (Optional) The named port configuration. See the section below   for details on configuration.\n    named_port = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # update_strategy - (Optional) (Optional, Default `\"NONE\"`) If the `instance_template`   resource is modified, a value of `\"NONE\"` will prevent any of the managed   instances from being restarted by Terraform. A value of `\"ROLLING_UPDATE\"`   is supported as a beta feature. A value of `\"ROLLING_UPDATE\"` requires   `rolling_update_policy` block to be set. This field is deprecated as in   `2.0.0` it has no functionality anymore. It will be removed then. This field   is only present in the `google` provider.\n    update_strategy = \"\"\n\n    # target_size - (Optional) The target number of running instances for this managed   instance group. This value should always be explicitly set unless this resource is attached to    an autoscaler, in which case it should never be set. Defaults to `0`.\n    target_size = \"\"\n\n    # target_pools - (Optional) The full URL of all target pools to which new   instances in the group are added. Updating the target pools attribute does   not affect existing instances.\n    target_pools = \"\"\n\n    # wait_for_instances - (Optional) Whether to wait for all instances to be created/updated before   returning. Note that if this is set to true and the operation does not succeed, Terraform will   continue trying until it times out.\n    wait_for_instances = \"\"\n\n    # auto_healing_policies - (Optional) The autohealing policies for this managed instance\n    auto_healing_policies = \"\"\n\n    # wait_for_instances - (Optional) Whether to wait for all instances to be created/updated before   returning. Note that if this is set to true and the operation does not succeed, Terraform will   continue trying until it times out.\n    wait_for_instances = \"\"\n\n    # rolling_update_policy - (Optional) The update policy for this managed instance group. Structure is documented below. For more information, see the [official documentation](https://cloud.google.com/compute/docs/instance-groups/updating-managed-instance-groups) and [API](https://cloud.google.com/compute/docs/reference/rest/beta/regionInstanceGroupManagers/patch)\n    rolling_update_policy = \"\"\n\n    # wait_for_instances - (Optional) Whether to wait for all instances to be created/updated before   returning. Note that if this is set to true and the operation does not succeed, Terraform will   continue trying until it times out.\n    wait_for_instances = \"\"\n\n    # distribution_policy_zones - (Optional) The distribution policy for this managed instance\n    distribution_policy_zones = \"\"\n\n    # wait_for_instances - (Optional) Whether to wait for all instances to be created/updated before   returning. Note that if this is set to true and the operation does not succeed, Terraform will   continue trying until it times out.\n    wait_for_instances = \"\"\n\n    # max_surge_fixed - (Optional) \n    max_surge_fixed = \"\"\n\n    # max_surge_percent - (Optional) \n    max_surge_percent = \"\"\n\n    # max_unavailable_fixed - (Optional) \n    max_unavailable_fixed = \"\"\n\n    # max_unavailable_percent - (Optional) \n    max_unavailable_percent = \"\"\n\n    # min_ready_sec - (Optional) \n    min_ready_sec = \"\"\n\n    # target_size - (Optional) - The number of instances calculated as a fixed number or a percentage depending on the settings. Structure is documented below.\n    target_size = \"\"\n\n    # fixed - (Optional) \n    fixed = \"\"\n\n    # percent - (Optional) \n    percent = \"\"\n\n    # Exported Attributes\n    # \"fingerprint\" - The fingerprint of the instance group manager.\n    # \"instance_group\" - The full URL of the instance group created by the manager.\n    # \"self_link\" - The URL of the created resource.\n}",
        "description": "The Google Compute Engine Regional Instance Group Manager API creates and manages pools\nof homogeneous Compute Engine virtual machine instances from a common instance\ntemplate. For more information, see [the official documentation](https://cloud.google.com/compute/docs/instance-groups/distributing-instances-with-regional-instance-groups)\nand [API](https://cloud.google.com/compute/docs/reference/latest/regionInstanceGroupManagers) ~> **Note:** Use [google_compute_instance_group_manager](/docs/providers/google/r/compute_instance_group_manager.html) to create a single-zone instance group manager.",
        "prefix": "google-compute-region_instance-group-manager"
    },
    "google-compute-router-interface": {
        "body": "resource \"google_compute_router_interface\" \"$1\" {\n    # vpn_tunnel - (Required) The name or resource link to the VPN tunnel this   interface will be linked to. Changing this forces a new interface to be created.\n    vpn_tunnel = \"\"\n\n    # router - (Required) The name of the router this interface will be attached to.   Changing this forces a new interface to be created.\n    router = \"\"\n\n    # name - (Required) A unique name for the interface, required by GCE. Changing   this forces a new interface to be created.\n    name = \"\"\n\n    # ip_range - (Optional) IP address and range of the interface. The IP range must be   in the RFC3927 link-local IP space. Changing this forces a new interface to be created.\n    ip_range = \"\"\n\n    # project - (Optional) The ID of the project in which this interface's router belongs. If it   is not provided, the provider project is used. Changing this forces a new interface to be created.\n    project = \"\"\n\n    # region - (Optional) The region this interface's router sits in. If not specified,   the project region will be used. Changing this forces a new interface to be   created.\n    region = \"\"\n\n    # Exported Attributes\n}",
        "description": "Manages a Cloud Router interface. For more information see\n[the official documentation](https://cloud.google.com/compute/docs/cloudrouter)\nand\n[API](https://cloud.google.com/compute/docs/reference/latest/routers).",
        "prefix": "google-compute-router-interface"
    },
    "google-compute-router-peer": {
        "body": "resource \"google_compute_router_peer\" \"$1\" {\n    # peer_asn - (Required) Peer BGP Autonomous System Number (ASN).   Changing this forces a new peer to be created.\n    peer_asn = \"\"\n\n    # peer_ip_address - (Required) IP address of the BGP interface outside Google Cloud.   Changing this forces a new peer to be created.\n    peer_ip_address = \"\"\n\n    # interface - (Required) The name of the interface the BGP peer is associated with.   Changing this forces a new peer to be created.\n    interface = \"\"\n\n    # router - (Required) The name of the router in which this BGP peer will be configured.   Changing this forces a new peer to be created.\n    router = \"\"\n\n    # name - (Required) A unique name for BGP peer, required by GCE. Changing   this forces a new peer to be created.\n    name = \"\"\n\n    # advertised_route_priority - (Optional) The priority of routes advertised to this BGP peer.   Changing this forces a new peer to be created.\n    advertised_route_priority = \"\"\n\n    # project - (Optional) The ID of the project in which this peer's router belongs. If it   is not provided, the provider project is used. Changing this forces a new peer to be created.\n    project = \"\"\n\n    # region - (Optional) The region this peer's router sits in. If not specified,   the project region will be used. Changing this forces a new peer to be   created.\n    region = \"\"\n\n    # Exported Attributes\n    # \"ip_address\" - IP address of the interface inside Google Cloud Platform.\n    # \"region\" - (Optional) The region this peer's router sits in. If not specified,   the project region will be used. Changing this forces a new peer to be   created.\n}",
        "description": "Manages a Cloud Router BGP peer. For more information see\n[the official documentation](https://cloud.google.com/compute/docs/cloudrouter)\nand\n[API](https://cloud.google.com/compute/docs/reference/latest/routers).",
        "prefix": "google-compute-router-peer"
    },
    "google-compute-security-policy": {
        "body": "resource \"google_compute_security_policy\" \"$1\" {\n    # versioned_expr - (Required) Predefined rule expression. Available options: SRC_IPS_V1: Must specify the corresponding `src_ip_ranges` field in `config`.\n    versioned_expr = \"\"\n\n    # src_ip_ranges - (Required) Set of IP addresses or ranges (IPV4 or IPV6) in CIDR notation\n    src_ip_ranges = \"\"\n\n    # versioned_expr - (Required) Predefined rule expression. Available options: SRC_IPS_V1: Must specify the corresponding `src_ip_ranges` field in `config`.\n    versioned_expr = \"\"\n\n    # versioned_expr - (Required) Predefined rule expression. Available options: SRC_IPS_V1: Must specify the corresponding `src_ip_ranges` field in `config`.\n    versioned_expr = \"\"\n\n    # config - (Required) The configuration options available when specifying `versioned_expr`.   Structure is documented below.\n    config = \"\"\n\n    # match - (Required) A match condition that incoming traffic is evaluated against.   If it evaluates to true, the corresponding `action` is enforced. Structure is documented below.\n    match = \"\"\n\n    # priority - (Required) An unique positive integer indicating the priority of evaluation for a rule.   Rules are evaluated from highest priority (lowest numerically) to lowest priority (highest numerically) in order.\n    priority = \"\"\n\n    # action - (Required) Action to take when `match` matches the request. Valid values: \"allow\" : allow access to target\n    action = \"\"\n\n    # action - (Required) Action to take when `match` matches the request. Valid values: \"allow\" : allow access to target\n    action = \"\"\n\n    # action - (Required) Action to take when `match` matches the request. Valid values: \"allow\" : allow access to target\n    action = \"\"\n\n    # name - (Required) The name of the security policy.\n    name = \"\"\n\n    # description - (Optional) An optional description of this security policy. Max size is 2048.\n    description = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # rule - (Optional) The set of rules that belong to this policy. There must always be a default   rule (rule with priority 2147483647 and match \"\\*\"). If no rules are provided when creating a   security policy, a default rule with action \"allow\" will be added. Structure is documented below.\n    rule = \"\"\n\n    # description - (Optional) An optional description of this rule. Max size is 64.\n    description = \"\"\n\n    # preview - (Optional) When set to true, the `action` specified above is not enforced.   Stackdriver logs for requests that trigger a preview action are annotated as such.\n    preview = \"\"\n\n    # Exported Attributes\n    # \"fingerprint\" - Fingerprint of this resource.\n    # \"self_link\" - The URI of the created resource.\n}",
        "description": "A Security Policy defines an IP blacklist or whitelist that protects load balanced Google Cloud services by denying or permitting traffic from specified IP ranges. For more information\nsee the [official documentation](https://cloud.google.com/armor/docs/configure-security-policies)\nand the [API](https://cloud.google.com/compute/docs/reference/rest/beta/securityPolicies).",
        "prefix": "google-compute-security-policy"
    },
    "google-compute-shared-vpc-host-project": {
        "body": "resource \"google_compute_shared_vpc_host_project\" \"$1\" {\n    # project - (Required) The ID of the project that will serve as a Shared VPC host project\n    project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Enables the Google Compute Engine\n[Shared VPC](https://cloud.google.com/compute/docs/shared-vpc)\nfeature for a project, assigning it as a Shared VPC host project. For more information, see,\n[the Project API documentation](https://cloud.google.com/compute/docs/reference/latest/projects),\nwhere the Shared VPC feature is referred to by its former name \"XPN\".",
        "prefix": "google-compute-shared-vpc-host-project"
    },
    "google-compute-shared-vpc-service-project": {
        "body": "resource \"google_compute_shared_vpc_service_project\" \"$1\" {\n    # service_project - (Required) The ID of the project that will serve as a Shared VPC service project.\n    service_project = \"\"\n\n    # host_project - (Required) The ID of a host project to associate.\n    host_project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Enables the Google Compute Engine\n[Shared VPC](https://cloud.google.com/compute/docs/shared-vpc)\nfeature for a project, assigning it as a Shared VPC service project associated\nwith a given host project. For more information, see,\n[the Project API documentation](https://cloud.google.com/compute/docs/reference/latest/projects),\nwhere the Shared VPC feature is referred to by its former name \"XPN\".",
        "prefix": "google-compute-shared-vpc-service-project"
    },
    "google-compute-subnetwork-iam": {
        "body": "resource \"google_compute_subnetwork_iam\" \"$1\" {\n    # role - (Required) The role that should be applied. Only one   `google_compute_subnetwork_iam_binding` can be used per role. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # subnetwork - (Required) The name of the subnetwork.\n    subnetwork = \"\"\n\n    # policy_data - (Optional) (Required only by `google_compute_subnetwork_iam_policy`) The policy data generated by a `google_iam_policy` data source.\n    policy_data = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) The region of the subnetwork. If   unspecified, this defaults to the region configured in the provider.\n    region = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the subnetwork's IAM policy.\n    # \"region\" - (Optional) The region of the subnetwork. If   unspecified, this defaults to the region configured in the provider.\n}",
        "description": "~> **Warning:** These resources are in beta, and should be used with the terraform-provider-google-beta provider.\nSee [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta resources. Three different resources help you manage your IAM policy for GCE subnetwork. Each of these resources serves a different use case: `google_compute_subnetwork_iam_policy`: Authoritative. Sets the IAM policy for the subnetwork and replaces any existing policy already attached.  `google_compute_subnetwork_iam_binding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the subnetwork are preserved.  `google_compute_subnetwork_iam_member`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the subnetwork are preserved.  ~> **Note:** `google_compute_subnetwork_iam_policy` **cannot** be used in conjunction with `google_compute_subnetwork_iam_binding` and `google_compute_subnetwork_iam_member` or they will fight over what your policy should be. ~> **Note:** `google_compute_subnetwork_iam_binding` resources **can be** used in conjunction with `google_compute_subnetwork_iam_member` resources **only if** they do not grant privilege to the same role.",
        "prefix": "google-compute-subnetwork-iam"
    },
    "google-compute-target-pool": {
        "body": "resource \"google_compute_target_pool\" \"$1\" {\n    # name - (Required) A unique name for the resource, required by GCE. Changing\n    name = \"\"\n\n    # backup_pool - (Optional) URL to the backup target pool. Must also set   failover\\_ratio.\n    backup_pool = \"\"\n\n    # description - (Optional) Textual description field.\n    description = \"\"\n\n    # failover_ratio - (Optional) Ratio (0 to 1) of failed nodes before using the   backup pool (which must also be set).\n    failover_ratio = \"\"\n\n    # health_checks - (Optional) List of zero or one health check name or self_link. Only   legacy `google_compute_http_health_check` is supported.\n    health_checks = \"\"\n\n    # instances - (Optional) List of instances in the pool. They can be given as   URLs, or in the form of \"zone/name\". Note that the instances need not exist   at the time of target pool creation, so there is no need to use the   Terraform interpolators to create a dependency on the instances from the   target pool.\n    instances = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) Where the target pool resides. Defaults to project   region.\n    region = \"\"\n\n    # session_affinity - (Optional) How to distribute load. Options are \"NONE\" (no   affinity). \"CLIENT\\_IP\" (hash of the source/dest addresses / ports), and   \"CLIENT\\_IP\\_PROTO\" also includes the protocol (default \"NONE\").\n    session_affinity = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The URI of the created resource.\n    # \"session_affinity\" - (Optional) How to distribute load. Options are \"NONE\" (no   affinity). \"CLIENT\\_IP\" (hash of the source/dest addresses / ports), and   \"CLIENT\\_IP\\_PROTO\" also includes the protocol (default \"NONE\").\n}",
        "description": "Manages a Target Pool within GCE. This is a collection of instances used as\ntarget of a network load balancer (Forwarding Rule). For more information see\n[the official\ndocumentation](https://cloud.google.com/compute/docs/load-balancing/network/target-pools)\nand [API](https://cloud.google.com/compute/docs/reference/latest/targetPools).",
        "prefix": "google-compute-target-pool"
    },
    "google-compute-url-map": {
        "body": "resource \"google_compute_url_map\" \"$1\" {\n    # path - (Required) The path component of the URL being tested.\n    path = \"\"\n\n    # host - (Required) The host component of the URL being tested.\n    host = \"\"\n\n    # service - (Required) The backend service or backend bucket link that should be matched by this test.\n    service = \"\"\n\n    # service - (Required) The backend service or backend bucket to use if any of the given paths match.\n    service = \"\"\n\n    # paths - (Required) The list of [paths](https://cloud.google.com/compute/docs/reference/latest/urlMaps#pathMatchers.pathRules.paths)   to match against.\n    paths = \"\"\n\n    # default_service - (Required) The backend service or backend bucket to use if none of the given paths match.\n    default_service = \"\"\n\n    # name - (Required) The name of the `path_matcher` resource.\n    name = \"\"\n\n    # path_matcher - (Required) The name of the `path_matcher` to apply this host rule to.\n    path_matcher = \"\"\n\n    # hosts - (Required) - The list of [host patterns](https://cloud.google.com/compute/docs/reference/latest/urlMaps#hostRules.hosts) to match.\n    hosts = \"\"\n\n    # name - (Required) A unique name for the resource, required by GCE.   Changing this forces a new resource to be created.\n    name = \"\"\n\n    # default_service - (Required) The backend service or backend bucket to use when none of the given rules match.\n    default_service = \"\"\n\n    # description - (Optional) A brief description of this resource.\n    description = \"\"\n\n    # host_rule - (Optional) A list of host rules. Multiple blocks of this type are permitted. Structure is documented below.\n    host_rule = \"\"\n\n    # path_matcher - (Optional) A list of paths to match. Structure is documented below.\n    path_matcher = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # test - (Optional) The test to perform.  Multiple blocks of this type are permitted. Structure is documented below.\n    test = \"\"\n\n    # description - (Optional) An optional description of the host rule.\n    description = \"\"\n\n    # description - (Optional) An optional description of the host rule.\n    description = \"\"\n\n    # path_rule - (Optional)  A list of path rules. Multiple blocks of this type are permitted. Structure is documented below.\n    path_rule = \"\"\n\n    # description - (Optional) An optional description of this test.\n    description = \"\"\n\n    # Exported Attributes\n    # \"fingerprint\" - The unique fingerprint for this resource.\n    # \"map_id\" - The GCE assigned ID of the resource.\n    # \"self_link\" - The URI of the created resource.\n}",
        "description": "Manages a URL Map resource within GCE. For more information see\n[the official documentation](https://cloud.google.com/compute/docs/load-balancing/http/url-map)\nand\n[API](https://cloud.google.com/compute/docs/reference/latest/urlMaps).",
        "prefix": "google-compute-url-map"
    },
    "google-container-cluster": {
        "body": "resource \"google_container_cluster\" \"$1\" {\n    # effect - (Required) Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.\n    effect = \"\"\n\n    # effect - (Required) Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.\n    effect = \"\"\n\n    # effect - (Required) Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.\n    effect = \"\"\n\n    # effect - (Required) Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.\n    effect = \"\"\n\n    # node_metadata - (Required) How to expose the node metadata to the workload running on the node.\n    node_metadata = \"\"\n\n    # effect - (Required) Effect for taint. Accepted values are `NO_SCHEDULE`, `PREFER_NO_SCHEDULE`, and `NO_EXECUTE`.\n    effect = \"\"\n\n    # value - (Required) Value for taint.\n    value = \"\"\n\n    # key - (Required) Key for taint.\n    key = \"\"\n\n    # count - (Required) - The number of the guest accelerator cards exposed to this instance.\n    count = \"\"\n\n    # enabled - (Required) - Enable the PodSecurityPolicy controller for this cluster.\n    enabled = \"\"\n\n    # count - (Required) - The number of the guest accelerator cards exposed to this instance.\n    count = \"\"\n\n    # type - (Required) - The accelerator type resource to expose to this instance. E.g. `nvidia-tesla-k80`.\n    type = \"\"\n\n    # username - (Required) The username to use for HTTP basic authentication when accessing   the Kubernetes master endpoint\n    username = \"\"\n\n    # password - (Required) The password to use for HTTP basic authentication when accessing   the Kubernetes master endpoint\n    password = \"\"\n\n    # daily_maintenance_window - (Required) Time window specified for daily maintenance operations.\n    daily_maintenance_window = \"\"\n\n    # resource_type - (Required) See [the docs](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning)\n    resource_type = \"\"\n\n    # enabled - (Required) Whether cluster autoscaling (also called autoprovisioning) is\n    enabled = \"\"\n\n    # name - (Required) The name of the cluster, unique within the project and\n    name = \"\"\n\n    # zone - (Optional) The zone that the master and the number of nodes specified   in `initial_node_count` should be created in. Only one of `zone` and `region`   may be set. If neither zone nor region are set, the provider zone is used.\n    zone = \"\"\n\n    # region - (Optional)   The region to create the cluster in, for   [Regional Clusters](https://cloud.google.com/kubernetes-engine/docs/concepts/multi-zone-and-regional-clusters#regional).   In a Regional Cluster, the number of nodes specified in `initial_node_count` is    created in three zones of the region (this can be changed by setting `additional_zones`).   This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    region = \"\"\n\n    # additional_zones - (Optional) The list of additional Google Compute Engine   locations in which the cluster's nodes should be located. If additional zones are   configured, the number of nodes specified in `initial_node_count` is created in   all specified zones.\n    additional_zones = \"\"\n\n    # addons_config - (Optional) The configuration for addons supported by GKE.   Structure is documented below.\n    addons_config = \"\"\n\n    # cluster_autoscaling - (Optional) (Optional, [Beta](https://terraform.io/docs/providers/google/provider_versions.html))   Configuration for cluster autoscaling (also called autoprovisioning), as described in   [the docs](https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning).   Structure is documented below.\n    cluster_autoscaling = \"\"\n\n    # description - (Optional) Description of the cluster.\n    description = \"\"\n\n    # enable_binary_authorization - (Optional) Enable Binary Authorization for this cluster.   If enabled, all container images will be validated by Google Binary Authorization.   This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    enable_binary_authorization = \"\"\n\n    # enable_kubernetes_alpha - (Optional) Whether to enable Kubernetes Alpha features for   this cluster. Note that when this option is enabled, the cluster cannot be upgraded   and will be automatically deleted after 30 days.\n    enable_kubernetes_alpha = \"\"\n\n    # enable_tpu - (Optional) Whether to enable Cloud TPU resources in this cluster.   See the [official documentation](https://cloud.google.com/tpu/docs/kubernetes-engine-setup).   This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    enable_tpu = \"\"\n\n    # enable_legacy_abac - (Optional) Whether the ABAC authorizer is enabled for this cluster.   When enabled, identities in the system, including service accounts, nodes, and controllers,   will have statically granted permissions beyond those provided by the RBAC configuration or IAM.   Defaults to `false`\n    enable_legacy_abac = \"\"\n\n    # initial_node_count - (Optional) The number of nodes to create in this   cluster (not including the Kubernetes master). Must be set if `node_pool` is not set.\n    initial_node_count = \"\"\n\n    # ip_allocation_policy - (Optional) Configuration for cluster IP allocation. As of now, only pre-allocated subnetworks (custom type with secondary ranges) are supported.   This will activate IP aliases. See the [official documentation](https://cloud.google.com/kubernetes-engine/docs/how-to/ip-aliases)   Structure is documented below.\n    ip_allocation_policy = \"\"\n\n    # logging_service - (Optional) The logging service that the cluster should   write logs to. Available options include `logging.googleapis.com`,   `logging.googleapis.com/kubernetes` (beta), and `none`. Defaults to `logging.googleapis.com`\n    logging_service = \"\"\n\n    # maintenance_policy - (Optional) The maintenance policy to use for the cluster. Structure is   documented below.\n    maintenance_policy = \"\"\n\n    # master_auth - (Optional) The authentication information for accessing the   Kubernetes master. Structure is documented below.\n    master_auth = \"\"\n\n    # master_authorized_networks_config - (Optional) The desired configuration options   for master authorized networks. Omit the nested `cidr_blocks` attribute to disallow   external access (except the cluster node IPs, which GKE automatically whitelists).\n    master_authorized_networks_config = \"\"\n\n    # min_master_version - (Optional) The minimum version of the master. GKE   will auto-update the master to new versions, so this does not guarantee the   current master version--use the read-only `master_version` field to obtain that.   If unset, the cluster's version will be set by GKE to the version of the most recent   official release (which is not necessarily the latest version).\n    min_master_version = \"\"\n\n    # monitoring_service - (Optional) The monitoring service that the cluster   should write metrics to.   Automatically send metrics from pods in the cluster to the Google Cloud Monitoring API.   VM metrics will be collected by Google Compute Engine regardless of this setting   Available options include   `monitoring.googleapis.com`, `monitoring.googleapis.com/kubernetes` (beta) and `none`.   Defaults to `monitoring.googleapis.com`\n    monitoring_service = \"\"\n\n    # network - (Optional) The name or self_link of the Google Compute Engine   network to which the cluster is connected. For Shared VPC, set this to the self link of the   shared network.\n    network = \"\"\n\n    # network_policy - (Optional) Configuration options for the   [NetworkPolicy](https://kubernetes.io/docs/concepts/services-networking/networkpolicies/)   feature. Structure is documented below.\n    network_policy = \"\"\n\n    # node_config - (Optional) Parameters used in creating the cluster's nodes.   Structure is documented below.\n    node_config = \"\"\n\n    # node_pool - (Optional) List of node pools associated with this cluster.   See [google_container_node_pool](container_node_pool.html) for schema.   **Warning:** node pools defined inside a cluster can't be changed (or added/removed) after   cluster creation without deleting and recreating the entire cluster. Unless you absolutely need the ability   to say \"these are the _only_ node pools associated with this cluster\", use the   [google_container_node_pool](container_node_pool.html) resource instead of this property.\n    node_pool = \"\"\n\n    # node_version - (Optional) The Kubernetes version on the nodes. Must either be unset   or set to the same value as `min_master_version` on create. Defaults to the default   version set by GKE which is not necessarily the latest version.\n    node_version = \"\"\n\n    # pod_security_policy_config - (Optional) Configuration for the   [PodSecurityPolicy](https://cloud.google.com/kubernetes-engine/docs/how-to/pod-security-policies) feature.   Structure is documented below.   This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    pod_security_policy_config = \"\"\n\n    # private_cluster_config - (Optional) A set of options for creating   a private cluster. Structure is documented below.   This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    private_cluster_config = \"\"\n\n    # private_cluster - (Optional) (Optional, Deprecated) If true, a   [private cluster](https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters) will be created, meaning   nodes do not get public IP addresses. It is mandatory to specify `master_ipv4_cidr_block` and    `ip_allocation_policy` with this option.   This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.   This field is deprecated, use `private_cluster_config.enable_private_nodes` instead.\n    private_cluster = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # remove_default_node_pool - (Optional) If true, deletes the default node pool upon cluster creation.\n    remove_default_node_pool = \"\"\n\n    # resource_labels - (Optional) The GCE resource labels (a map of key/value pairs) to be applied to the cluster.\n    resource_labels = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine subnetwork in   which the cluster's instances are launched.\n    subnetwork = \"\"\n\n    # horizontal_pod_autoscaling - (Optional) The status of the Horizontal Pod Autoscaling\n    horizontal_pod_autoscaling = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine subnetwork in   which the cluster's instances are launched.\n    subnetwork = \"\"\n\n    # http_load_balancing - (Optional) The status of the HTTP (L7) load balancing\n    http_load_balancing = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine subnetwork in   which the cluster's instances are launched.\n    subnetwork = \"\"\n\n    # kubernetes_dashboard - (Optional) The status of the Kubernetes Dashboard\n    kubernetes_dashboard = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine subnetwork in   which the cluster's instances are launched.\n    subnetwork = \"\"\n\n    # network_policy_config - (Optional) Whether we should enable the network policy addon\n    network_policy_config = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine subnetwork in   which the cluster's instances are launched.\n    subnetwork = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine subnetwork in   which the cluster's instances are launched.\n    subnetwork = \"\"\n\n    # resource_limits - (Optional) A list of limits on the autoprovisioning.\n    resource_limits = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine subnetwork in   which the cluster's instances are launched.\n    subnetwork = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine subnetwork in   which the cluster's instances are launched.\n    subnetwork = \"\"\n\n    # minimum - (Optional) The minimum value for the resource type specified.\n    minimum = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine subnetwork in   which the cluster's instances are launched.\n    subnetwork = \"\"\n\n    # maximum - (Optional) The maximum value for the resource type specified.\n    maximum = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine subnetwork in   which the cluster's instances are launched.\n    subnetwork = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine subnetwork in   which the cluster's instances are launched.\n    subnetwork = \"\"\n\n    # cluster_secondary_range_name - (Optional) The name of the secondary range to be   used as for the cluster CIDR block. The secondary range will be used for pod IP   addresses. This must be an existing secondary range associated with the cluster   subnetwork.\n    cluster_secondary_range_name = \"\"\n\n    # services_secondary_range_name - (Optional) The name of the secondary range to be   used as for the services CIDR block.  The secondary range will be used for service   ClusterIPs. This must be an existing secondary range associated with the cluster   subnetwork.\n    services_secondary_range_name = \"\"\n\n    # create_subnetwork - (Optional) Whether a new subnetwork will be created automatically for the cluster.\n    create_subnetwork = \"\"\n\n    # subnetwork_name - (Optional) A custom subnetwork name to be used if create_subnetwork is true.   If this field is empty, then an automatic name will be chosen for the new subnetwork.\n    subnetwork_name = \"\"\n\n    # client_certificate_config - (Optional) Whether client certificate authorization is enabled for this cluster.  For example:\n    client_certificate_config = \"\"\n\n    # cidr_blocks - (Optional) Defines up to 20 external networks that can access\n    cidr_blocks = \"\"\n\n    # client_certificate_config - (Optional) Whether client certificate authorization is enabled for this cluster.  For example:\n    client_certificate_config = \"\"\n\n    # cidr_block - (Optional) External network that can access Kubernetes master through HTTPS.   Must be specified in CIDR notation.\n    cidr_block = \"\"\n\n    # display_name - (Optional) Field for users to identify CIDR blocks.\n    display_name = \"\"\n\n    # provider - (Optional) The selected network policy provider. Defaults to PROVIDER_UNSPECIFIED.\n    provider = \"\"\n\n    # enabled - (Optional) Whether network policy is enabled on the cluster. Defaults to false.\n    enabled = \"\"\n\n    # disk_size_gb - (Optional) Size of the disk attached to each node, specified   in GB. The smallest allowed disk size is 10GB. Defaults to 100GB.\n    disk_size_gb = \"\"\n\n    # disk_type - (Optional) Type of the disk attached to each node   (e.g. 'pd-standard' or 'pd-ssd'). If unspecified, the default disk type is 'pd-standard'\n    disk_type = \"\"\n\n    # guest_accelerator - (Optional) List of the type and count of accelerator cards attached to the instance.   Structure documented below.\n    guest_accelerator = \"\"\n\n    # image_type - (Optional) The image type to use for this node. Note that changing the image type   will delete and recreate all nodes in the node pool.\n    image_type = \"\"\n\n    # labels - (Optional) The Kubernetes labels (key/value pairs) to be applied to each node.\n    labels = \"\"\n\n    # local_ssd_count - (Optional) The amount of local SSD disks that will be   attached to each cluster node. Defaults to 0.\n    local_ssd_count = \"\"\n\n    # machine_type - (Optional) The name of a Google Compute Engine machine type.   Defaults to `n1-standard-1`. To create a custom machine type, value should be set as specified   [here](https://cloud.google.com/compute/docs/reference/latest/instances#machineType).\n    machine_type = \"\"\n\n    # metadata - (Optional) The metadata key/value pairs assigned to instances in   the cluster.\n    metadata = \"\"\n\n    # min_cpu_platform - (Optional) Minimum CPU platform to be used by this instance.   The instance may be scheduled on the specified or newer CPU platform. Applicable   values are the friendly names of CPU platforms, such as `Intel Haswell`. See the   [official documentation](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)   for more information.\n    min_cpu_platform = \"\"\n\n    # oauth_scopes - (Optional) The set of Google API scopes to be made available   on all of the node VMs under the \"default\" service account. These can be   either FQDNs, or scope aliases. The following scopes are necessary to ensure   the correct functioning of the cluster: `compute-rw` (`https://www.googleapis.com/auth/compute`)\n    oauth_scopes = \"\"\n\n    # oauth_scopes - (Optional) The set of Google API scopes to be made available   on all of the node VMs under the \"default\" service account. These can be   either FQDNs, or scope aliases. The following scopes are necessary to ensure   the correct functioning of the cluster: `compute-rw` (`https://www.googleapis.com/auth/compute`)\n    oauth_scopes = \"\"\n\n    # oauth_scopes - (Optional) The set of Google API scopes to be made available   on all of the node VMs under the \"default\" service account. These can be   either FQDNs, or scope aliases. The following scopes are necessary to ensure   the correct functioning of the cluster: `compute-rw` (`https://www.googleapis.com/auth/compute`)\n    oauth_scopes = \"\"\n\n    # monitoring - (Optional) `monitoring` (`https://www.googleapis.com/auth/monitoring`),\n    monitoring = \"\"\n\n    # oauth_scopes - (Optional) The set of Google API scopes to be made available   on all of the node VMs under the \"default\" service account. These can be   either FQDNs, or scope aliases. The following scopes are necessary to ensure   the correct functioning of the cluster: `compute-rw` (`https://www.googleapis.com/auth/compute`)\n    oauth_scopes = \"\"\n\n    # oauth_scopes - (Optional) The set of Google API scopes to be made available   on all of the node VMs under the \"default\" service account. These can be   either FQDNs, or scope aliases. The following scopes are necessary to ensure   the correct functioning of the cluster: `compute-rw` (`https://www.googleapis.com/auth/compute`)\n    oauth_scopes = \"\"\n\n    # preemptible - (Optional) A boolean that represents whether or not the underlying node VMs   are preemptible. See the [official documentation](https://cloud.google.com/container-engine/docs/preemptible-vm)   for more information. Defaults to false.\n    preemptible = \"\"\n\n    # service_account - (Optional) The service account to be used by the Node VMs.   If not specified, the \"default\" service account is used.\n    service_account = \"\"\n\n    # tags - (Optional) The list of instance tags applied to all nodes. Tags are used to identify   valid sources or targets for network firewalls.\n    tags = \"\"\n\n    # taint - (Optional) List of   [kubernetes taints](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)   to apply to each node. Structure is documented below. This property is in beta, and should be   used with the terraform-provider-google-beta provider. See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html)   for more details on beta fields.\n    taint = \"\"\n\n    # workload_metadata_config - (Optional) Metadata configuration to expose to workloads on the node pool.   Structure is documented below. This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    workload_metadata_config = \"\"\n\n    # enable_private_endpoint - (Optional) - Whether the master's internal IP address is used as the cluster endpoint.\n    enable_private_endpoint = \"\"\n\n    # enable_private_nodes - (Optional) - Whether nodes have internal IP addresses only. If enabled, all nodes are given only RFC 1918 private   addresses and communicate with the master via private networking.\n    enable_private_nodes = \"\"\n\n    # private_endpoint - (Optional) The internal IP address of this cluster's master endpoint.\n    private_endpoint = \"\"\n\n    # public_endpoint - (Optional) The external IP address of this cluster's master endpoint.\n    public_endpoint = \"\"\n\n    # Exported Attributes\n    # \"endpoint\" - The IP address of this cluster's Kubernetes master.\n    # \"instance_group_urls\" - List of instance group URLs which have been assigned   to the cluster.\n    # \"maintenance_policy.0.daily_maintenance_window.0.duration\" - Duration of the time window, automatically chosen to be   smallest possible in the given scenario.   Duration will be in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format \"PTnHnMnS\".\n    # \"master_auth.0.client_certificate\" - Base64 encoded public certificate   used by clients to authenticate to the cluster endpoint.\n    # \"master_auth.0.client_key\" - Base64 encoded private key used by clients   to authenticate to the cluster endpoint.\n    # \"master_auth.0.cluster_ca_certificate\" - Base64 encoded public certificate   that is the root of trust for the cluster.\n    # \"master_version\" - The current version of the master in the cluster. This may   be different than the \"min_master_version\" set in the config if the master   has been updated by GKE.\n}",
        "description": "Creates a Google Kubernetes Engine (GKE) cluster. For more information see\n[the official documentation](https://cloud.google.com/container-engine/docs/clusters)\nand\n[API](https://cloud.google.com/container-engine/reference/rest/v1/projects.zones.clusters). ~> **Note:** All arguments including the username and password will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](/docs/state/sensitive-data.html).",
        "prefix": "google-container-cluster"
    },
    "google-container-node-pool": {
        "body": "resource \"google_container_node_pool\" \"$1\" {\n    # max_node_count - (Required) Maximum number of nodes in the NodePool. Must be >= min_node_count.\n    max_node_count = \"\"\n\n    # min_node_count - (Required) Minimum number of nodes in the NodePool. Must be >=1 and   <= `max_node_count`.\n    min_node_count = \"\"\n\n    # cluster - (Required) The cluster to create the node pool for.  Cluster must be present in `zone` provided for zonal clusters.\n    cluster = \"\"\n\n    # zone - (Optional) The zone in which the cluster resides.\n    zone = \"\"\n\n    # region - (Optional) The region in which the cluster resides (for regional clusters).   This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    region = \"\"\n\n    # autoscaling - (Optional) Configuration required by cluster autoscaler to adjust   the size of the node pool to the current cluster usage. Structure is documented below.\n    autoscaling = \"\"\n\n    # initial_node_count - (Optional) The initial node count for the pool. Changing this will force   recreation of the resource.\n    initial_node_count = \"\"\n\n    # management - (Optional) Node management configuration, wherein auto-repair and   auto-upgrade is configured. Structure is documented below.\n    management = \"\"\n\n    # max_pods_per_node - (Optional) The maximum number of pods per node in this node pool.   Note that this does not work on node pools which are \"route-based\" - that is, node   pools belonging to clusters that do not have IP Aliasing enabled.   This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    max_pods_per_node = \"\"\n\n    # name - (Optional) The name of the node pool. If left blank, Terraform will   auto-generate a unique name.\n    name = \"\"\n\n    # name_prefix - (Optional) (Deprecated, Optional) Creates a unique name for the node pool beginning   with the specified prefix. Conflicts with `name`.\n    name_prefix = \"\"\n\n    # node_config - (Optional) The node configuration of the pool. See   [google_container_cluster](container_cluster.html) for schema.\n    node_config = \"\"\n\n    # node_count - (Optional) The number of nodes per instance group. This field can be used to   update the number of nodes per instance group but should not be used alongside `autoscaling`.\n    node_count = \"\"\n\n    # project - (Optional) The ID of the project in which to create the node pool. If blank,   the provider-configured project will be used.\n    project = \"\"\n\n    # version - (Optional) The Kubernetes version for the nodes in this pool. Note that if this field   and `auto_upgrade` are both specified, they will fight each other for what the node version should   be, so setting both is highly discouraged.\n    version = \"\"\n\n    # auto_repair - (Optional) Whether the nodes will be automatically repaired.\n    auto_repair = \"\"\n\n    # auto_upgrade - (Optional) Whether the nodes will be automatically upgraded.\n    auto_upgrade = \"\"\n\n    # Exported Attributes\n}",
        "description": "Manages a Node Pool resource within GKE. For more information see\n[the official documentation](https://cloud.google.com/container-engine/docs/node-pools)\nand\n[API](https://cloud.google.com/container-engine/reference/rest/v1/projects.zones.clusters.nodePools).",
        "prefix": "google-container-node-pool"
    },
    "google-dataflow-job": {
        "body": "resource \"google_dataflow_job\" \"$1\" {\n    # temp_gcs_location - (Required) A writeable location on GCS for the Dataflow job to dump its temporary data.\n    temp_gcs_location = \"\"\n\n    # template_gcs_path - (Required) The GCS path to the Dataflow job template.\n    template_gcs_path = \"\"\n\n    # name - (Required) A unique name for the resource, required by Dataflow.\n    name = \"\"\n\n    # parameters - (Optional) Key/Value pairs to be passed to the Dataflow job (as used in the template).\n    parameters = \"\"\n\n    # max_workers - (Optional) The number of workers permitted to work on the job.  More workers may improve processing speed at additional cost.\n    max_workers = \"\"\n\n    # on_delete - (Optional) One of \"drain\" or \"cancel\".  Specifies behavior of deletion during `terraform destroy`.  See above note.\n    on_delete = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it is not provided, the provider project is used.\n    project = \"\"\n\n    # zone - (Optional) The zone in which the created job should run. If it is not provided, the provider zone is used.\n    zone = \"\"\n\n    # Exported Attributes\n    # \"state\" - The current state of the resource, selected from the [JobState enum](https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.jobs#Job.JobState)\n}",
        "description": "Creates a job on Dataflow, which is an implementation of Apache Beam running on Google Compute Engine. For more information see\nthe official documentation for\n[Beam](https://beam.apache.org) and [Dataflow](https://cloud.google.com/dataflow/).",
        "prefix": "google-dataflow-job"
    },
    "google-dataproc-cluster": {
        "body": "resource \"google_dataproc_cluster\" \"$1\" {\n    # script - (Required) The script to be executed during initialization of the cluster.  The script must be a GCS file with a gs:// prefix.\n    script = \"\"\n\n    # name - (Required) The name of the cluster, unique within the project and\n    name = \"\"\n\n    # project - (Optional) The ID of the project in which the `cluster` will exist. If it \tis not provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) The region in which the cluster and associated nodes will be created in.  Defaults to `global`.\n    region = \"\"\n\n    # labels - (Optional) (Optional, Computed) The list of labels (key/value pairs) to be applied to  instances in the cluster. GCP generates some itself including `goog-dataproc-cluster-name`  which is the name of the cluster.\n    labels = \"\"\n\n    # cluster_config - (Optional) Allows you to configure various aspects of the cluster.  Structure defined below.\n    cluster_config = \"\"\n\n    # staging_bucket - (Optional) The Cloud Storage staging bucket used to stage files,  such as Hadoop jars, between client machines and the cluster.  Note: If you don't explicitly specify a `staging_bucket`  then GCP will auto create / assign one for you. However, you are not guaranteed  an auto generated bucket which is solely dedicated to your cluster; it may be shared  with other clusters in the same region/zone also choosing to use the auto generation  option.\n    staging_bucket = \"\"\n\n    # delete_autogen_bucket - (Optional) `delete_autogen_bucket` (Optional, Deprecated) If this is set to true, upon destroying the cluster,  if no explicit `staging_bucket` was specified (i.e. an auto generated bucket was relied  upon) then this auto generated bucket will also be deleted as part of the cluster destroy.  By default this is set to false. This value is deprecated: autogenerated buckets are shared by  all clusters in the same region, so deleting the bucket could adversely harm other dataproc clusters.\n    delete_autogen_bucket = \"\"\n\n    # gce_cluster_config - (Optional) Common config settings for resources of Google Compute Engine cluster  instances, applicable to all instances in the cluster. Structure defined below.\n    gce_cluster_config = \"\"\n\n    # master_config - (Optional) The Google Compute Engine config settings for the master instances  in a cluster.. Structure defined below.\n    master_config = \"\"\n\n    # worker_config - (Optional) The Google Compute Engine config settings for the worker instances  in a cluster.. Structure defined below.\n    worker_config = \"\"\n\n    # preemptible_worker_config - (Optional) The Google Compute Engine config settings for the additional (aka  preemptible) instancesin a cluster. Structure defined below.\n    preemptible_worker_config = \"\"\n\n    # software_config - (Optional) The config settings for software inside the cluster.  Structure defined below.\n    software_config = \"\"\n\n    # initialization_action - (Optional) Commands to execute on each node after config is completed.  You can specify multiple versions of these. Structure defined below.\n    initialization_action = \"\"\n\n    # zone - (Optional) (Optional, Computed) The GCP zone where your data is stored and used (i.e. where \tthe master and the worker nodes will be created in). If `region` is set to 'global' (default) \tthen `zone` is mandatory, otherwise GCP is able to make use of [Auto Zone Placement](https://cloud.google.com/dataproc/docs/concepts/auto-zone) \tto determine this automatically for you. \tNote: This setting additionally determines and restricts \twhich computing resources are available for use with other configs such as \t`cluster_config.master_config.machine_type` and `cluster_config.worker_config.machine_type`.\n    zone = \"\"\n\n    # network - (Optional) (Optional, Computed) The name or self_link of the Google Compute Engine \tnetwork to the cluster will be part of. Conflicts with `subnetwork`. \tIf neither is specified, this defaults to the \"default\" network.\n    network = \"\"\n\n    # subnetwork - (Optional) The name or self_link of the Google Compute Engine  subnetwork the cluster will be part of. Conflicts with `network`.\n    subnetwork = \"\"\n\n    # service_account - (Optional) The service account to be used by the Node VMs. \tIf not specified, the \"default\" service account is used.\n    service_account = \"\"\n\n    # service_account_scopes - (Optional) (Optional, Computed) The set of Google API scopes to be made available \ton all of the node VMs under the `service_account` specified. These can be \teither FQDNs, or scope aliases. The following scopes are necessary to ensure \tthe correct functioning of the cluster: `useraccounts-ro` (`https://www.googleapis.com/auth/cloud.useraccounts.readonly`)\n    service_account_scopes = \"\"\n\n    # service_account_scopes - (Optional) (Optional, Computed) The set of Google API scopes to be made available \ton all of the node VMs under the `service_account` specified. These can be \teither FQDNs, or scope aliases. The following scopes are necessary to ensure \tthe correct functioning of the cluster: `useraccounts-ro` (`https://www.googleapis.com/auth/cloud.useraccounts.readonly`)\n    service_account_scopes = \"\"\n\n    # service_account_scopes - (Optional) (Optional, Computed) The set of Google API scopes to be made available \ton all of the node VMs under the `service_account` specified. These can be \teither FQDNs, or scope aliases. The following scopes are necessary to ensure \tthe correct functioning of the cluster: `useraccounts-ro` (`https://www.googleapis.com/auth/cloud.useraccounts.readonly`)\n    service_account_scopes = \"\"\n\n    # service_account_scopes - (Optional) (Optional, Computed) The set of Google API scopes to be made available \ton all of the node VMs under the `service_account` specified. These can be \teither FQDNs, or scope aliases. The following scopes are necessary to ensure \tthe correct functioning of the cluster: `useraccounts-ro` (`https://www.googleapis.com/auth/cloud.useraccounts.readonly`)\n    service_account_scopes = \"\"\n\n    # tags - (Optional) The list of instance tags applied to instances in the cluster.  Tags are used to identify valid sources or targets for network firewalls.\n    tags = \"\"\n\n    # internal_ip_only - (Optional) By default, clusters are not restricted to internal IP addresses,   and will have ephemeral external IP addresses assigned to each instance. If set to true, all   instances in the cluster will only have internal IP addresses. Note: Private Google Access   (also known as `privateIpGoogleAccess`) must be enabled on the subnetwork that the cluster   will be launched in.\n    internal_ip_only = \"\"\n\n    # metadata - (Optional) A map of the Compute Engine metadata entries to add to all instances  (see [Project and instance metadata](https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).\n    metadata = \"\"\n\n    # num_instances - (Optional) `num_instances`- (Optional, Computed) Specifies the number of master nodes to create.  If not specified, GCP will default to a predetermined computed value (currently 1).\n    num_instances = \"\"\n\n    # machine_type - (Optional) (Optional, Computed) The name of a Google Compute Engine machine type  to create for the master. If not specified, GCP will default to a predetermined  computed value (currently `n1-standard-4`).\n    machine_type = \"\"\n\n    # disk_config - (Optional) Disk Config\n    disk_config = \"\"\n\n    # num_instances - (Optional) `num_instances`- (Optional, Computed) Specifies the number of worker nodes to create.  If not specified, GCP will default to a predetermined computed value (currently 2).  There is currently a beta feature which allows you to run a  [Single Node Cluster](https://cloud.google.com/dataproc/docs/concepts/single-node-clusters).  In order to take advantage of this you need to set  `\"dataproc:dataproc.allow.zero.workers\" = \"true\"` in  `cluster_config.software_config.properties`\n    num_instances = \"\"\n\n    # machine_type - (Optional) (Optional, Computed) The name of a Google Compute Engine machine type  to create for the worker nodes. If not specified, GCP will default to a predetermined  computed value (currently `n1-standard-4`).\n    machine_type = \"\"\n\n    # boot_disk_size_gb - (Optional) (Optional, Computed) Size of the primary disk attached to each worker node, specified in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined computed value if not set (currently 500GB). Note: If SSDs are not \tattached, it also contains the HDFS data blocks and Hadoop working directories.\n    boot_disk_size_gb = \"\"\n\n    # num_local_ssds - (Optional) The amount of local SSD disks that will be \tattached to each worker cluster node. Defaults to 0.\n    num_local_ssds = \"\"\n\n    # num_local_ssds - (Optional) The amount of local SSD disks that will be \tattached to each worker cluster node. Defaults to 0.\n    num_local_ssds = \"\"\n\n    # num_instances - (Optional) Specifies the number of preemptible nodes to create.  Defaults to 0.\n    num_instances = \"\"\n\n    # disk_config - (Optional) Disk Config `boot_disk_size_gb` - (Optional, Computed) Size of the primary disk attached to each preemptible worker node, specified in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined computed value if not set (currently 500GB). Note: If SSDs are not \tattached, it also contains the HDFS data blocks and Hadoop working directories.\n    disk_config = \"\"\n\n    # disk_config - (Optional) Disk Config `boot_disk_size_gb` - (Optional, Computed) Size of the primary disk attached to each preemptible worker node, specified in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined computed value if not set (currently 500GB). Note: If SSDs are not \tattached, it also contains the HDFS data blocks and Hadoop working directories.\n    disk_config = \"\"\n\n    # image_version - (Optional) this controls the sets of software versions  installed onto the nodes when you create clusters. If not specified, defaults to the  latest version. For a list of valid versions see  [Cloud Dataproc versions](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions)\n    image_version = \"\"\n\n    # override_properties - (Optional) A list of override and additional properties (key/value pairs)  used to modify various aspects of the common configuration files used when creating  a cluster. For a list of valid properties please see [Cluster properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties)\n    override_properties = \"\"\n\n    # timeout_sec - (Optional) (Optional, Computed) The maximum duration (in seconds) which `script` is  allowed to take to execute its action. GCP will default to a predetermined  computed value if not set (currently 300).\n    timeout_sec = \"\"\n\n    # Exported Attributes\n    # \"cluster_config.master_config.instance_names\" - List of master instance names which  have been assigned to the cluster.\n    # \"cluster_config.worker_config.instance_names\" - List of worker instance names which have been assigned \tto the cluster.\n    # \"cluster_config.preemptible_worker_config.instance_names\" - List of preemptible instance names which have been assigned \tto the cluster.\n    # \"cluster_config.bucket\" - The name of the cloud storage bucket ultimately used to house the staging data  for the cluster. If \"staging_bucket\" is specified, it will contain this value, otherwise  it will be the auto generated name.\n    # \"cluster_config.software_config.properties\" - A list of the properties used to set the daemon config files.  This will include any values supplied by the user via \"cluster_config.software_config.override_properties\"\n}",
        "description": "Manages a Cloud Dataproc cluster resource within GCP. For more information see\n[the official dataproc documentation](https://cloud.google.com/dataproc/). !> **Warning:** Due to limitations of the API, all arguments except\n`labels`,`cluster_config.worker_config.num_instances` and `cluster_config.preemptible_worker_config.num_instances` are non-updateable. Changing others will cause recreation of the\nwhole cluster!",
        "prefix": "google-dataproc-cluster"
    },
    "google-dataproc-job": {
        "body": "resource \"google_dataproc_job\" \"$1\" {\n    # main_python_file_uri - (Required) The HCFS URI of the main Python file to use as the driver. Must be a .py file.\n    main_python_file_uri = \"\"\n\n    # xxx_config - (Required) Exactly one of the specific job types to run on the  cluster should be specified. If you want to submit multiple jobs, this will  currently require the definition of multiple `google_dataproc_job` resources  as shown in the example above, or by setting the `count` attribute.  The following job configs are supported:  * pyspark_config  - Submits a PySpark job to the cluster\n    xxx_config = \"\"\n\n    # project - (Optional) The project in which the `cluster` can be found and jobs  subsequently run against. If it is not provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) The Cloud Dataproc region. This essentially determines which clusters are available  for this job to be submitted to. If not specified, defaults to `global`.\n    region = \"\"\n\n    # force_delete - (Optional) By default, you can only delete inactive jobs within  Dataproc. Setting this to true, and calling destroy, will ensure that the  job is first cancelled before issuing the delete.\n    force_delete = \"\"\n\n    # labels - (Optional) The list of labels (key/value pairs) to add to the job.\n    labels = \"\"\n\n    # args - (Optional) The arguments to pass to the driver.\n    args = \"\"\n\n    # python_file_uris - (Optional) HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.\n    python_file_uris = \"\"\n\n    # jar_file_uris - (Optional) HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks.\n    jar_file_uris = \"\"\n\n    # file_uris - (Optional) HCFS URIs of files to be copied to the working directory of Python drivers and distributed tasks. Useful for naively parallel tasks.\n    file_uris = \"\"\n\n    # archive_uris - (Optional) HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.\n    archive_uris = \"\"\n\n    # properties - (Optional) A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in `/etc/spark/conf/spark-defaults.conf` and classes in user code.\n    properties = \"\"\n\n    # main_class - (Optional) The class containing the main method of the driver. Must be in a  provided jar or jar that is already on the classpath. Conflicts with `main_jar_file_uri`\n    main_class = \"\"\n\n    # main_jar_file_uri - (Optional) The HCFS URI of jar file containing  the driver jar. Conflicts with `main_class`\n    main_jar_file_uri = \"\"\n\n    # args - (Optional) The arguments to pass to the driver.\n    args = \"\"\n\n    # jar_file_uris - (Optional) HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks.\n    jar_file_uris = \"\"\n\n    # file_uris - (Optional) HCFS URIs of files to be copied to the working directory of Spark drivers and distributed tasks. Useful for naively parallel tasks.\n    file_uris = \"\"\n\n    # archive_uris - (Optional) HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.\n    archive_uris = \"\"\n\n    # properties - (Optional) A mapping of property names to values, used to configure Spark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in `/etc/spark/conf/spark-defaults.conf` and classes in user code.\n    properties = \"\"\n\n    # main_class - (Optional) The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jar_file_uris`. Conflicts with `main_jar_file_uri`\n    main_class = \"\"\n\n    # main_jar_file_uri - (Optional) The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `main_class`\n    main_jar_file_uri = \"\"\n\n    # args - (Optional) The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.\n    args = \"\"\n\n    # jar_file_uris - (Optional) HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks.\n    jar_file_uris = \"\"\n\n    # file_uris - (Optional) HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.\n    file_uris = \"\"\n\n    # archive_uris - (Optional) HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.\n    archive_uris = \"\"\n\n    # properties - (Optional) A mapping of property names to values, used to configure Hadoop. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in `/etc/hadoop/conf/*-site` and classes in user code..\n    properties = \"\"\n\n    # query_list - (Optional) The list of Hive queries or statements to execute as part of the job.  Conflicts with `query_file_uri`\n    query_list = \"\"\n\n    # query_file_uri - (Optional) HCFS URI of file containing Hive script to execute as the job.  Conflicts with `query_list`\n    query_file_uri = \"\"\n\n    # continue_on_failure - (Optional) Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.\n    continue_on_failure = \"\"\n\n    # script_variables - (Optional) Mapping of query variable names to values (equivalent to the Hive command: `SET name=\"value\";`).\n    script_variables = \"\"\n\n    # properties - (Optional)  A mapping of property names and values, used to configure Hive. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in `/etc/hadoop/conf/*-site.xml`, `/etc/hive/conf/hive-site.xml`, and classes in user code..\n    properties = \"\"\n\n    # jar_file_uris - (Optional) HCFS URIs of jar files to add to the CLASSPATH of the Hive server and Hadoop MapReduce (MR) tasks. Can contain Hive SerDes and UDFs.\n    jar_file_uris = \"\"\n\n    # query_list - (Optional) The list of Hive queries or statements to execute as part of the job.  Conflicts with `query_file_uri`\n    query_list = \"\"\n\n    # query_file_uri - (Optional) HCFS URI of file containing Hive script to execute as the job.  Conflicts with `query_list`\n    query_file_uri = \"\"\n\n    # continue_on_failure - (Optional) Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.\n    continue_on_failure = \"\"\n\n    # script_variables - (Optional) Mapping of query variable names to values (equivalent to the Pig command: `name=[value]`).\n    script_variables = \"\"\n\n    # properties - (Optional) A mapping of property names to values, used to configure Pig. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in `/etc/hadoop/conf/*-site.xml`, `/etc/pig/conf/pig.properties`, and classes in user code.\n    properties = \"\"\n\n    # jar_file_uris - (Optional) HCFS URIs of jar files to add to the CLASSPATH of the Pig Client and Hadoop MapReduce (MR) tasks. Can contain Pig UDFs.\n    jar_file_uris = \"\"\n\n    # query_list - (Optional) The list of SQL queries or statements to execute as part of the job.  Conflicts with `query_file_uri`\n    query_list = \"\"\n\n    # query_file_uri - (Optional) The HCFS URI of the script that contains SQL queries.  Conflicts with `query_list`\n    query_file_uri = \"\"\n\n    # script_variables - (Optional) Mapping of query variable names to values (equivalent to the Spark SQL command: `SET name=\"value\";`).\n    script_variables = \"\"\n\n    # properties - (Optional) A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.\n    properties = \"\"\n\n    # jar_file_uris - (Optional) HCFS URIs of jar files to be added to the Spark CLASSPATH.\n    jar_file_uris = \"\"\n\n    # Exported Attributes\n    # \"reference.0.cluster_uuid\" - A cluster UUID generated by the Cloud Dataproc service when the job is submitted.\n    # \"status.0.state\" - A state message specifying the overall job state.\n    # \"status.0.details\" - Optional job state details, such as an error description if the state is ERROR.\n    # \"status.0.state_start_time\" - The time when this state was entered.\n    # \"status.0.substate\" - Additional state information, which includes status reported by the agent.\n    # \"driver_output_resource_uri\" - A URI pointing to the location of the stdout of the job's driver program.\n    # \"driver_controls_files_uri\" - If present, the location of miscellaneous control files which may be used as part of job setup and handling. If not present, control files may be placed in the same location as driver_output_uri.\n}",
        "description": "Manages a job resource within a Dataproc cluster within GCE. For more information see\n[the official dataproc documentation](https://cloud.google.com/dataproc/). !> **Note:** This resource does not support 'update' and changing any attributes will cause the resource to be recreated.",
        "prefix": "google-dataproc-job"
    },
    "google-datasource-active-folder": {
        "body": "data \"google_active_folder\" \"$1\" {\n    # parent - (Required) The resource name of the parent Folder or Organization.\n    parent = \"\"\n\n    # display_name - (Required) The folder's display name.\n    display_name = \"\"\n\n    # Exported Attributes\n    # \"name\" - The resource name of the Folder. This uniquely identifies the folder.\n    # \"parent\" - (Required) The resource name of the parent Folder or Organization.\n}",
        "description": "Get an active folder within GCP by `display_name` and `parent`.",
        "prefix": "google-datasource-active-folder"
    },
    "google-datasource-billing-account": {
        "body": "data \"google_billing_account\" \"$1\" {\n    # billing_account - (Optional) - The name of the billing account in the form `{billing_account_id}` or `billingAccounts/{billing_account_id}`.\n    billing_account = \"\"\n\n    # display_name - (Optional) - The display name of the billing account.\n    display_name = \"\"\n\n    # open - (Optional) - `true` if the billing account is open, `false` if the billing account is closed.\n    open = \"\"\n\n    # Exported Attributes\n    # \"id\" - The billing account ID.\n    # \"name\" - The resource name of the billing account in the form \"billingAccounts/{billing_account_id}\".\n    # \"project_ids\" - The IDs of any projects associated with the billing account.\n}",
        "description": "Use this data source to get information about a Google Billing Account. data \"google_billing_account\" \"acct\" {\n  display_name = \"My Billing Account\"\n  open         = true\n}\n\nresource \"google_project\" \"my_project\" {\n  name       = \"My Project\"\n  project_id = \"your-project-id\"\n  org_id     = \"1234567\"\n\n  billing_account = \"${data.google_billing_account.acct.id}\"\n}",
        "prefix": "google-datasource-billing-account"
    },
    "google-datasource-client-config": {
        "body": "data \"google_client_config\" \"$1\" {\n    # Exported Attributes\n    # \"project\" - The ID of the project to apply any resources to.\n    # \"region\" - The region to operate under.\n    # \"access_token\" - The OAuth2 access token used by the client to authenticate against the Google Cloud API.\n}",
        "description": "Use this data source to access the configuration of the Google Cloud provider.",
        "prefix": "google-datasource-client-config"
    },
    "google-datasource-cloudfunctions-function": {
        "body": "data \"google_cloudfunctions_function\" \"$1\" {\n    # name - (Required) The name of a Cloud Function.\n    name = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    region = \"\"\n\n    # Exported Attributes\n    # \"name\" - The name of the Cloud Function.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"source_archive_bucket\" - The GCS bucket containing the zip archive which contains the function.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"source_archive_object\" - The source archive object (file) in archive bucket.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"description\" - Description of the function.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"available_memory_mb\" - Available memory (in MB) to the function.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"timeout\" - Function execution timeout (in seconds).\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"runtime\" - The runtime in which the function is running.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"entry_point\" - Name of a JavaScript function that will be executed when the Google Cloud Function is triggered.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"trigger_http\" - If function is triggered by HTTP, this boolean is set.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"event_trigger\" - A source that fires events in response to a condition in another service. Structure is documented below.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"trigger_bucket\" - If function is triggered by bucket, bucket name is set here. Deprecated. Use \"event_trigger\" instead.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"trigger_topic\" - If function is triggered by Pub/Sub topic, name of topic is set here. Deprecated. Use \"event_trigger\" instead.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"https_trigger_url\" - If function is triggered by HTTP, trigger URL is set here.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"labels\" - A map of labels applied to this function.\n    # \"region\" - (Optional) The region in which the resource belongs. If it   is not provided, the provider region is used.\n    # \"event_type\" - The type of event being observed. For example: \"\"providers/cloud.storage/eventTypes/object.change\"\"   and \"\"providers/cloud.pubsub/eventTypes/topic.publish\"\". See the documentation on [calling Cloud Functions](https://cloud.google.com/functions/docs/calling/)   for a full reference.\n    # \"resource\" - The name of the resource whose events are being observed, for example, \"\"myBucket\"\"\n    # \"failure_policy\" - Policy for failed executions. Structure is documented below.\n    # \"retry\" - Whether the function should be retried on failure.\n    # \"failure_policy\" - Policy for failed executions. Structure is documented below.\n}",
        "description": "Get information about a Google Cloud Function. For more information see\nthe [official documentation](https://cloud.google.com/functions/docs/)\nand [API](https://cloud.google.com/functions/docs/apis).",
        "prefix": "google-datasource-cloudfunctions-function"
    },
    "google-datasource-compute-address": {
        "body": "data \"google_compute_address\" \"$1\" {\n    # name - (Required) A unique name for the resource, required by GCE.\n    name = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) The Region in which the created address reside.   If it is not provided, the provider region is used.\n    region = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The URI of the created resource.\n    # \"region\" - (Optional) The Region in which the created address reside.   If it is not provided, the provider region is used.\n    # \"address\" - The IP of the created resource.\n    # \"region\" - (Optional) The Region in which the created address reside.   If it is not provided, the provider region is used.\n    # \"status\" - Indicates if the address is used. Possible values are: RESERVED or IN_USE.\n    # \"region\" - (Optional) The Region in which the created address reside.   If it is not provided, the provider region is used.\n}",
        "description": "Get the IP address from a static address. For more information see\nthe official [API](https://cloud.google.com/compute/docs/reference/latest/addresses/get) documentation.",
        "prefix": "google-datasource-compute-address"
    },
    "google-datasource-compute-backend-service": {
        "body": "data \"google_compute_backend_service\" \"$1\" {\n    # name - (Required) The name of the Backend Service.\n    name = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it is not provided, the provider project is used.\n    project = \"\"\n\n    # Exported Attributes\n    # \"connection_draining_timeout_sec\" - Time for which instance will be drained (not accept new connections, but still work to finish started ones).\n    # \"description\" - Textual description for the Backend Service.\n    # \"enable_cdn\" - Whether or not Cloud CDN is enabled on the Backend Service.\n    # \"fingerprint\" - The fingerprint of the Backend Service.\n    # \"port_name\" - The name of a service that has been added to an instance group in this backend.\n    # \"protocol\" - The protocol for incoming requests.\n    # \"self_link\" - The URI of the Backend Service.\n    # \"session_affinity\" - The Backend Service session stickyness configuration.\n    # \"timeout_sec\" - The number of seconds to wait for a backend to respond to a request before considering the request failed.\n    # \"backend\" - The list of backends that serve this Backend Service.\n    # \"health_checks\" - The list of HTTP/HTTPS health checks used by the Backend Service.\n}",
        "description": "Provide acces to a Backend Service's attribute. For more information\nsee [the official documentation](https://cloud.google.com/compute/docs/load-balancing/http/backend-service)\nand the [API](https://cloud.google.com/compute/docs/reference/latest/backendServices).",
        "prefix": "google-datasource-compute-backend-service"
    },
    "google-datasource-compute-default-service-account": {
        "body": "data \"google_compute_default_service_account\" \"$1\" {\n    # project - (Optional) The project ID. If it is not provided, the provider project is used.\n    project = \"\"\n\n    # Exported Attributes\n    # \"email\" - Email address of the default service account used by VMs running in this project\n}",
        "description": "Use this data source to retrieve default service account for this project",
        "prefix": "google-datasource-compute-default-service-account"
    },
    "google-datasource-compute-forwarding-rule": {
        "body": "data \"google_compute_forwarding_rule\" \"$1\" {\n    # name - (Required) The name of the forwarding rule.\n    name = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) The region in which the resource belongs. If it   is not provided, the project region is used.\n    region = \"\"\n\n    # Exported Attributes\n    # \"description\" - Description of this forwarding rule.\n    # \"network\" - Network of this forwarding rule.\n    # \"subnetwork\" - Subnetwork of this forwarding rule.\n    # \"ip_address\" - IP address of this forwarding rule.\n    # \"ip_protocol\" - IP protocol of this forwarding rule.\n    # \"ports\" - List of ports to use for internal load balancing, if this forwarding rule has any.\n    # \"port_range\" - Port range, if this forwarding rule has one.\n    # \"target\" - URL of the target pool, if this forwarding rule has one.\n    # \"backend_service\" - Backend service, if this forwarding rule has one.\n    # \"load_balancing_scheme\" - Type of load balancing of this forwarding rule.\n    # \"region\" - Region of this forwarding rule.\n    # \"self_link\" - The URI of the resource.\n}",
        "description": "Get a forwarding rule within GCE from its name.",
        "prefix": "google-datasource-compute-forwarding-rule"
    },
    "google-datasource-compute-global-address": {
        "body": "data \"google_compute_global_address\" \"$1\" {\n    # name - (Required) A unique name for the resource, required by GCE.\n    name = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it\n    project = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The URI of the created resource.\n    # \"address\" - The IP of the created resource.\n    # \"status\" - Indicates if the address is used. Possible values are: RESERVED or IN_USE.\n}",
        "description": "Get the IP address from a static address reserved for a Global Forwarding Rule which are only used for HTTP load balancing. For more information see\nthe official [API](https://cloud.google.com/compute/docs/reference/latest/globalAddresses) documentation.",
        "prefix": "google-datasource-compute-global-address"
    },
    "google-datasource-compute-image": {
        "body": "data \"google_compute_image\" \"$1\" {\n    # name - (Required) The name of a specific image or a family.\n    name = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it is not\n    project = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The URI of the image.\n    # \"name\" - The name of the image.\n    # \"family\" - The family name of the image.\n    # \"disk_size_gb\" - The size of the image when restored onto a persistent disk in gigabytes.\n    # \"archive_size_bytes\" - The size of the image tar.gz archive stored in Google Cloud Storage in bytes.\n    # \"image_id\" - The unique identifier for the image.\n    # \"image_encryption_key_sha256\" - The [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)\n    # \"source_image_id\" - The ID value of the image used to create this image.\n    # \"source_disk\" - The URL of the source disk used to create this image.\n    # \"source_disk_encryption_key_sha256\" - The [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)\n    # \"source_disk_id\" - The ID value of the disk used to create this image.\n    # \"creation_timestamp\" - The creation timestamp in RFC3339 text format.\n    # \"description\" - An optional description of this image.\n    # \"labels\" - A map of labels applied to this image.\n    # \"label_fingerprint\" - A fingerprint for the labels being applied to this image.\n    # \"licenses\" - A list of applicable license URI.\n    # \"status\" - The status of the image. Possible values are **FAILED**, **PENDING**, or **READY**.\n}",
        "description": "Get information about a Google Compute Image. Check that your service account has the `compute.imageUser` role if you want to share [custom images](https://cloud.google.com/compute/docs/images/sharing-images-across-projects) from another project. If you want to use [public images][pubimg], do not forget to specify the dedicated project. For more information see\n[the official documentation](https://cloud.google.com/compute/docs/images) and its [API](https://cloud.google.com/compute/docs/reference/latest/images).",
        "prefix": "google-datasource-compute-image"
    },
    "google-datasource-compute-instance-group": {
        "body": "data \"google_compute_instance_group\" \"$1\" {\n    # name - (Optional) The name of the instance group. Either `name` or `self_link` must be provided.\n    name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # self_link - (Optional) The self link of the instance group. Either `name` or `self_link` must be provided.\n    self_link = \"\"\n\n    # zone - (Optional) The zone of the instance group. If referencing the instance group by name   and `zone` is not provided, the provider zone is used.\n    zone = \"\"\n\n    # Exported Attributes\n    # \"description\" - Textual description of the instance group.\n    # \"instances\" - List of instances in the group.\n    # \"named_port\" - List of named ports in the group.\n    # \"network\" - The URL of the network the instance group is in.\n    # \"self_link\" - The URI of the resource.\n    # \"size\" - The number of instances in the group.\n}",
        "description": "Get a Compute Instance Group within GCE.\nFor more information, see [the official documentation](https://cloud.google.com/compute/docs/instance-groups/#unmanaged_instance_groups)\nand [API](https://cloud.google.com/compute/docs/reference/latest/instanceGroups) data \"google_compute_instance_group\" \"all\" {\n\tname = \"instance-group-name\"\n\tzone = \"us-central1-a\"\n}",
        "prefix": "google-datasource-compute-instance-group"
    },
    "google-datasource-compute-instance-x": {
        "body": "data \"google_compute_instance\" \"$1\" {\n    # self_link - (Optional) The self link of the instance. One of `name` or `self_link` must be provided.\n    self_link = \"\"\n\n    # name - (Optional) The name of the instance. One of `name` or `self_link` must be provided.\n    name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs.   If `self_link` is provided, this value is ignored.  If neither `self_link`   nor `project` are provided, the provider project is used.\n    project = \"\"\n\n    # zone - (Optional) The zone of the instance. If `self_link` is provided, this   value is ignored.  If neither `self_link` nor `zone` are provided, the   provider zone is used.\n    zone = \"\"\n\n    # Exported Attributes\n    # \"boot_disk\" - The boot disk for the instance. Sructure is documented below.\n    # \"machine_type\" - The machine type to create.\n    # \"network_interface\" - The networks attached to the instance. Structure is documented below.\n    # \"attached_disk\" - List of disks attached to the instance. Structure is documented below.\n    # \"can_ip_forward\" - Whether sending and receiving of packets with non-matching source or destination IPs is allowed.\n    # \"description\" - A brief description of the resource.\n    # \"deletion_protection\" - Whether deletion protection is enabled on this instance.\n    # \"guest_accelerator\" - List of the type and count of accelerator cards attached to the instance. Structure is documented below.\n    # \"labels\" - A set of key/value label pairs assigned to the instance.\n    # \"metadata\" - Metadata key/value pairs made available within the instance.\n    # \"min_cpu_platform\" - The minimum CPU platform specified for the VM instance.\n    # \"scheduling\" - The scheduling strategy being used by the instance.\n    # \"scratch_disk\" - The scratch disks attached to the instance. Structure is documented below.\n    # \"service_account\" - The service account to attach to the instance. Structure is documented below.\n    # \"tags\" - The list of tags attached to the instance.\n    # \"instance_id\" - The server-assigned unique identifier of this instance.\n    # \"metadata_fingerprint\" - The unique fingerprint of the metadata.\n    # \"self_link\" - The URI of the created resource.\n    # \"tags_fingerprint\" - The unique fingerprint of the tags.\n    # \"label_fingerprint\" - The unique fingerprint of the labels.\n    # \"cpu_platform\" - The CPU platform used by this instance.\n    # \"network_interface.0.address\" - (Deprecated) The internal ip address of the instance, either manually or dynamically assigned. This attribute has been deprecated. Use \"network_interface.0.network_ip\" instead.\n    # \"network_interface.0.network_ip\" - The internal ip address of the instance, either manually or dynamically assigned.\n    # \"network_interface.0.access_config.0.nat_ip\" - If the instance has an access config, either the given external ip (in the \"nat_ip\" field) or the ephemeral (generated) ip (if you didn't provide one).\n    # \"network_interface.0.access_config.0.assigned_nat_ip\" -  (Deprecated)  If the instance has an access config, either the given external ip (in the \"nat_ip\" field) or the ephemeral (generated) ip (if you didn't provide one). This attribute has been deprecated. Use \"network_interface.0.access_config.0.nat_ip\" instead.\n    # \"attached_disk.0.disk_encryption_key_sha256\" - The [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)   encoded SHA-256 hash of the [customer-supplied encryption key]   (https://cloud.google.com/compute/docs/disks/customer-supplied-encryption) that protects this resource.\n    # \"boot_disk.disk_encryption_key_sha256\" - The [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)   encoded SHA-256 hash of the [customer-supplied encryption key]   (https://cloud.google.com/compute/docs/disks/customer-supplied-encryption) that protects this resource.\n    # \"disk.0.disk_encryption_key_sha256\" - The [RFC 4648 base64](https://tools.ietf.org/html/rfc4648#section-4)   encoded SHA-256 hash of the [customer-supplied encryption key]   (https://cloud.google.com/compute/docs/disks/customer-supplied-encryption) that protects this resource.\n    # \"auto_delete\" - Whether the disk will be auto-deleted when the instance is deleted.\n    # \"device_name\" - Name with which attached disk will be accessible under \"/dev/disk/by-id/\"\n    # \"initialize_params\" - Parameters with which a disk was created alongside the instance.   Structure is documented below.\n    # \"source\" - The name or self_link of an existing disk (such as those managed by   \"google_compute_disk\") that was attached to the instance.\n    # \"size\" - The size of the image in gigabytes.\n    # \"type\" - The GCE disk type. One of \"pd-standard\" or \"pd-ssd\".\n    # \"image\" - The image from which this disk was initialised.\n    # \"interface\" - The disk interface used for attaching this disk. One of \"SCSI\" or \"NVME\".\n    # \"image\" - The image from which this disk was initialised.\n    # \"source\" - The name or self_link of the disk attached to this instance.\n    # \"device_name\" - Name with which the attached disk is accessible   under \"/dev/disk/by-id/\"\n    # \"mode\" - Read/write mode for the disk. One of \"\"READ_ONLY\"\" or \"\"READ_WRITE\"\".\n    # \"network\" - The name or self_link of the network attached to this interface.\n    # \"subnetwork\" - The name or self_link of the subnetwork attached to this interface.\n    # \"subnetwork_project\" - The project in which the subnetwork belongs.\n    # \"address\" - (Deprecated) The private IP address assigned to the instance. This attribute has been deprecated. Use \"network_interface.network_ip\" instead.\n    # \"network_ip\" - The private IP address assigned to the instance.\n    # \"access_config\" - Access configurations, i.e. IPs via which this   instance can be accessed via the Internet. Structure documented below.\n    # \"alias_ip_range\" - An array of alias IP ranges for this network interface. Structure documented below.\n    # \"nat_ip\" - The IP address that is be 1:1 mapped to the instance's   network ip.\n    # \"public_ptr_domain_name\" - The DNS domain name for the public PTR record.\n    # \"network_tier\" - The [networking tier][network-tier] used for configuring this instance. One of \"PREMIUM\" or \"STANDARD\".\n    # \"ip_cidr_range\" - The IP CIDR range represented by this alias IP range.\n    # \"subnetwork_range_name\" - The subnetwork secondary range name specifying   the secondary range from which to allocate the IP CIDR range for this alias IP   range.\n    # \"email\" - The service account e-mail address.\n    # \"scopes\" - A list of service scopes.\n    # \"preemptible\" - Whether the instance is preemptible.\n    # \"on_host_maintenance\" - Describes maintenance behavior for the   instance. One of \"MIGRATE\" or \"TERMINATE\", for more info, read   [here](https://cloud.google.com/compute/docs/instances/setting-instance-scheduling-options)\n    # \"automatic_restart\" - Specifies if the instance should be   restarted if it was terminated by Compute Engine (not a user).\n    # \"type\" - The accelerator type resource exposed to this instance. E.g. \"nvidia-tesla-k80\".\n    # \"count\" - The number of the guest accelerator cards exposed to this instance.\n}",
        "description": "Get information about a VM instance resource within GCE. For more information see\n[the official documentation](https://cloud.google.com/compute/docs/instances)\nand\n[API](https://cloud.google.com/compute/docs/reference/latest/instances).",
        "prefix": "google-datasource-compute-instance-x"
    },
    "google-datasource-compute-lb-ip-ranges": {
        "body": "data \"google_compute_lb_ip_ranges\" \"$1\" {\n    # Exported Attributes\n    # \"network\" - The IP ranges used for health checks when **Network load balancing** is used\n    # \"http_ssl_tcp_internal\" - The IP ranges used for health checks when **HTTP(S), SSL proxy, TCP proxy, and Internal load balancing** is used\n}",
        "description": "Use this data source to access IP ranges in your firewall rules. https://cloud.google.com/compute/docs/load-balancing/health-checks#health_check_source_ips_and_firewall_rules",
        "prefix": "google-datasource-compute-lb-ip-ranges"
    },
    "google-datasource-compute-network": {
        "body": "data \"google_compute_network\" \"$1\" {\n    # name - (Required) The name of the network.\n    name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it\n    project = \"\"\n\n    # Exported Attributes\n    # \"network\" - The network name or resource link to the parent   network of this network.\n    # \"description\" - Description of this network.\n    # \"gateway_ipv4\" - The IP address of the gateway.\n    # \"subnetworks_self_links\" - the list of subnetworks which belong to the network\n    # \"self_link\" - The URI of the resource.\n}",
        "description": "Get a network within GCE from its name.",
        "prefix": "google-datasource-compute-network"
    },
    "google-datasource-compute-region-instance-group": {
        "body": "data \"google_compute_region_instance_group\" \"$1\" {\n    # name - (Optional) The name of the instance group.  One of `name` or `self_link` must be provided.\n    name = \"\"\n\n    # self_link - (Optional) The link to the instance group.  One of `name` or `self_link` must be provided.\n    self_link = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs.   If `self_link` is provided, this value is ignored.  If neither `self_link`   nor `project` are provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) The region in which the resource belongs.  If `self_link`   is provided, this value is ignored.  If neither `self_link` nor `region` are   provided, the provider region is used.\n    region = \"\"\n\n    # Exported Attributes\n    # \"size\" - The number of instances in the group.\n    # \"instances\" - List of instances in the group, as a list of resources, each containing: \"instance\" - URL to the instance.\n    # \"named_ports\" - List of named ports in the group, as a list of resources, each containing:\n    # \"port\" - Integer port number\n    # \"instances\" - List of instances in the group, as a list of resources, each containing: \"instance\" - URL to the instance.\n    # \"name\" - String port name\n    # \"instances\" - List of instances in the group, as a list of resources, each containing: \"instance\" - URL to the instance.\n    # \"instances\" - List of instances in the group, as a list of resources, each containing: \"instance\" - URL to the instance.\n    # \"status\" - String description of current state of the instance.\n    # \"instances\" - List of instances in the group, as a list of resources, each containing: \"instance\" - URL to the instance.\n    # \"instances\" - List of instances in the group, as a list of resources, each containing: \"instance\" - URL to the instance.\n}",
        "description": "Get a Compute Region Instance Group within GCE.\nFor more information, see [the official documentation](https://cloud.google.com/compute/docs/instance-groups/distributing-instances-with-regional-instance-groups) and [API](https://cloud.google.com/compute/docs/reference/latest/regionInstanceGroups). data \"google_compute_region_instance_group\" \"group\" {\n\tname = \"instance-group-name\"\n} The most common use of this datasource will be to fetch information about the instances inside regional managed instance groups, for instance: resource \"google_compute_region_instance_group_manager\" \"foo\" {\n\tname = \"some_name\"\n    ...\n\tbase_instance_name = \"foo\"\n    ...\n\tinstance_template = \"${google_compute_instance_template.foo.self_link}\"\n\ttarget_pools = [\"${google_compute_target_pool.foo.self_link}\"]\n    ...\n}\n\ndata \"google_compute_region_instance_group\" \"data_source\" {\n\tself_link = \"${google_compute_region_instance_group_manager.foo.instance_group}\"\n}",
        "prefix": "google-datasource-compute-region-instance-group"
    },
    "google-datasource-compute-regions": {
        "body": "data \"google_compute_regions\" \"$1\" {\n    # project - (Optional) - Project from which to list available regions. Defaults to project declared in the provider.\n    project = \"\"\n\n    # status - (Optional) - Allows to filter list of regions based on their current status. Status can be either `UP` or `DOWN`.\n    status = \"\"\n\n    # Exported Attributes\n    # \"names\" - A list of regions available in the given project\n}",
        "description": "Provides access to available Google Compute regions for a given project.\nSee more about [regions and regions](https://cloud.google.com/compute/docs/regions-zones/) in the upstream docs. data \"google_compute_regions\" \"available\" {}\n\nresource \"google_compute_subnetwork\" \"cluster\" {\n  count = \"${length(data.google_compute_regions.available.names)}\"\n  name          = \"my-network\"\n  ip_cidr_range = \"10.36.${count.index}.0/24\"\n  network       = \"my-network\"\n  region        = \"${data.google_compute_regions.available.names[count.index]}\"\n}",
        "prefix": "google-datasource-compute-regions"
    },
    "google-datasource-compute-ssl-policy": {
        "body": "data \"google_compute_ssl_policy\" \"$1\" {\n    # name - (Required) The name of the SSL Policy.\n    name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it\n    project = \"\"\n\n    # Exported Attributes\n    # \"enabled_features\" - The set of enabled encryption ciphers as a result of the policy config\n    # \"description\" - Description of this SSL Policy.\n    # \"min_tls_version\" - The minimum supported TLS version of this policy.\n    # \"profile\" - The Google-curated or custom profile used by this policy.\n    # \"custom_features\" - If the \"profile\" is \"CUSTOM\", these are the custom encryption   ciphers supported by the profile. If the \"profile\" is *not* \"CUSTOM\", this   attribute will be empty.\n    # \"fingerprint\" - Fingerprint of this resource.\n    # \"self_link\" - The URI of the created resource.\n}",
        "description": "Gets an SSL Policy within GCE from its name, for use with Target HTTPS and Target SSL Proxies.\n    For more information see [the official documentation](https://cloud.google.com/compute/docs/load-balancing/ssl-policies).",
        "prefix": "google-datasource-compute-ssl-policy"
    },
    "google-datasource-compute-subnetwork": {
        "body": "data \"google_compute_subnetwork\" \"$1\" {\n    # name - (Optional) The name of the subnetwork.\n    name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) The region this subnetwork has been created in. If   unspecified, this defaults to the region configured in the provider.\n    region = \"\"\n\n    # Exported Attributes\n    # \"network\" - The network name or resource link to the parent   network of this subnetwork.\n    # \"description\" - Description of this subnetwork.\n    # \"ip_cidr_range\" - The IP address range that machines in this   network are assigned to, represented as a CIDR block.\n    # \"gateway_address\" - The IP address of the gateway.\n    # \"private_ip_google_access\" - Whether the VMs in this subnet   can access Google services without assigned external IP   addresses.\n    # \"secondary_ip_range\" - An array of configurations for secondary IP ranges for   VM instances contained in this subnetwork. Structure is documented below.\n    # \"self_link\" - The URI of the created resource.\n    # \"range_name\" - The name associated with this subnetwork secondary range, used   when adding an alias IP range to a VM instance.\n    # \"ip_cidr_range\" - The range of IP addresses belonging to this subnetwork   secondary range.\n}",
        "description": "Get a subnetwork within GCE from its name and region.",
        "prefix": "google-datasource-compute-subnetwork"
    },
    "google-datasource-compute-vpn-gateway": {
        "body": "data \"google_compute_vpn_gateway\" \"$1\" {\n    # name - (Required) The name of the VPN gateway.\n    name = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # region - (Optional) The region in which the resource belongs. If it   is not provided, the project region is used.\n    region = \"\"\n\n    # Exported Attributes\n    # \"network\" - The network of this VPN gateway.\n    # \"description\" - Description of this VPN gateway.\n    # \"region\" - Region of this VPN gateway.\n    # \"self_link\" - The URI of the resource.\n}",
        "description": "Get a VPN gateway within GCE from its name.",
        "prefix": "google-datasource-compute-vpn-gateway"
    },
    "google-datasource-compute-zones": {
        "body": "data \"google_compute_zones\" \"$1\" {\n    # project - (Optional) - Project from which to list available zones. Defaults to project declared in the provider.\n    project = \"\"\n\n    # region - (Optional) - Region from which to list available zones. Defaults to region declared in the provider.\n    region = \"\"\n\n    # status - (Optional) - Allows to filter list of zones based on their current status. Status can be either `UP` or `DOWN`.\n    status = \"\"\n\n    # Exported Attributes\n    # \"names\" - A list of zones available in the given region\n}",
        "description": "Provides access to available Google Compute zones in a region for a given project.\nSee more about [regions and zones](https://cloud.google.com/compute/docs/regions-zones/regions-zones) in the upstream docs. data \"google_compute_zones\" \"available\" {}\n\nresource \"google_compute_instance_group_manager\" \"foo\" {\n  count = \"${length(data.google_compute_zones.available.names)}\"\n\n  name               = \"terraform-test-${count.index}\"\n  instance_template  = \"${google_compute_instance_template.foobar.self_link}\"\n  base_instance_name = \"foobar-${count.index}\"\n  zone               = \"${data.google_compute_zones.available.names[count.index]}\"\n  target_size        = 1\n}",
        "prefix": "google-datasource-compute-zones"
    },
    "google-datasource-container-cluster": {
        "body": "data \"google_container_cluster\" \"$1\" {\n    # name - (Optional) The name of the cluster.\n    name = \"\"\n\n    # zone - (Optional) The zone or region this cluster has been created in.\n    zone = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it\n    project = \"\"\n\n    # zone - (Optional) The zone or region this cluster has been created in.\n    zone = \"\"\n\n    # Exported Attributes\n}",
        "description": "Get info about a cluster within GKE from its name and zone.",
        "prefix": "google-datasource-container-cluster"
    },
    "google-datasource-container-image": {
        "body": "data \"google_container_registry_image\" \"$1\" {\n    # name - (Required) The image name.\n    name = \"\"\n\n    # project - (Optional) The project ID that this image is attached to.  If not provider, provider project will be used instead.\n    project = \"\"\n\n    # region - (Optional) The GCR region to use.  As of this writing, one of `asia`, `eu`, and `us`.  See [the documentation](https://cloud.google.com/container-registry/docs/pushing-and-pulling) for additional information.\n    region = \"\"\n\n    # tag - (Optional) The tag to fetch, if any.\n    tag = \"\"\n\n    # digest - (Optional) The image digest to fetch, if any.\n    digest = \"\"\n\n    # Exported Attributes\n    # \"image_url\": The URL at which the image can be accessed.\n}",
        "description": "This data source fetches the project name, and provides the appropriate URLs to use for container registry for this project. The URLs are computed entirely offline - as long as the project exists, they will be valid, but this data source does not contact Google Container Registry (GCR) at any point.",
        "prefix": "google-datasource-container-image"
    },
    "google-datasource-container-repo": {
        "body": "data \"google_container_registry_repository\" \"$1\" {\n    # project - (Optional) The project ID that this repository is attached to.  If not provided, provider project will be used instead.\n    project = \"\"\n\n    # region - (Optional) The GCR region to use.  As of this writing, one of `asia`, `eu`, and `us`.  See [the documentation](https://cloud.google.com/container-registry/docs/pushing-and-pulling) for additional information.\n    region = \"\"\n\n    # Exported Attributes\n    # \"repository_url\": The URL at which the repository can be accessed.\n}",
        "description": "This data source fetches the project name, and provides the appropriate URLs to use for container registry for this project. The URLs are computed entirely offline - as long as the project exists, they will be valid, but this data source does not contact Google Container Registry (GCR) at any point.",
        "prefix": "google-datasource-container-repo"
    },
    "google-datasource-container-versions": {
        "body": "data \"google_container_engine_versions\" \"$1\" {\n    # zone - (Optional) Zone to list available cluster versions for. Should match the zone the cluster will be deployed in.   If not specified, the provider-level zone is used. One of zone or provider-level zone is required.\n    zone = \"\"\n\n    # region - (Optional) Region to list available cluster versions for. Should match the region the cluster will be deployed in.   For regional clusters, this value must be specified and cannot be inferred from provider-level region. One of zone,   region, or provider-level zone is required. This property is in beta, and should be used with the terraform-provider-google-beta provider.   See [Provider Versions](https://terraform.io/docs/providers/google/provider_versions.html) for more details on beta fields.\n    region = \"\"\n\n    # project - (Optional) ID of the project to list available cluster versions for. Should match the project the cluster will be deployed to. Defaults to the project that the provider is authenticated with.\n    project = \"\"\n\n    # Exported Attributes\n    # \"valid_master_versions\" - A list of versions available in the given zone for use with master instances.\n    # \"project\" (optional) - ID of the project to list available cluster versions for. Should match the project the cluster will be deployed to. Defaults to the project that the provider is authenticated with.\n    # \"valid_node_versions\" - A list of versions available in the given zone for use with node instances.\n    # \"project\" (optional) - ID of the project to list available cluster versions for. Should match the project the cluster will be deployed to. Defaults to the project that the provider is authenticated with.\n    # \"latest_master_version\" - The latest version available in the given zone for use with master instances.\n    # \"project\" (optional) - ID of the project to list available cluster versions for. Should match the project the cluster will be deployed to. Defaults to the project that the provider is authenticated with.\n    # \"latest_node_version\" - The latest version available in the given zone for use with node instances.\n    # \"project\" (optional) - ID of the project to list available cluster versions for. Should match the project the cluster will be deployed to. Defaults to the project that the provider is authenticated with.\n    # \"default_cluster_version\" - Version of Kubernetes the service deploys by default.\n    # \"project\" (optional) - ID of the project to list available cluster versions for. Should match the project the cluster will be deployed to. Defaults to the project that the provider is authenticated with.\n}",
        "description": "Provides access to available Google Container Engine versions in a zone or region for a given project. data \"google_container_engine_versions\" \"central1b\" {\n  zone = \"us-central1-b\"\n}\n\nresource \"google_container_cluster\" \"foo\" {\n  name               = \"terraform-test-cluster\"\n  zone               = \"us-central1-b\"\n  node_version       = \"${data.google_container_engine_versions.central1b.latest_node_version}\"\n  initial_node_count = 1\n\n  master_auth {\n    username = \"mr.yoda\"\n    password = \"adoy.rm\"\n  }\n}",
        "prefix": "google-datasource-container-versions"
    },
    "google-datasource-dns-managed-zone": {
        "body": "data \"google_dns_managed_zone\" \"$1\" {\n    # name - (Required) A unique name for the resource.\n    name = \"\"\n\n    # project - (Optional) The ID of the project for the Google Cloud DNS zone.\n    project = \"\"\n\n    # Exported Attributes\n    # \"dns_name\" - The fully qualified DNS name of this zone, e.g. \"terraform.io.\".\n    # \"description\" - A textual description field.\n    # \"name_servers\" - The list of nameservers that will be authoritative for this   domain. Use NS records to redirect from your DNS provider to these names,   thus making Google Cloud DNS authoritative for this zone.\n}",
        "description": "Provides access to a zone's attributes within Google Cloud DNS.\nFor more information see\n[the official documentation](https://cloud.google.com/dns/zones/)\nand\n[API](https://cloud.google.com/dns/api/v1/managedZones). data \"google_dns_managed_zone\" \"env_dns_zone\" {\n  name        = \"qa-zone\"\n}\n\nresource \"google_dns_record_set\" \"dns\" {\n  name = \"my-address.${data.google_dns_managed_zone.env_dns_zone.dns_name}\"\n  type = \"TXT\"\n  ttl  = 300\n\n  managed_zone = \"${data.google_dns_managed_zone.env_dns_zone.name}\"\n\n  rrdatas = [\"test\"]\n}",
        "prefix": "google-datasource-dns-managed-zone"
    },
    "google-datasource-folder": {
        "body": "data \"google_folder\" \"$1\" {\n    # folder - (Required) - The name of the Folder in the form `{folder_id}` or `folders/{folder_id}`.\n    folder = \"\"\n\n    # lookup_organization - (Optional) - `true` to find the organization that the folder belongs, `false` to avoid the lookup. It searches up the tree. (defaults to `false`)\n    lookup_organization = \"\"\n\n    # Exported Attributes\n    # \"id\" - The Folder ID.\n    # \"name\" - The resource name of the Folder in the form \"folders/{organization_id}\".\n    # \"parent\" - The resource name of the parent Folder or Organization.\n    # \"display_name\" - The folder's display name.\n    # \"create_time\" - Timestamp when the Organization was created. A timestamp in RFC3339 UTC \"Zulu\" format, accurate to nanoseconds. Example: \"2014-10-02T15:01:23.045123456Z\".\n    # \"lifecycle_state\" - The Folder's current lifecycle state.\n    # \"organization\" - If \"lookup_organization\" is enable, the resource name of the Organization that the folder belongs.\n}",
        "description": "Use this data source to get information about a Google Cloud Folder. # Get folder by id\ndata \"google_folder\" \"my_folder_1\" {\n  folder = \"folders/12345\"\n  lookup_organization = true\n}\n\n# Search by fields\ndata \"google_folder\" \"my_folder_2\" {\n  folder = \"folders/23456\"\n}\n\noutput \"my_folder_1_organization\" {\n  value = \"${data.google_folder.my_folder_1.organization}\"\n}\n\noutput \"my_folder_2_parent\" {\n  value = \"${data.google_folder.my_folder_2.parent}\"\n}",
        "prefix": "google-datasource-folder"
    },
    "google-datasource-iam-policy": {
        "body": "data \"google_iam_policy\" \"$1\" {\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account. It **can't** be used with the `google_project` resource.\n    members = \"\"\n\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account. It **can't** be used with the `google_project` resource.\n    members = \"\"\n\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account. It **can't** be used with the `google_project` resource.\n    members = \"\"\n\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account. It **can't** be used with the `google_project` resource.\n    members = \"\"\n\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account. It **can't** be used with the `google_project` resource.\n    members = \"\"\n\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account. It **can't** be used with the `google_project` resource.\n    members = \"\"\n\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account. It **can't** be used with the `google_project` resource.\n    members = \"\"\n\n    # role - (Required) - The role/permission that will be granted to the members. See the [IAM Roles](https://cloud.google.com/compute/docs/access/iam) documentation for a complete list of roles. Note that custom roles must be of the format `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # binding - (Required) - A nested configuration block (described below)\n    binding = \"\"\n\n    # binding - (Optional) `binding` arguments are supported.\n    binding = \"\"\n\n    # Exported Attributes\n    # \"policy_data\" - The above bindings serialized in a format suitable for\n    # \"members\" (Required) - An array of identites that will be granted the privilege in the \"role\". Each entry can have one of the following values: **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account. It **can't** be used with the \"google_project\" resource.\n}",
        "description": "Generates an IAM policy document that may be referenced by and applied to\nother Google Cloud Platform resources, such as the `google_project` resource. data \"google_iam_policy\" \"admin\" {\n  binding {\n    role = \"roles/compute.instanceAdmin\"\n\n    members = [\n      \"serviceAccount:your-custom-sa@your-project.iam.gserviceaccount.com\",\n    ]\n  }\n\n  binding {\n    role = \"roles/storage.objectViewer\"\n\n    members = [\n      \"user:jane@example.com\",\n    ]\n  }\n} This data source is used to define IAM policies to apply to other resources.\nCurrently, defining a policy through a datasource and referencing that policy\nfrom another resource is the only way to apply an IAM policy to a resource. **Note:** Several restrictions apply when setting IAM policies through this API.\nSee the [setIamPolicy docs](https://cloud.google.com/resource-manager/reference/rest/v1/projects/setIamPolicy)\nfor a list of these restrictions.",
        "prefix": "google-datasource-iam-policy"
    },
    "google-datasource-iam-role": {
        "body": "data \"google_iam_role\" \"$1\" {\n    # name - (Required) - The name of the Role to lookup in the form `roles/{ROLE_NAME}`, `organizations/{ORGANIZATION_ID}/roles/{ROLE_NAME}` or `projects/{PROJECT_ID}/roles/{ROLE_NAME}`\n    name = \"\"\n\n    # Exported Attributes\n    # \"title\" - is a friendly title for the role, such as \"Role Viewer\"\n    # \"included_permissions\" - specifies the list of one or more permissions to include in the custom role, such as - \"iam.roles.get\"\n    # \"stage\" -  indicates the stage of a role in the launch lifecycle, such as \"GA\", \"BETA\" or \"ALPHA\".\n}",
        "description": "Use this data source to get information about a Google IAM Role. data \"google_iam_role\" \"roleinfo\" {\n  name = \"roles/compute.viewer\"\n}\n\noutput \"the_role_permissions\" {\n  value = \"${data.google_iam_role.roleinfo.included_permissions}\"\n}",
        "prefix": "google-datasource-iam-role"
    },
    "google-datasource-netblock-ip-ranges": {
        "body": "data \"google_netblock_ip_ranges\" \"$1\" {\n    # Exported Attributes\n    # \"cidr_blocks\" - Retrieve list of all CIDR blocks.\n    # \"cidr_blocks_ipv4\" - Retrieve list of the IP4 CIDR blocks\n    # \"cidr_blocks_ipv6\" - Retrieve list of the IP6 CIDR blocks.\n}",
        "description": "Use this data source to get the IP ranges from the sender policy framework (SPF) record of \\_cloud-netblocks.googleusercontent https://cloud.google.com/compute/docs/faq#where_can_i_find_product_name_short_ip_ranges",
        "prefix": "google-datasource-netblock-ip-ranges"
    },
    "google-datasource-organization": {
        "body": "data \"google_organization\" \"$1\" {\n    # organization - (Optional) - The name of the Organization in the form `{organization_id}` or `organizations/{organization_id}`.\n    organization = \"\"\n\n    # domain - (Optional) - The domain name of the Organization.\n    domain = \"\"\n\n    # Exported Attributes\n    # \"id\" - The Organization ID.\n    # \"name\" - The resource name of the Organization in the form \"organizations/{organization_id}\".\n    # \"directory_customer_id\" - The Google for Work customer ID of the Organization.\n    # \"create_time\" - Timestamp when the Organization was created. A timestamp in RFC3339 UTC \"Zulu\" format, accurate to nanoseconds. Example: \"2014-10-02T15:01:23.045123456Z\".\n    # \"lifecycle_state\" - The Organization's current lifecycle state.\n}",
        "description": "Use this data source to get information about a Google Cloud Organization. data \"google_organization\" \"org\" {\n  domain = \"example.com\"\n}\n\nresource \"google_folder\" \"sales\" {\n  display_name = \"Sales\"\n  parent       = \"${data.google_organization.org.name}\"\n}",
        "prefix": "google-datasource-organization"
    },
    "google-datasource-project": {
        "body": "data \"google_project\" \"$1\" {\n    # project_id - (Optional) The project ID. If it is not provided, the provider project is used.\n    project_id = \"\"\n\n    # Exported Attributes\n}",
        "description": "Use this data source to get project details.\nFor more information see \n[API](https://cloud.google.com/resource-manager/reference/rest/v1/projects#Project)",
        "prefix": "google-datasource-project"
    },
    "google-datasource-project-services": {
        "body": "data \"google_project_services\" \"$1\" {\n    # project - (Required) The project ID.\n    project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Use this data source to get details on the enabled project services. For a list of services available, visit the\n[API library page](https://console.cloud.google.com/apis/library) or run `gcloud services list`.",
        "prefix": "google-datasource-project-services"
    },
    "google-datasource-service-account": {
        "body": "data \"google_service_account\" \"$1\" {\n    # account_id - (Required) The Service account id.\n    account_id = \"\"\n\n    # project - (Optional) The ID of the project that the service account will be created in.   Defaults to the provider project configuration.\n    project = \"\"\n\n    # Exported Attributes\n    # \"email\" - The e-mail address of the service account. This value   should be referenced from any \"google_iam_policy\" data sources   that would grant the service account privileges.\n    # \"unique_id\" - The unique id of the service account.\n    # \"name\" - The fully-qualified name of the service account.\n    # \"display_name\" - The display name for the service account.\n}",
        "description": "Get the service account from a project. For more information see\nthe official [API](https://cloud.google.com/compute/docs/access/service-accounts) documentation.",
        "prefix": "google-datasource-service-account"
    },
    "google-datasource-service-account-key": {
        "body": "data \"google_service_account_key\" \"$1\" {\n    # name - (Required) The name of the service account key. This must have format   `projects/{PROJECT_ID}/serviceAccounts/{ACCOUNT}/keys/{KEYID}`, where `{ACCOUNT}`   is the email address or unique id of the service account.\n    name = \"\"\n\n    # project - (Optional) The ID of the project that the service account will be created in.   Defaults to the provider project configuration.\n    project = \"\"\n\n    # public_key_type - (Optional) The output format of the public key requested. X509_PEM is the default output format.\n    public_key_type = \"\"\n\n    # Exported Attributes\n    # \"public_key\" - The public key, base64 encoded\n    # \"public_key_type\" (Optional) The output format of the public key requested. X509_PEM is the default output format.\n}",
        "description": "Get service account public key. For more information, see [the official documentation](https://cloud.google.com/iam/docs/creating-managing-service-account-keys) and [API](https://cloud.google.com/iam/reference/rest/v1/projects.serviceAccounts.keys/get).",
        "prefix": "google-datasource-service-account-key"
    },
    "google-datasource-signed_url": {
        "body": "data \"google_storage_object_signed_url\" \"$1\" {\n    # path - (Required) The full path to the object inside the bucket\n    path = \"\"\n\n    # bucket - (Required) The name of the bucket to read the object from\n    bucket = \"\"\n\n    # http_method - (Optional) What HTTP Method will the signed URL allow (defaults to `GET`)\n    http_method = \"\"\n\n    # duration - (Optional) For how long shall the signed URL be valid (defaults to 1 hour - i.e. `1h`). \n    duration = \"\"\n\n    # credentials - (Optional) What Google service account credentials json should be used to sign the URL. \n    credentials = \"\"\n\n    # content_type - (Optional) If you specify this in the datasource, the client must provide the `Content-Type` HTTP header with the same value in its request.\n    content_type = \"\"\n\n    # extension_headers - (Optional) As needed. The server checks to make sure that the client provides matching values in requests using the signed URL. \n    extension_headers = \"\"\n\n    # Exported Attributes\n    # \"signed_url\" - The signed URL that can be used to access the storage object without authentication.\n}",
        "description": "The Google Cloud storage signed URL data source generates a signed URL for a given storage object. Signed URLs provide a way to give time-limited read or write access to anyone in possession of the URL, regardless of whether they have a Google account. For more info about signed URL's is available [here](https://cloud.google.com/storage/docs/access-control/signed-urls).",
        "prefix": "google-datasource-signed_url"
    },
    "google-datasource-storage-project-service-account": {
        "body": "data \"google_storage_project_service_account\" \"$1\" {\n    # project - (Optional) The project the unique service account was created for. If it is not provided, the provider project is used.\n    project = \"\"\n\n    # user_project - (Optional) The project the lookup originates from. This field is used if you are making the request from a different account than the one you are finding the service account for.\n    user_project = \"\"\n\n    # Exported Attributes\n    # \"email_address\" - The email address of the service account. This value is often used to refer to the service account\n    # \"user_project\" - (Optional) The project the lookup originates from. This field is used if you are making the request from a different account than the one you are finding the service account for.\n}",
        "description": "Get the email address of a project's unique Google Cloud Storage service account. Each Google Cloud project has a unique service account for use with Google Cloud Storage. Only this\nspecial service account can be used to set up `google_storage_notification` resources. For more information see\n[the API reference](https://cloud.google.com/storage/docs/json_api/v1/projects/serviceAccount).",
        "prefix": "google-datasource-storage-project-service-account"
    },
    "google-dns-managed-zone": {
        "body": "resource \"google_dns_managed_zone\" \"$1\" {\n    # name - (Required) A unique name for the resource, required by GCE.   Changing this forces a new resource to be created.\n    name = \"\"\n\n    # dns_name - (Required) The fully qualified DNS name of this zone, e.g. `terraform.io.`.\n    dns_name = \"\"\n\n    # description - (Optional) A textual description field. Defaults to 'Managed by Terraform'.\n    description = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # labels - (Optional) A set of key/value label pairs to assign to the instance.\n    labels = \"\"\n\n    # Exported Attributes\n    # \"name_servers\" - The list of nameservers that will be authoritative for this\n    # \"labels\" - (Optional) A set of key/value label pairs to assign to the instance.\n}",
        "description": "Manages a zone within Google Cloud DNS. For more information see [the official documentation](https://cloud.google.com/dns/zones/) and\n[API](https://cloud.google.com/dns/api/v1/managedZones).",
        "prefix": "google-dns-managed-zone"
    },
    "google-dns-record-set": {
        "body": "resource \"google_dns_record_set\" \"$1\" {\n    # type - (Required) The DNS record set type.\n    type = \"\"\n\n    # type - (Required) The DNS record set type.\n    type = \"\"\n\n    # ttl - (Required) The time-to-live of this record set (seconds).\n    ttl = \"\"\n\n    # rrdatas - (Required) The string data for the records in this record set   whose meaning depends on the DNS type. For TXT record, if the string data contains spaces, add surrounding `\\\"` if you don't want your string to get split on spaces.\n    rrdatas = \"\"\n\n    # name - (Required) The DNS name this record set will apply to.\n    name = \"\"\n\n    # managed_zone - (Required) The name of the zone in which this record set will   reside.\n    managed_zone = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it\n    project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Manages a set of DNS records within Google Cloud DNS. For more information see [the official documentation](https://cloud.google.com/dns/records/) and\n[API](https://cloud.google.com/dns/api/v1/resourceRecordSets). ~> **Note:** The Google Cloud DNS API requires NS records be present at all\ntimes. To accommodate this, when creating NS records, the default records\nGoogle automatically creates will be silently overwritten.  Also, when\ndestroying NS records, Terraform will not actually remove NS records, but will\nreport that it did.",
        "prefix": "google-dns-record-set"
    },
    "google-endpoints-service": {
        "body": "resource \"google_endpoints_service\" \"$1\" {\n    # service_name - (Required) The name of the service.  Usually of the form `$apiname.endpoints.$projectid.cloud.goog`.\n    service_name = \"\"\n\n    # openapi_config - (Optional) The full text of the OpenAPI YAML configuration as described [here](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md).  Either this, or *both* of `grpc_config` and `protoc_output` must be specified.\n    openapi_config = \"\"\n\n    # grpc_config - (Optional) The full text of the Service Config YAML file (Example located [here](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/master/endpoints/bookstore-grpc/api_config.yaml)).  If provided, must also provide `protoc_output`.  `open_api` config must *not* be provided.\n    grpc_config = \"\"\n\n    # protoc_output - (Optional) `protoc_output`: (Deprecated) The full contents of the Service Descriptor File generated by protoc.  This should be a compiled .pb file.  Use `protoc_output_base64` instead to prevent a permanent diff from the statefile's munging of non-UTF8 bytes.\n    protoc_output = \"\"\n\n    # project - (Optional) The project ID that the service belongs to.  If not provided, provider project is used.\n    project = \"\"\n\n    # Exported Attributes\n    # \"config_id\": The autogenerated ID for the configuration that is rolled out as part of the creation of this resource.  Must be provided to compute engine instances as a tag.\n    # \"dns_address\": The address at which the service can be found - usually the same as the service name.\n    # \"apis\": A list of API objects; structure is documented below.\n    # \"endpoints\": A list of Endpoint objects; structure is documented below.\n}",
        "description": "This resource creates and rolls out a Cloud Endpoints service using OpenAPI or gRPC.  View the relevant docs for [OpenAPI](https://cloud.google.com/endpoints/docs/openapi/) and [gRPC](https://cloud.google.com/endpoints/docs/grpc/).",
        "prefix": "google-endpoints-service"
    },
    "google-folder-iam-binding": {
        "body": "resource \"google_folder_iam_binding\" \"$1\" {\n    # role - (Required) The role that should be applied. Only one   `google_folder_iam_binding` can be used per role. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.\n    members = \"\"\n\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.\n    members = \"\"\n\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.\n    members = \"\"\n\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.\n    members = \"\"\n\n    # members - (Required) - An array of identites that will be granted the privilege in the `role`. Each entry can have one of the following values: **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.\n    members = \"\"\n\n    # folder - (Required) The resource name of the folder the policy is attached to. Its format is folders/{folder_id}.\n    folder = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the folder's IAM policy.\n    # \"role\" - (Required) The role that should be applied. Only one   \"google_folder_iam_binding\" can be used per role. Note that custom roles must be of the format   \"[projects|organizations]/{parent-name}/roles/{role-name}\".\n}",
        "description": "Allows creation and management of a single binding within IAM policy for\nan existing Google Cloud Platform folder. ~> **Note:** This resource _must not_ be used in conjunction with\n   `google_folder_iam_policy` or they will fight over what your policy\n   should be.",
        "prefix": "google-folder-iam-binding"
    },
    "google-folder-iam-member": {
        "body": "resource \"google_folder_iam_member\" \"$1\" {\n    # role - (Required) The role that should be applied. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # member - (Required) The identity that will be granted the privilege in the `role`. This field can have one of the following values: **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.\n    member = \"\"\n\n    # member - (Required) The identity that will be granted the privilege in the `role`. This field can have one of the following values: **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.\n    member = \"\"\n\n    # member - (Required) The identity that will be granted the privilege in the `role`. This field can have one of the following values: **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.\n    member = \"\"\n\n    # member - (Required) The identity that will be granted the privilege in the `role`. This field can have one of the following values: **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.\n    member = \"\"\n\n    # member - (Required) The identity that will be granted the privilege in the `role`. This field can have one of the following values: **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.\n    member = \"\"\n\n    # folder - (Required) The resource name of the folder the policy is attached to. Its format is folders/{folder_id}.\n    folder = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the folder's IAM policy.\n    # \"role\" - (Required) The role that should be applied. Note that custom roles must be of the format   \"[projects|organizations]/{parent-name}/roles/{role-name}\".\n}",
        "description": "Allows creation and management of a single member for a single binding within\nthe IAM policy for an existing Google Cloud Platform folder. ~> **Note:** This resource _must not_ be used in conjunction with\n   `google_folder_iam_policy` or they will fight over what your policy\n   should be. Similarly, roles controlled by `google_folder_iam_binding`\n   should not be assigned to using `google_folder_iam_member`.",
        "prefix": "google-folder-iam-member"
    },
    "google-folder-organization-policy": {
        "body": "resource \"google_folder_organization_policy\" \"$1\" {\n    # default - (Required) May only be set to true. If set, then the default Policy is restored.\n    default = \"\"\n\n    # enforced - (Required) If true, then the Policy is enforced. If false, then any configuration is acceptable.\n    enforced = \"\"\n\n    # constraint - (Required) The name of the Constraint the Policy is configuring, for example, `serviceuser.services`. Check out the [complete list of available constraints](https://cloud.google.com/resource-manager/docs/organization-policy/understanding-constraints#available_constraints).\n    constraint = \"\"\n\n    # folder - (Required) The resource name of the folder to set the policy for. Its format is folders/{folder_id}.\n    folder = \"\"\n\n    # version - (Optional) Version of the Policy. Default version is 0.\n    version = \"\"\n\n    # boolean_policy - (Optional) A boolean policy is a constraint that is either enforced or not. Structure is documented below. \n    boolean_policy = \"\"\n\n    # list_policy - (Optional) A policy that can define specific values that are allowed or denied for the given constraint. It  can also be used to allow or deny all values. Structure is documented below.\n    list_policy = \"\"\n\n    # restore_policy - (Optional) A restore policy is a constraint to restore the default policy. Structure is documented below. \n    restore_policy = \"\"\n\n    # restore_policy - (Optional) A restore policy is a constraint to restore the default policy. Structure is documented below. \n    restore_policy = \"\"\n\n    # allow - (Optional) One or the other must be set.\n    allow = \"\"\n\n    # suggested_values - (Optional) The Google Cloud Console will try to default to a configuration that matches the value specified in this field.\n    suggested_values = \"\"\n\n    # all - (Optional) The policy allows or denies all values.\n    all = \"\"\n\n    # values - (Optional) The policy can define specific values that are allowed or denied.\n    values = \"\"\n\n    # values - (Optional) The policy can define specific values that are allowed or denied.\n    values = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the organization policy. \"etag\" is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. \n    # \"update_time\" - (Computed) The timestamp in RFC3339 UTC \"Zulu\" format, accurate to nanoseconds, representing when the variable was last updated. Example: \"2016-10-09T12:33:37.578138407Z\".\n}",
        "description": "Allows management of Organization policies for a Google Folder. For more information see\n[the official\ndocumentation](https://cloud.google.com/resource-manager/docs/organization-policy/overview) and\n[API](https://cloud.google.com/resource-manager/reference/rest/v1/folders/setOrgPolicy).",
        "prefix": "google-folder-organization-policy"
    },
    "google-folder-x": {
        "body": "resource \"google_folder\" \"$1\" {\n    # parent - (Required) The resource name of the parent Folder or Organization.   Must be of the form `folders/{folder_id}` or `organizations/{org_id}`.\n    parent = \"\"\n\n    # display_name - (Required) The folder\u2019s display name.   A folder\u2019s display name must be unique amongst its siblings, e.g. no two folders with the same parent can share the same display name. The display name must start and end with a letter or digit, may contain letters, digits, spaces, hyphens and underscores and can be no longer than 30 characters. \n    display_name = \"\"\n\n    # Exported Attributes\n    # \"name\" - The resource name of the Folder. Its format is folders/{folder_id}.\n    # \"parent\" - (Required) The resource name of the parent Folder or Organization.   Must be of the form \"folders/{folder_id}\" or \"organizations/{org_id}\".\n    # \"lifecycle_state\" - The lifecycle state of the folder such as \"ACTIVE\" or \"DELETE_REQUESTED\".\n    # \"parent\" - (Required) The resource name of the parent Folder or Organization.   Must be of the form \"folders/{folder_id}\" or \"organizations/{org_id}\".\n    # \"create_time\" - Timestamp when the Folder was created. Assigned by the server.\n    # \"parent\" - (Required) The resource name of the parent Folder or Organization.   Must be of the form \"folders/{folder_id}\" or \"organizations/{org_id}\".\n}",
        "description": "Allows management of a Google Cloud Platform folder. For more information see \n[the official documentation](https://cloud.google.com/resource-manager/docs/creating-managing-folders)\nand \n[API](https://cloud.google.com/resource-manager/reference/rest/v2/folders). A folder can contain projects, other folders, or a combination of both. You can use folders to group projects under an organization in a hierarchy. For example, your organization might contain multiple departments, each with its own set of Cloud Platform resources. Folders allows you to group these resources on a per-department basis. Folders are used to group resources that share common IAM policies. Folders created live inside an Organization. See the [Organization documentation](https://cloud.google.com/resource-manager/docs/quickstarts) for more details. The service account used to run Terraform when creating a `google_folder`\nresource must have `roles/resourcemanager.folderCreator`. See the\n[Access Control for Folders Using IAM](https://cloud.google.com/resource-manager/docs/access-control-folders)\ndoc for more information.",
        "prefix": "google-folder-x"
    },
    "google-folders-iam-policy": {
        "body": "resource \"google_folder_iam_policy\" \"$1\" {\n    # policy_data - (Required) The `google_iam_policy` data source that represents   the IAM policy that will be applied to the folder. This policy overrides any existing   policy applied to the folder.\n    policy_data = \"\"\n\n    # folder - (Required) The resource name of the folder the policy is attached to. Its format is folders/{folder_id}.\n    folder = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the folder's IAM policy. \"etag\" is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. \n    # \"policy_data\" - (Required) The \"google_iam_policy\" data source that represents   the IAM policy that will be applied to the folder. This policy overrides any existing   policy applied to the folder.\n}",
        "description": "Allows creation and management of the IAM policy for an existing Google Cloud\nPlatform folder.",
        "prefix": "google-folders-iam-policy"
    },
    "google-kms-crypto-key-iam-binding": {
        "body": "resource \"google_kms_crypto_key_iam_binding\" \"$1\" {\n    # crypto_key_id - (Required) The crypto key ID, in the form   `{project_id}/{location_name}/{key_ring_name}/{crypto_key_name}` or   `{location_name}/{key_ring_name}/{crypto_key_name}`.   In the second form, the provider's project setting will be used as a fallback.\n    crypto_key_id = \"\"\n\n    # role - (Required) The role that should be applied. Only one   `google_kms_crypto_key_iam_binding` can be used per role. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # members - (Required) A list of users that the role should apply to.\n    members = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the crypto key's IAM policy.\n    # \"crypto_key_id\" - (Required) The crypto key ID, in the form   \"{project_id}/{location_name}/{key_ring_name}/{crypto_key_name}\" or   \"{location_name}/{key_ring_name}/{crypto_key_name}\".   In the second form, the provider's project setting will be used as a fallback.\n}",
        "description": "Allows creation and management of a single binding within IAM policy for\nan existing Google Cloud KMS crypto key.",
        "prefix": "google-kms-crypto-key-iam-binding"
    },
    "google-kms-crypto-key-iam-member": {
        "body": "resource \"google_kms_crypto_key_iam_member\" \"$1\" {\n    # crypto_key_id - (Required) The key ring ID, in the form   `{project_id}/{location_name}/{key_ring_name}/{crypto_key_name}` or   `{location_name}/{key_ring_name}/{crypto_key_name}`. In the second form,   the provider's project setting will be used as a fallback.\n    crypto_key_id = \"\"\n\n    # role - (Required) The role that should be applied. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # member - (Required) The user that the role should apply to.\n    member = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the project's IAM policy.\n    # \"crypto_key_id\" - (Required) The key ring ID, in the form   \"{project_id}/{location_name}/{key_ring_name}/{crypto_key_name}\" or   \"{location_name}/{key_ring_name}/{crypto_key_name}\". In the second form,   the provider's project setting will be used as a fallback.\n}",
        "description": "Allows creation and management of a single member for a single binding within\nthe IAM policy for an existing Google Cloud KMS crypto key. ~> **Note:** This resource _must not_ be used in conjunction with\n   `google_kms_crypto_key_iam_policy` or they will fight over what your policy\n   should be. Similarly, roles controlled by `google_kms_crypto_key_iam_binding`\n   should not be assigned to using `google_kms_crypto_key_iam_member`.",
        "prefix": "google-kms-crypto-key-iam-member"
    },
    "google-kms-crypto-key-x": {
        "body": "resource \"google_kms_crypto_key\" \"$1\" {\n    # key_ring - (Required) The id of the Google Cloud Platform KeyRing to which the key shall belong.\n    key_ring = \"\"\n\n    # key_ring - (Required) The id of the Google Cloud Platform KeyRing to which the key shall belong.\n    key_ring = \"\"\n\n    # name - (Required) The CryptoKey's name.   A CryptoKey\u2019s name must be unique within a location and match the regular expression `[a-zA-Z0-9_-]{1,63}`\n    name = \"\"\n\n    # rotation_period - (Optional) Every time this period passes, generate a new CryptoKeyVersion and set it as\n    rotation_period = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The self link of the created CryptoKey. Its format is \"projects/{projectId}/locations/{location}/keyRings/{keyRingName}/cryptoKeys/{cryptoKeyName}\".\n    # \"key_ring\" - (Required) The id of the Google Cloud Platform KeyRing to which the key shall belong.\n}",
        "description": "Allows creation of a Google Cloud Platform KMS CryptoKey. For more information see\n[the official documentation](https://cloud.google.com/kms/docs/object-hierarchy#cryptokey)\nand\n[API](https://cloud.google.com/kms/docs/reference/rest/v1/projects.locations.keyRings.cryptoKeys). A CryptoKey is an interface to key material which can be used to encrypt and decrypt data. A CryptoKey belongs to a\nGoogle Cloud KMS KeyRing. ~> Note: CryptoKeys cannot be deleted from Google Cloud Platform. Destroying a\nTerraform-managed CryptoKey will remove it from state and delete all\nCryptoKeyVersions, rendering the key unusable, but **will not delete the\nresource on the server**. When Terraform destroys these keys, any data\npreviously encrypted with these keys will be irrecoverable. For this reason, it\nis strongly recommended that you add lifecycle hooks to the resource to prevent\naccidental destruction.",
        "prefix": "google-kms-crypto-key-x"
    },
    "google-kms-key-ring-iam": {
        "body": "resource \"google_kms_key_ring_iam\" \"$1\" {\n    # role - (Required) The role that should be applied. Only one   `google_kms_key_ring_iam_binding` can be used per role. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # key_ring_id - (Required) The key ring ID, in the form   `{project_id}/{location_name}/{key_ring_name}` or   `{location_name}/{key_ring_name}`. In the second form, the provider's   project setting will be used as a fallback.\n    key_ring_id = \"\"\n\n    # policy_data - (Optional) (Required only by `google_kms_key_ring_iam_policy`) The policy data generated by a `google_iam_policy` data source.\n    policy_data = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the key ring's IAM policy.\n    # \"policy_data\" - (Required only by \"google_kms_key_ring_iam_policy\") The policy data generated by a \"google_iam_policy\" data source.\n}",
        "description": "Three different resources help you manage your IAM policy for KMS key ring. Each of these resources serves a different use case: `google_kms_key_ring_iam_policy`: Authoritative. Sets the IAM policy for the key ring and replaces any existing policy already attached.  `google_kms_key_ring_iam_binding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the key ring are preserved.  `google_kms_key_ring_iam_member`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the key ring are preserved.  ~> **Note:** `google_kms_key_ring_iam_policy` **cannot** be used in conjunction with `google_kms_key_ring_iam_binding` and `google_kms_key_ring_iam_member` or they will fight over what your policy should be. ~> **Note:** `google_kms_key_ring_iam_binding` resources **can be** used in conjunction with `google_kms_key_ring_iam_member` resources **only if** they do not grant privilege to the same role.",
        "prefix": "google-kms-key-ring-iam"
    },
    "google-kms-key-ring-x": {
        "body": "resource \"google_kms_key_ring\" \"$1\" {\n    # location - (Required) The Google Cloud Platform location for the KeyRing.   A full list of valid locations can be found by running `gcloud kms locations list`.\n    location = \"\"\n\n    # location - (Required) The Google Cloud Platform location for the KeyRing.   A full list of valid locations can be found by running `gcloud kms locations list`.\n    location = \"\"\n\n    # name - (Required) The KeyRing's name.   A KeyRing\u2019s name must be unique within a location and match the regular expression `[a-zA-Z0-9_-]{1,63}`\n    name = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it\n    project = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The self link of the created KeyRing. Its format is \"projects/{projectId}/locations/{location}/keyRings/{keyRingName}\".\n    # \"location\" - (Required) The Google Cloud Platform location for the KeyRing.   A full list of valid locations can be found by running \"gcloud kms locations list\".\n}",
        "description": "Allows creation of a Google Cloud Platform KMS KeyRing. For more information see\n[the official documentation](https://cloud.google.com/kms/docs/object-hierarchy#keyring)\nand \n[API](https://cloud.google.com/kms/docs/reference/rest/v1/projects.locations.keyRings). A KeyRing is a grouping of CryptoKeys for organizational purposes. A KeyRing belongs to a Google Cloud Platform Project\nand resides in a specific location. ~> Note: KeyRings cannot be deleted from Google Cloud Platform. Destroying a Terraform-managed KeyRing will remove it\nfrom state but **will not delete the resource on the server**.",
        "prefix": "google-kms-key-ring-x"
    },
    "google-kms-secret": {
        "body": "data \"google_kms_secret\" \"$1\" {\n    # crypto_key - (Required) - The id of the CryptoKey that will be used to\n    crypto_key = \"\"\n\n    # ciphertext - (Required) - The ciphertext to be decrypted, encoded in base64\n    ciphertext = \"\"\n\n    # Exported Attributes\n    # \"plaintext\" - Contains the result of decrypting the provided ciphertext.\n}",
        "description": "This data source allows you to use data encrypted with Google Cloud KMS\nwithin your resource definitions. For more information see\n[the official documentation](https://cloud.google.com/kms/docs/encrypt-decrypt). ~> **NOTE**: Using this data provider will allow you to conceal secret data within your\nresource definitions, but it does not take care of protecting that data in the\nlogging output, plan output, or state output.  Please take care to secure your secret\ndata outside of resource definitions.",
        "prefix": "google-kms-secret"
    },
    "google-logging-billing-account-sink": {
        "body": "resource \"google_logging_billing_account_sink\" \"$1\" {\n    # destination - (Required) The destination of the sink (or, in other words, where logs are written to). Can be a   Cloud Storage bucket, a PubSub topic, or a BigQuery dataset. Examples: \"storage.googleapis.com/[GCS_BUCKET]\"\n    destination = \"\"\n\n    # billing_account - (Required) The billing account exported to the sink.\n    billing_account = \"\"\n\n    # name - (Required) The name of the logging sink.\n    name = \"\"\n\n    # filter - (Optional) The filter to apply when exporting logs. Only log entries that match the filter are exported.   See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced_filters) for information on how to   write a filter.\n    filter = \"\"\n\n    # Exported Attributes\n    # \"writer_identity\" - The identity associated with this sink. This identity must be granted write access to the\n    # \"filter\" - (Optional) The filter to apply when exporting logs. Only log entries that match the filter are exported.   See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced_filters) for information on how to   write a filter.\n}",
        "description": "Manages a billing account logging sink. For more information see\n[the official documentation](https://cloud.google.com/logging/docs/) and\n[Exporting Logs in the API](https://cloud.google.com/logging/docs/api/tasks/exporting-logs). ~> **Note** You must have the \"Logs Configuration Writer\" IAM role (`roles/logging.configWriter`)\n[granted on the billing account](https://cloud.google.com/billing/reference/rest/v1/billingAccounts/getIamPolicy) to\nthe credentials used with Terraform. [IAM roles granted on a billing account](https://cloud.google.com/billing/docs/how-to/billing-access) are separate from the\ntypical IAM roles granted on a project.",
        "prefix": "google-logging-billing-account-sink"
    },
    "google-logging-billing_account-exclusion": {
        "body": "resource \"google_logging_billing_account_exclusion\" \"$1\" {\n    # filter - (Required) The filter to apply when excluding logs. Only log entries that match the filter are excluded.   See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced-filters) for information on how to   write a filter.\n    filter = \"\"\n\n    # name - (Required) The name of the logging exclusion.\n    name = \"\"\n\n    # billing_account - (Required) The billing account to create the exclusion for.\n    billing_account = \"\"\n\n    # description - (Optional) A human-readable description.\n    description = \"\"\n\n    # disabled - (Optional) Whether this exclusion rule should be disabled or not. This defaults to   false.\n    disabled = \"\"\n\n    # Exported Attributes\n}",
        "description": "Manages a billing account logging exclusion. For more information see\n[the official documentation](https://cloud.google.com/logging/docs/) and\n[Excluding Logs](https://cloud.google.com/logging/docs/exclusions). Note that you must have the \"Logs Configuration Writer\" IAM role (`roles/logging.configWriter`)\ngranted to the credentials used with Terraform.",
        "prefix": "google-logging-billing_account-exclusion"
    },
    "google-logging-folder-exclusion": {
        "body": "resource \"google_logging_folder_exclusion\" \"$1\" {\n    # filter - (Required) The filter to apply when excluding logs. Only log entries that match the filter are excluded.   See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced-filters) for information on how to   write a filter.\n    filter = \"\"\n\n    # name - (Required) The name of the logging exclusion.\n    name = \"\"\n\n    # folder - (Required) The folder to be exported to the sink. Note that either [FOLDER_ID] or \"folders/[FOLDER_ID]\" is   accepted.\n    folder = \"\"\n\n    # description - (Optional) A human-readable description.\n    description = \"\"\n\n    # disabled - (Optional) Whether this exclusion rule should be disabled or not. This defaults to   false.\n    disabled = \"\"\n\n    # Exported Attributes\n}",
        "description": "Manages a folder-level logging exclusion. For more information see\n[the official documentation](https://cloud.google.com/logging/docs/) and\n[Excluding Logs](https://cloud.google.com/logging/docs/exclusions). Note that you must have the \"Logs Configuration Writer\" IAM role (`roles/logging.configWriter`)\ngranted to the credentials used with Terraform.",
        "prefix": "google-logging-folder-exclusion"
    },
    "google-logging-folder-sink": {
        "body": "resource \"google_logging_folder_sink\" \"$1\" {\n    # destination - (Required) The destination of the sink (or, in other words, where logs are written to). Can be a   Cloud Storage bucket, a PubSub topic, or a BigQuery dataset. Examples: \"storage.googleapis.com/[GCS_BUCKET]\"\n    destination = \"\"\n\n    # folder - (Required) The folder to be exported to the sink. Note that either [FOLDER_ID] or \"folders/[FOLDER_ID]\" is   accepted.\n    folder = \"\"\n\n    # name - (Required) The name of the logging sink.\n    name = \"\"\n\n    # filter - (Optional) The filter to apply when exporting logs. Only log entries that match the filter are exported.   See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced_filters) for information on how to   write a filter.\n    filter = \"\"\n\n    # include_children - (Optional) Whether or not to include children folders in the sink export. If true, logs   associated with child projects are also exported; otherwise only logs relating to the provided folder are included.\n    include_children = \"\"\n\n    # Exported Attributes\n    # \"writer_identity\" - The identity associated with this sink. This identity must be granted write access to the\n    # \"include_children\" - (Optional) Whether or not to include children folders in the sink export. If true, logs   associated with child projects are also exported; otherwise only logs relating to the provided folder are included.\n}",
        "description": "Manages a folder-level logging sink. For more information see\n[the official documentation](https://cloud.google.com/logging/docs/) and\n[Exporting Logs in the API](https://cloud.google.com/logging/docs/api/tasks/exporting-logs). Note that you must have the \"Logs Configuration Writer\" IAM role (`roles/logging.configWriter`)\ngranted to the credentials used with terraform.",
        "prefix": "google-logging-folder-sink"
    },
    "google-logging-organization-exclusion": {
        "body": "resource \"google_logging_organization_exclusion\" \"$1\" {\n    # filter - (Required) The filter to apply when excluding logs. Only log entries that match the filter are excluded.   See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced-filters) for information on how to   write a filter.\n    filter = \"\"\n\n    # org_id - (Required) The organization to create the exclusion in.\n    org_id = \"\"\n\n    # name - (Required) The name of the logging exclusion.\n    name = \"\"\n\n    # description - (Optional) A human-readable description.\n    description = \"\"\n\n    # disabled - (Optional) Whether this exclusion rule should be disabled or not. This defaults to   false.\n    disabled = \"\"\n\n    # Exported Attributes\n}",
        "description": "Manages an organization-level logging exclusion. For more information see\n[the official documentation](https://cloud.google.com/logging/docs/) and\n[Excluding Logs](https://cloud.google.com/logging/docs/exclusions). Note that you must have the \"Logs Configuration Writer\" IAM role (`roles/logging.configWriter`)\ngranted to the credentials used with Terraform.",
        "prefix": "google-logging-organization-exclusion"
    },
    "google-logging-organization-sink": {
        "body": "resource \"google_logging_organization_sink\" \"$1\" {\n    # destination - (Required) The destination of the sink (or, in other words, where logs are written to). Can be a   Cloud Storage bucket, a PubSub topic, or a BigQuery dataset. Examples: \"storage.googleapis.com/[GCS_BUCKET]\"\n    destination = \"\"\n\n    # org_id - (Required) The numeric ID of the organization to be exported to the sink.\n    org_id = \"\"\n\n    # name - (Required) The name of the logging sink.\n    name = \"\"\n\n    # filter - (Optional) The filter to apply when exporting logs. Only log entries that match the filter are exported.   See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced_filters) for information on how to   write a filter.\n    filter = \"\"\n\n    # include_children - (Optional) Whether or not to include children organizations in the sink export. If true, logs   associated with child projects are also exported; otherwise only logs relating to the provided organization are included.\n    include_children = \"\"\n\n    # Exported Attributes\n    # \"writer_identity\" - The identity associated with this sink. This identity must be granted write access to the\n    # \"include_children\" - (Optional) Whether or not to include children organizations in the sink export. If true, logs   associated with child projects are also exported; otherwise only logs relating to the provided organization are included.\n}",
        "description": "Manages a organization-level logging sink. For more information see\n[the official documentation](https://cloud.google.com/logging/docs/) and\n[Exporting Logs in the API](https://cloud.google.com/logging/docs/api/tasks/exporting-logs). Note that you must have the \"Logs Configuration Writer\" IAM role (`roles/logging.configWriter`)\ngranted to the credentials used with terraform.",
        "prefix": "google-logging-organization-sink"
    },
    "google-logging-project-exclusion": {
        "body": "resource \"google_logging_project_exclusion\" \"$1\" {\n    # name - (Required) The name of the logging exclusion.\n    name = \"\"\n\n    # filter - (Required) The filter to apply when excluding logs. Only log entries that match the filter are excluded.   See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced-filters) for information on how to   write a filter.\n    filter = \"\"\n\n    # description - (Optional) A human-readable description.\n    description = \"\"\n\n    # disabled - (Optional) Whether this exclusion rule should be disabled or not. This defaults to   false.\n    disabled = \"\"\n\n    # project - (Optional) The project to create the exclusion in. If omitted, the project associated with the provider is   used.\n    project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Manages a project-level logging exclusion. For more information see\n[the official documentation](https://cloud.google.com/logging/docs/) and\n[Excluding Logs](https://cloud.google.com/logging/docs/exclusions). Note that you must have the \"Logs Configuration Writer\" IAM role (`roles/logging.configWriter`)\ngranted to the credentials used with Terraform.",
        "prefix": "google-logging-project-exclusion"
    },
    "google-logging-project-sink": {
        "body": "resource \"google_logging_project_sink\" \"$1\" {\n    # destination - (Required) The destination of the sink (or, in other words, where logs are written to). Can be a   Cloud Storage bucket, a PubSub topic, or a BigQuery dataset. Examples: \"storage.googleapis.com/[GCS_BUCKET]\"\n    destination = \"\"\n\n    # name - (Required) The name of the logging sink.\n    name = \"\"\n\n    # filter - (Optional) The filter to apply when exporting logs. Only log entries that match the filter are exported.   See [Advanced Log Filters](https://cloud.google.com/logging/docs/view/advanced_filters) for information on how to   write a filter.\n    filter = \"\"\n\n    # project - (Optional) The ID of the project to create the sink in. If omitted, the project associated with the provider is   used.\n    project = \"\"\n\n    # unique_writer_identity - (Optional) Whether or not to create a unique identity associated with this sink. If `false`   (the default), then the `writer_identity` used is `serviceAccount:cloud-logs@system.gserviceaccount.com`. If `true`,   then a unique service account is created and used for this sink. If you wish to publish logs across projects, you   must set `unique_writer_identity` to true.\n    unique_writer_identity = \"\"\n\n    # Exported Attributes\n    # \"writer_identity\" - The identity associated with this sink. This identity must be granted write access to the\n    # \"unique_writer_identity\" - (Optional) Whether or not to create a unique identity associated with this sink. If \"false\"   (the default), then the \"writer_identity\" used is \"serviceAccount:cloud-logs@system.gserviceaccount.com\". If \"true\",   then a unique service account is created and used for this sink. If you wish to publish logs across projects, you   must set \"unique_writer_identity\" to true.\n}",
        "description": "Manages a project-level logging sink. For more information see\n[the official documentation](https://cloud.google.com/logging/docs/),\n[Exporting Logs in the API](https://cloud.google.com/logging/docs/api/tasks/exporting-logs)\nand\n[API](https://cloud.google.com/logging/docs/reference/v2/rest/). ~> **Note:** You must have [granted the \"Logs Configuration Writer\"](https://cloud.google.com/logging/docs/access-control) IAM role (`roles/logging.configWriter`) to the credentials used with terraform. ~> **Note** You must [enable the Cloud Resource Manager API](https://console.cloud.google.com/apis/library/cloudresourcemanager.googleapis.com)",
        "prefix": "google-logging-project-sink"
    },
    "google-organization-iam-binding": {
        "body": "resource \"google_organization_iam_binding\" \"$1\" {\n    # members - (Required) A list of users that the role should apply to.\n    members = \"\"\n\n    # role - (Required) The role that should be applied. Only one   `google_organization_iam_binding` can be used per role. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # org_id - (Required) The numeric ID of the organization in which you want to create a custom role.\n    org_id = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the organization's IAM policy.\n    # \"members\" - (Required) A list of users that the role should apply to.\n}",
        "description": "Allows creation and management of a single binding within IAM policy for\nan existing Google Cloud Platform Organization. ~> **Note:** This resource __must not__ be used in conjunction with\n   `google_organization_iam_member` for the __same role__ or they will fight over\n   what your policy should be.",
        "prefix": "google-organization-iam-binding"
    },
    "google-organization-iam-custom-role": {
        "body": "resource \"google_organization_iam_custom_role\" \"$1\" {\n    # permissions - (Required) The names of the permissions this role grants when bound in an IAM policy. At least one permission must be specified.\n    permissions = \"\"\n\n    # title - (Required) A human-readable title for the role.\n    title = \"\"\n\n    # org_id - (Required) The numeric ID of the organization in which you want to create a custom role.\n    org_id = \"\"\n\n    # role_id - (Required) The role id to use for this role.\n    role_id = \"\"\n\n    # stage - (Optional) The current launch stage of the role.   Defaults to `GA`.   List of possible stages is [here](https://cloud.google.com/iam/reference/rest/v1/organizations.roles#Role.RoleLaunchStage).\n    stage = \"\"\n\n    # description - (Optional) A human-readable description for the role.\n    description = \"\"\n\n    # deleted - (Optional) The current deleted state of the role. Defaults to `false`.\n    deleted = \"\"\n\n    # Exported Attributes\n}",
        "description": "Allows management of a customized Cloud IAM organization role. For more information see\n[the official documentation](https://cloud.google.com/iam/docs/understanding-custom-roles)\nand\n[API](https://cloud.google.com/iam/reference/rest/v1/organizations.roles). ~> **Warning:** Note that custom roles in GCP have the concept of a soft-delete. There are two issues that may arise\n from this and how roles are propagated. 1) creating a role may involve undeleting and then updating a role with the\n same name, possibly causing confusing behavior between undelete and update. 2) A deleted role is permanently deleted\n after 7 days, but it can take up to 30 more days (i.e. between 7 and 37 days after deletion) before the role name is\n made available again. This means a deleted role that has been deleted for more than 7 days cannot be changed at all\n by Terraform, and new roles cannot share that name.\n ",
        "prefix": "google-organization-iam-custom-role"
    },
    "google-organization-iam-member": {
        "body": "resource \"google_organization_iam_member\" \"$1\" {\n    # member - (Required) The user that the role should apply to.    ## Attributes Reference\n    member = \"\"\n\n    # member - (Required) The user that the role should apply to.    ## Attributes Reference\n    member = \"\"\n\n    # role - (Required) The role that should be applied. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # org_id - (Required) The numeric ID of the organization in which you want to create a custom role.\n    org_id = \"\"\n\n    # etag - (Optional) (Computed) The etag of the organization's IAM policy.\n    etag = \"\"\n\n    # Exported Attributes\n}",
        "description": "Allows creation and management of a single member for a single binding within\nthe IAM policy for an existing Google Cloud Platform Organization. ~> **Note:** This resource __must not__ be used in conjunction with\n   `google_organization_iam_binding` for the __same role__ or they will fight over\n   what your policy should be.",
        "prefix": "google-organization-iam-member"
    },
    "google-organization-iam-policy": {
        "body": "resource \"google_organization_iam_policy\" \"$1\" {\n    # policy_data - (Required) The `google_iam_policy` data source that represents   the IAM policy that will be applied to the organization. This policy overrides any existing   policy applied to the organization.\n    policy_data = \"\"\n\n    # org_id - (Required) The numeric ID of the organization in which you want to create a custom role.\n    org_id = \"\"\n\n    # Exported Attributes\n}",
        "description": "Allows management of the entire IAM policy for an existing Google Cloud Platform Organization. ~> **Warning:** New organizations have several default policies which will,\n   without extreme caution, be **overwritten** by use of this resource.\n   The safest alternative is to use multiple `google_organization_iam_binding`\n   resources.  It is easy to use this resource to remove your own access to\n   an organization, which will require a call to Google Support to have\n   fixed, and can take multiple days to resolve.  If you do use this resource,\n   the best way to be sure that you are not making dangerous changes is to start\n   by importing your existing policy, and examining the diff very closely. ~> **Note:** This resource __must not__ be used in conjunction with\n   `google_organization_iam_member` or `google_organization_iam_binding`\n   or they will fight over what your policy should be.",
        "prefix": "google-organization-iam-policy"
    },
    "google-organization-policy": {
        "body": "resource \"google_organization_policy\" \"$1\" {\n    # default - (Required) May only be set to true. If set, then the default Policy is restored.\n    default = \"\"\n\n    # enforced - (Required) If true, then the Policy is enforced. If false, then any configuration is acceptable.\n    enforced = \"\"\n\n    # constraint - (Required) The name of the Constraint the Policy is configuring, for example, `serviceuser.services`. Check out the [complete list of available constraints](https://cloud.google.com/resource-manager/docs/organization-policy/understanding-constraints#available_constraints).\n    constraint = \"\"\n\n    # org_id - (Required) The numeric ID of the organization to set the policy for.\n    org_id = \"\"\n\n    # version - (Optional) Version of the Policy. Default version is 0.\n    version = \"\"\n\n    # boolean_policy - (Optional) A boolean policy is a constraint that is either enforced or not. Structure is documented below. \n    boolean_policy = \"\"\n\n    # list_policy - (Optional) A policy that can define specific values that are allowed or denied for the given constraint. It can also be used to allow or deny all values. Structure is documented below.\n    list_policy = \"\"\n\n    # restore_policy - (Optional) A restore policy is a constraint to restore the default policy. Structure is documented below. \n    restore_policy = \"\"\n\n    # restore_policy - (Optional) A restore policy is a constraint to restore the default policy. Structure is documented below. \n    restore_policy = \"\"\n\n    # allow - (Optional) One or the other must be set.\n    allow = \"\"\n\n    # suggested_values - (Optional) The Google Cloud Console will try to default to a configuration that matches the value specified in this field.\n    suggested_values = \"\"\n\n    # all - (Optional) The policy allows or denies all values.\n    all = \"\"\n\n    # values - (Optional) The policy can define specific values that are allowed or denied.\n    values = \"\"\n\n    # values - (Optional) The policy can define specific values that are allowed or denied.\n    values = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the organization policy. \"etag\" is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. \n    # \"update_time\" - (Computed) The timestamp in RFC3339 UTC \"Zulu\" format, accurate to nanoseconds, representing when the variable was last updated. Example: \"2016-10-09T12:33:37.578138407Z\".\n}",
        "description": "Allows management of Organization policies for a Google Organization. For more information see\n[the official\ndocumentation](https://cloud.google.com/resource-manager/docs/organization-policy/overview) and\n[API](https://cloud.google.com/resource-manager/reference/rest/v1/organizations/setOrgPolicy).",
        "prefix": "google-organization-policy"
    },
    "google-project-iam-custom-role": {
        "body": "resource \"google_project_iam_custom_role\" \"$1\" {\n    # permissions - (Required) The names of the permissions this role grants when bound in an IAM policy. At least one permission must be specified.\n    permissions = \"\"\n\n    # title - (Required) A human-readable title for the role.\n    title = \"\"\n\n    # role_id - (Required) The role id to use for this role.\n    role_id = \"\"\n\n    # project - (Optional) The project that the service account will be created in.   Defaults to the provider project configuration.\n    project = \"\"\n\n    # stage - (Optional) The current launch stage of the role.   Defaults to `GA`.   List of possible stages is [here](https://cloud.google.com/iam/reference/rest/v1/organizations.roles#Role.RoleLaunchStage).\n    stage = \"\"\n\n    # description - (Optional) A human-readable description for the role.\n    description = \"\"\n\n    # Exported Attributes\n}",
        "description": "Allows management of a customized Cloud IAM project role. For more information see\n[the official documentation](https://cloud.google.com/iam/docs/understanding-custom-roles)\nand\n[API](https://cloud.google.com/iam/reference/rest/v1/projects.roles). ~> **Warning:** Note that custom roles in GCP have the concept of a soft-delete. There are two issues that may arise\n from this and how roles are propagated. 1) creating a role may involve undeleting and then updating a role with the\n same name, possibly causing confusing behavior between undelete and update. 2) A deleted role is permanently deleted\n after 7 days, but it can take up to 30 more days (i.e. between 7 and 37 days after deletion) before the role name is\n made available again. This means a deleted role that has been deleted for more than 7 days cannot be changed at all\n by Terraform, and new roles cannot share that name.",
        "prefix": "google-project-iam-custom-role"
    },
    "google-project-iam-x": {
        "body": "resource \"google_project_iam\" \"$1\" {\n    # role - (Required) The role that should be applied. Only one   `google_project_iam_binding` can be used per role. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # policy_data - (Optional) (Required only by `google_project_iam_policy`) The `google_iam_policy` data source that represents   the IAM policy that will be applied to the project. The policy will be   merged with any existing policy applied to the project.   Changing this updates the policy.   Deleting this removes the policy, but leaves the original project policy   intact. If there are overlapping `binding` entries between the original   project policy and the data source policy, they will be removed.\n    policy_data = \"\"\n\n    # project - (Optional) The project ID. If not specified, uses the   ID of the project configured with the provider.\n    project = \"\"\n\n    # authoritative - (Optional) (DEPRECATED) (Optional, only for `google_project_iam_policy`)   A boolean value indicating if this policy   should overwrite any existing IAM policy on the project. When set to true,   **any policies not in your config file will be removed**. This can **lock   you out** of your project until an Organization Administrator grants you   access again, so please exercise caution. If this argument is `true` and you   want to delete the resource, you must set the `disable_project` argument to   `true`, acknowledging that the project will be inaccessible to anyone but the   Organization Admins, as it will no longer have an IAM policy. Rather than using   this, you should use `google_project_iam_binding` and   `google_project_iam_member`.\n    authoritative = \"\"\n\n    # disable_project - (Optional) (DEPRECATED) (Optional, only for `google_project_iam_policy`)   A boolean value that must be set to `true`   if you want to delete a `google_project_iam_policy` that is authoritative.    ## Attributes Reference\n    disable_project = \"\"\n\n    # etag - (Optional) (Computed) The etag of the project's IAM policy.\n    etag = \"\"\n\n    # restore_policy - (Optional) (DEPRECATED) (Computed, only for `google_project_iam_policy`)   The IAM policy that will be restored when a   non-authoritative policy resource is deleted.\n    restore_policy = \"\"\n\n    # Exported Attributes\n}",
        "description": "Three different resources help you manage your IAM policy for a project. Each of these resources serves a different use case: `google_project_iam_policy`: Authoritative. Sets the IAM policy for the project and replaces any existing policy already attached.  `google_project_iam_binding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the project are preserved.  `google_project_iam_member`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the project are preserved.  ~> **Note:** `google_project_iam_policy` **cannot** be used in conjunction with `google_project_iam_binding` and `google_project_iam_member` or they will fight over what your policy should be. ~> **Note:** `google_project_iam_binding` resources **can be** used in conjunction with `google_project_iam_member` resources **only if** they do not grant privilege to the same role.",
        "prefix": "google-project-iam-x"
    },
    "google-project-organization-policy": {
        "body": "resource \"google_project_organization_policy\" \"$1\" {\n    # default - (Required) May only be set to true. If set, then the default Policy is restored.\n    default = \"\"\n\n    # enforced - (Required) If true, then the Policy is enforced. If false, then any configuration is acceptable.\n    enforced = \"\"\n\n    # constraint - (Required) The name of the Constraint the Policy is configuring, for example, `serviceuser.services`. Check out the [complete list of available constraints](https://cloud.google.com/resource-manager/docs/organization-policy/understanding-constraints#available_constraints).\n    constraint = \"\"\n\n    # project - (Required) The project id of the project to set the policy for.\n    project = \"\"\n\n    # version - (Optional) Version of the Policy. Default version is 0.\n    version = \"\"\n\n    # boolean_policy - (Optional) A boolean policy is a constraint that is either enforced or not. Structure is documented below.\n    boolean_policy = \"\"\n\n    # list_policy - (Optional) A policy that can define specific values that are allowed or denied for the given constraint. It can also be used to allow or deny all values. Structure is documented below.\n    list_policy = \"\"\n\n    # restore_policy - (Optional) A restore policy is a constraint to restore the default policy. Structure is documented below. \n    restore_policy = \"\"\n\n    # restore_policy - (Optional) A restore policy is a constraint to restore the default policy. Structure is documented below. \n    restore_policy = \"\"\n\n    # allow - (Optional) One or the other must be set.\n    allow = \"\"\n\n    # suggested_values - (Optional) The Google Cloud Console will try to default to a configuration that matches the value specified in this field.\n    suggested_values = \"\"\n\n    # all - (Optional) The policy allows or denies all values.\n    all = \"\"\n\n    # values - (Optional) The policy can define specific values that are allowed or denied.\n    values = \"\"\n\n    # values - (Optional) The policy can define specific values that are allowed or denied.\n    values = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the organization policy. \"etag\" is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other.\n    # \"update_time\" - (Computed) The timestamp in RFC3339 UTC \"Zulu\" format, accurate to nanoseconds, representing when the variable was last updated. Example: \"2016-10-09T12:33:37.578138407Z\".\n}",
        "description": "Allows management of Organization policies for a Google Project. For more information see\n[the official\ndocumentation](https://cloud.google.com/resource-manager/docs/organization-policy/overview) and\n[API](https://cloud.google.com/resource-manager/reference/rest/v1/projects/setOrgPolicy).",
        "prefix": "google-project-organization-policy"
    },
    "google-project-service-x": {
        "body": "resource \"google_project_service\" \"$1\" {\n    # service - (Required) The service to enable.\n    service = \"\"\n\n    # project - (Optional) The project ID. If not provided, the provider project is used.\n    project = \"\"\n\n    # disable_on_destroy - (Optional) If true, disable the service when the terraform resource is destroyed.  Defaults to true.  May be useful in the event that a project is long-lived but the infrastructure running in that project changes frequently.\n    disable_on_destroy = \"\"\n\n    # Exported Attributes\n}",
        "description": "Allows management of a single API service for an existing Google Cloud Platform project.  For a list of services available, visit the\n[API library page](https://console.cloud.google.com/apis/library) or run `gcloud services list`. ~> **Note:** This resource _must not_ be used in conjunction with\n   `google_project_services` or they will fight over which services should be enabled.",
        "prefix": "google-project-service-x"
    },
    "google-project-services": {
        "body": "resource \"google_project_services\" \"$1\" {\n    # services - (Required) The list of services that are enabled. Supports   update.\n    services = \"\"\n\n    # project - (Required) The project ID.   Changing this forces Terraform to attempt to disable all previously managed   API services in the previous project.\n    project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Allows management of enabled API services for an existing Google Cloud\nPlatform project. Services in an existing project that are not defined\nin the config will be removed. For a list of services available, visit the\n[API library page](https://console.cloud.google.com/apis/library) or run `gcloud services list`. ~> **Note:** This resource attempts to be the authoritative source on *all* enabled APIs, which often\n\tleads to conflicts when certain actions enable other APIs. If you do not need to ensure that\n\t*exclusively* a particular set of APIs are enabled, you should most likely use the\n\t[google_project_service](google_project_service.html) resource, one resource per API.",
        "prefix": "google-project-services"
    },
    "google-project-usage-export-bucket": {
        "body": "resource \"google_project_usage_export_bucket\" \"$1\" {\n    # bucket_name - (Required) The bucket to store reports in.\n    bucket_name = \"\"\n\n    # prefix - (Optional) A prefix for the reports, for instance, the project name.\n    prefix = \"\"\n\n    # project - (Optional) The project to set the export bucket on. If it is not provided, the provider project is used.\n    project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Sets up a usage export bucket for a particular project.  A usage export bucket\nis a pre-configured GCS bucket which is set up to receive daily and monthly\nreports of the GCE resources used. For more information see the [Docs](https://cloud.google.com/compute/docs/usage-export)\nand for further details, the\n[API Documentation](https://cloud.google.com/compute/docs/reference/rest/beta/projects/setUsageExportBucket). ~> **Note:** You should specify only one of these per project.  If there are two or more\nthey will fight over which bucket the reports should be stored in.  It is\nsafe to have multiple resources with the same backing bucket.",
        "prefix": "google-project-usage-export-bucket"
    },
    "google-project-x": {
        "body": "resource \"google_project\" \"$1\" {\n    # location_id - (Required) The [location](https://cloud.google.com/appengine/docs/locations)\n    location_id = \"\"\n\n    # project_id - (Required) The project ID. Changing this forces a new project to be created.\n    project_id = \"\"\n\n    # name - (Required) The display name of the project.\n    name = \"\"\n\n    # org_id - (Optional) The numeric ID of the organization this project belongs to.   Changing this forces a new project to be created.  Only one of   `org_id` or `folder_id` may be specified. If the `org_id` is   specified then the project is created at the top level. Changing   this forces the project to be migrated to the newly specified   organization.\n    org_id = \"\"\n\n    # folder_id - (Optional) The numeric ID of the folder this project should be  created under. Only one of `org_id` or `folder_id` may be  specified. If the `folder_id` is specified, then the project is  created under the specified folder. Changing this forces the  project to be migrated to the newly specified folder.\n    folder_id = \"\"\n\n    # billing_account - (Optional) The alphanumeric ID of the billing account this project   belongs to. The user or service account performing this operation with Terraform   must have Billing Account Administrator privileges (`roles/billing.admin`) in   the organization. See [Google Cloud Billing API Access Control](https://cloud.google.com/billing/v1/how-tos/access-control)   for more details.\n    billing_account = \"\"\n\n    # skip_delete - (Optional) If true, the Terraform resource can be deleted   without deleting the Project via the Google API.\n    skip_delete = \"\"\n\n    # policy_data - (Optional) (Deprecated) The IAM policy associated with the project.   This argument is no longer supported, and will be removed in a future version   of Terraform. It should be replaced with a `google_project_iam_policy` resource.\n    policy_data = \"\"\n\n    # labels - (Optional) A set of key/value label pairs to assign to the project.\n    labels = \"\"\n\n    # auto_create_network - (Optional) Create the 'default' network automatically.  Default true.   Note: this might be more accurately described as \"Delete Default Network\", since the network   is created automatically then deleted before project creation returns, but we choose this   name to match the GCP Console UI. Setting this field to false will enable the Compute Engine   API which is required to delete the network.\n    auto_create_network = \"\"\n\n    # app_engine - (Optional) A block of configuration to enable an App Engine app. Setting this  field will enabled the App Engine Admin API, which is required to manage the app.\n    app_engine = \"\"\n\n    # app_engine - (Optional) A block of configuration to enable an App Engine app. Setting this  field will enabled the App Engine Admin API, which is required to manage the app.\n    app_engine = \"\"\n\n    # auth_domain - (Optional) The domain to authenticate users with when using App Engine's User API.\n    auth_domain = \"\"\n\n    # app_engine - (Optional) A block of configuration to enable an App Engine app. Setting this  field will enabled the App Engine Admin API, which is required to manage the app.\n    app_engine = \"\"\n\n    # serving_status - (Optional) The serving status of the app. Note that this can't be updated at the moment.\n    serving_status = \"\"\n\n    # app_engine - (Optional) A block of configuration to enable an App Engine app. Setting this  field will enabled the App Engine Admin API, which is required to manage the app.\n    app_engine = \"\"\n\n    # feature_settings - (Optional) A block of optional settings to configure specific App Engine features:\n    feature_settings = \"\"\n\n    # split_health_checks - (Optional) Set to false to use the legacy health check instead of the readiness\n    split_health_checks = \"\"\n\n    # app_engine - (Optional) A block of configuration to enable an App Engine app. Setting this  field will enabled the App Engine Admin API, which is required to manage the app.\n    app_engine = \"\"\n\n    # app_engine - (Optional) A block of configuration to enable an App Engine app. Setting this  field will enabled the App Engine Admin API, which is required to manage the app.\n    app_engine = \"\"\n\n    # Exported Attributes\n    # \"number\" - The numeric identifier of the project.\n    # \"policy_etag\" - (Deprecated) The etag of the project's IAM policy, used to   determine if the IAM policy has changed. Please use \"google_project_iam_policy\"'s   \"etag\" property instead; future versions of Terraform will remove the \"policy_etag\"   attribute\n    # \"app_engine.0.name\" - Unique name of the app, usually \"apps/{PROJECT_ID}\"\n    # \"app_engine.0.url_dispatch_rule\" - A list of dispatch rule blocks. Each block has a \"domain\", \"path\", and \"service\" field.\n    # \"app_engine.0.name\" - Unique name of the app, usually \"apps/{PROJECT_ID}\"\n    # \"app_engine.0.code_bucket\" - The GCS bucket code is being stored in for this app.\n    # \"app_engine.0.name\" - Unique name of the app, usually \"apps/{PROJECT_ID}\"\n    # \"app_engine.0.default_hostname\" - The default hostname for this app.\n    # \"app_engine.0.name\" - Unique name of the app, usually \"apps/{PROJECT_ID}\"\n    # \"app_engine.0.default_bucket\" - The GCS bucket content is being stored in for this app.\n    # \"app_engine.0.name\" - Unique name of the app, usually \"apps/{PROJECT_ID}\"\n    # \"app_engine.0.gcr_domain\" - The GCR domain used for storing managed Docker images for this app.\n    # \"app_engine.0.name\" - Unique name of the app, usually \"apps/{PROJECT_ID}\"\n}",
        "description": "Allows creation and management of a Google Cloud Platform project. Projects created with this resource must be associated with an Organization.\nSee the [Organization documentation](https://cloud.google.com/resource-manager/docs/quickstarts) for more details. The service account used to run Terraform when creating a `google_project`\nresource must have `roles/resourcemanager.projectCreator`. See the\n[Access Control for Organizations Using IAM](https://cloud.google.com/resource-manager/docs/access-control-org)\ndoc for more information. Note that prior to 0.8.5, `google_project` functioned like a data source,\nmeaning any project referenced by it had to be created and managed outside\nTerraform. As of 0.8.5, `google_project` functions like any other Terraform\nresource, with Terraform creating and managing the project. To replicate the old\nbehavior, either: Use the project ID directly in whatever is referencing the project, using the [google_project_iam_policy](/docs/providers/google/r/google_project_iam.html) to replace the old `policy_data` property.  Use the [import](/docs/import/usage.html) functionality to import your pre-existing project into Terraform, where it can be referenced and used just like always, keeping in mind that Terraform will attempt to undo any changes made outside Terraform.  ~> It's important to note that any project resources that were added to your Terraform config\nprior to 0.8.5 will continue to function as they always have, and will not be managed by\nTerraform. Only newly added projects are affected.",
        "prefix": "google-project-x"
    },
    "google-pubsub-subscription-iam": {
        "body": "resource \"google_pubsub_subscription_iam\" \"$1\" {\n    # role - (Required) The role that should be applied. Only one   `google_pubsub_subscription_iam_binding` can be used per role. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # subscription - (Required) The subscription name or id to bind to attach IAM policy to.\n    subscription = \"\"\n\n    # policy_data - (Optional) (Required only by `google_pubsub_subscription_iam_policy`) The policy data generated by a `google_iam_policy` data source.\n    policy_data = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it\n    project = \"\"\n\n    # policy_data - (Optional) (Required only by `google_pubsub_subscription_iam_policy`) The policy data generated by a `google_iam_policy` data source.\n    policy_data = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the subscription's IAM policy.\n    # \"policy_data\" - (Required only by \"google_pubsub_subscription_iam_policy\") The policy data generated by a \"google_iam_policy\" data source.\n}",
        "description": "Three different resources help you manage your IAM policy for pubsub subscription. Each of these resources serves a different use case: `google_pubsub_subscription_iam_policy`: Authoritative. Sets the IAM policy for the subscription and replaces any existing policy already attached.  `google_pubsub_subscription_iam_binding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the subscription are preserved.  `google_pubsub_subscription_iam_member`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the subscription are preserved.  ~> **Note:** `google_pubsub_subscription_iam_policy` **cannot** be used in conjunction with `google_pubsub_subscription_iam_binding` and `google_pubsub_subscription_iam_member` or they will fight over what your policy should be. ~> **Note:** `google_pubsub_subscription_iam_binding` resources **can be** used in conjunction with `google_pubsub_subscription_iam_member` resources **only if** they do not grant privilege to the same role.",
        "prefix": "google-pubsub-subscription-iam"
    },
    "google-pubsub-subscription-x": {
        "body": "resource \"google_pubsub_subscription\" \"$1\" {\n    # push_endpoint - (Required) The URL of the endpoint to which messages should   be pushed. Changing this forces a new resource to be created.\n    push_endpoint = \"\"\n\n    # topic - (Required) The topic name or id to bind this subscription to, required by pubsub.   Changing this forces a new resource to be created.\n    topic = \"\"\n\n    # name - (Required) A unique name for the resource, required by pubsub.   Changing this forces a new resource to be created.\n    name = \"\"\n\n    # ack_deadline_seconds - (Optional) The maximum number of seconds a   subscriber has to acknowledge a received message, otherwise the message is   redelivered. Changing this forces a new resource to be created.\n    ack_deadline_seconds = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # push_config - (Optional) Block configuration for push options. More   configuration options are detailed below.\n    push_config = \"\"\n\n    # attributes - (Optional) Key-value pairs of API supported attributes used   to control aspects of the message delivery. Currently, only   `x-goog-version` is supported, which controls the format of the data   delivery. For more information, read [the API docs   here](https://cloud.google.com/pubsub/reference/rest/v1/projects.subscriptions#PushConfig.FIELDS.attributes).   Changing this forces a new resource to be created.\n    attributes = \"\"\n\n    # Exported Attributes\n    # \"path\" - Path of the subscription in the format \"projects/{project}/subscriptions/{sub}\"\n    # \"attributes\" - (Optional) Key-value pairs of API supported attributes used   to control aspects of the message delivery. Currently, only   \"x-goog-version\" is supported, which controls the format of the data   delivery. For more information, read [the API docs   here](https://cloud.google.com/pubsub/reference/rest/v1/projects.subscriptions#PushConfig.FIELDS.attributes).   Changing this forces a new resource to be created.\n}",
        "description": "Creates a subscription in Google's pubsub queueing system. For more information see\n[the official documentation](https://cloud.google.com/pubsub/docs) and\n[API](https://cloud.google.com/pubsub/docs/reference/rest/v1/projects.subscriptions).",
        "prefix": "google-pubsub-subscription-x"
    },
    "google-pubsub-topic-iam": {
        "body": "resource \"google_pubsub_topic_iam\" \"$1\" {\n    # role - (Required) The role that should be applied. Only one   `google_pubsub_topic_iam_binding` can be used per role. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # topic - (Required) The topic name or id to bind to attach IAM policy to.\n    topic = \"\"\n\n    # project - (Optional) The project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # policy_data - (Optional) (Required only by `google_pubsub_topic_iam_policy`) The policy data generated by a `google_iam_policy` data source.\n    policy_data = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the topic's IAM policy.\n    # \"policy_data\" - (Required only by \"google_pubsub_topic_iam_policy\") The policy data generated by a \"google_iam_policy\" data source.\n}",
        "description": "Three different resources help you manage your IAM policy for pubsub topic. Each of these resources serves a different use case: `google_pubsub_topic_iam_policy`: Authoritative. Sets the IAM policy for the topic and replaces any existing policy already attached.  `google_pubsub_topic_iam_binding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the topic are preserved.  `google_pubsub_topic_iam_member`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the topic are preserved.  ~> **Note:** `google_pubsub_topic_iam_policy` **cannot** be used in conjunction with `google_pubsub_topic_iam_binding` and `google_pubsub_topic_iam_member` or they will fight over what your policy should be. ~> **Note:** `google_pubsub_topic_iam_binding` resources **can be** used in conjunction with `google_pubsub_topic_iam_member` resources **only if** they do not grant privilege to the same role.",
        "prefix": "google-pubsub-topic-iam"
    },
    "google-pubsub-topic-x": {
        "body": "resource \"google_pubsub_topic\" \"$1\" {\n    # name - (Required) A unique name for the pubsub topic.\n    name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it\n    project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Creates a topic in Google's pubsub queueing system. For more information see\n[the official documentation](https://cloud.google.com/pubsub/docs) and\n[API](https://cloud.google.com/pubsub/docs/reference/rest/v1/projects.topics).",
        "prefix": "google-pubsub-topic-x"
    },
    "google-runtimeconfig-config": {
        "body": "resource \"google_runtimeconfig_config\" \"$1\" {\n    # name - (Required) The name of the runtime config.\n    name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it is not provided, the provider project is used.\n    project = \"\"\n\n    # description - (Optional) The description to associate with the runtime config.\n    description = \"\"\n\n    # Exported Attributes\n}",
        "description": "Manages a RuntimeConfig resource in Google Cloud. For more information, see the\n[official documentation](https://cloud.google.com/deployment-manager/runtime-configurator/),\nor the\n[JSON API](https://cloud.google.com/deployment-manager/runtime-configurator/reference/rest/).",
        "prefix": "google-runtimeconfig-config"
    },
    "google-runtimeconfig-variable": {
        "body": "resource \"google_runtimeconfig_variable\" \"$1\" {\n    # text - (Required) The content to associate with the variable. Exactly one of `text` or `variable` must be specified. If `text` is specified, it must be a valid UTF-8 string and less than 4096 bytes in length. If `value` is specified, it must be base64 encoded and less than 4096 bytes in length.\n    text = \"\"\n\n    # text - (Required) The content to associate with the variable. Exactly one of `text` or `variable` must be specified. If `text` is specified, it must be a valid UTF-8 string and less than 4096 bytes in length. If `value` is specified, it must be base64 encoded and less than 4096 bytes in length.\n    text = \"\"\n\n    # parent - (Required) The name of the RuntimeConfig resource containing this variable.\n    parent = \"\"\n\n    # name - (Required) The name of the variable to manage. Note that variable names can be hierarchical using slashes (e.g. \"prod-variables/hostname\").\n    name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it\n    project = \"\"\n\n    # Exported Attributes\n    # \"update_time\" - (Computed) The timestamp in RFC3339 UTC \"Zulu\" format,\n    # \"text\" or \"value\" - (Required) The content to associate with the variable. Exactly one of \"text\" or \"variable\" must be specified. If \"text\" is specified, it must be a valid UTF-8 string and less than 4096 bytes in length. If \"value\" is specified, it must be base64 encoded and less than 4096 bytes in length.\n}",
        "description": "Manages a RuntimeConfig variable in Google Cloud. For more information, see the\n[official documentation](https://cloud.google.com/deployment-manager/runtime-configurator/),\nor the\n[JSON API](https://cloud.google.com/deployment-manager/runtime-configurator/reference/rest/).",
        "prefix": "google-runtimeconfig-variable"
    },
    "google-service-account-iam": {
        "body": "resource \"google_service_account_iam\" \"$1\" {\n    # role - (Required) The role that should be applied. Only one   `google_service_account_iam_binding` can be used per role. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # service_account_id - (Required) The service account id to apply policy to.\n    service_account_id = \"\"\n\n    # policy_data - (Optional) (Required only by `google_service_account_iam_policy`) The policy data generated by a `google_iam_policy` data source.\n    policy_data = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the service account IAM policy.\n    # \"policy_data\" - (Required only by \"google_service_account_iam_policy\") The policy data generated by a \"google_iam_policy\" data source.\n}",
        "description": "When managing IAM roles, you can treat a service account either as a resource or as an identity. This resource is to add iam policy bindings to a service account resource to configure permissions for who can edit the service account. To configure permissions for a service account to act as an identity that can manage other GCP resources, use the [google_project_iam](google_project_iam.html) set of resources. Three different resources help you manage your IAM policy for a service account. Each of these resources serves a different use case: `google_service_account_iam_policy`: Authoritative. Sets the IAM policy for the service account and replaces any existing policy already attached.  `google_service_account_iam_binding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the service account are preserved.  `google_service_account_iam_member`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the service account are preserved.  ~> **Note:** `google_service_account_iam_policy` **cannot** be used in conjunction with `google_service_account_iam_binding` and `google_service_account_iam_member` or they will fight over what your policy should be. ~> **Note:** `google_service_account_iam_binding` resources **can be** used in conjunction with `google_service_account_iam_member` resources **only if** they do not grant privilege to the same role.",
        "prefix": "google-service-account-iam"
    },
    "google-service-account-key": {
        "body": "resource \"google_service_account_key\" \"$1\" {\n    # service_account_id - (Required) The Service account id of the Key Pair. This can be a string in the format `{ACCOUNT}` or `projects/{PROJECT_ID}/serviceAccounts/{ACCOUNT}`, where `{ACCOUNT}` is the email address or unique id of the service account. If the `{ACCOUNT}` syntax is used, the project will be inferred from the account.\n    service_account_id = \"\"\n\n    # key_algorithm - (Optional) The algorithm used to generate the key. KEY_ALG_RSA_2048 is the default algorithm. Valid values are listed at [ServiceAccountPrivateKeyType](https://cloud.google.com/iam/reference/rest/v1/projects.serviceAccounts.keys#ServiceAccountKeyAlgorithm) (only used on create)\n    key_algorithm = \"\"\n\n    # public_key_type - (Optional) The output format of the public key requested. X509_PEM is the default output format.\n    public_key_type = \"\"\n\n    # private_key_type - (Optional) The output format of the private key. TYPE_GOOGLE_CREDENTIALS_FILE is the default output format.\n    private_key_type = \"\"\n\n    # pgp_key - (Optional) An optional PGP key to encrypt the resulting private key material. Only used when creating or importing a new key pair. May either be a base64-encoded public key or a `keybase:keybaseusername` string for looking up in Vault.\n    pgp_key = \"\"\n\n    # Exported Attributes\n    # \"name\" - The name used for this key pair\n    # \"public_key\" - The public key, base64 encoded\n    # \"private_key\" - The private key in JSON format, base64 encoded. This is what you normally get as a file when creating service account keys through the CLI or web console. This is only populated when creating a new key, and when no \"pgp_key\" is provided.\n    # \"private_key_encrypted\" \u2013 The private key material, base 64 encoded and encrypted with the given \"pgp_key\". This is only populated when creating a new key and \"pgp_key\" is supplied\n    # \"private_key_fingerprint\" - The MD5 public key fingerprint for the encrypted private key. This is only populated when creating a new key and \"pgp_key\" is supplied\n    # \"valid_after\" - The key can be used after this timestamp. A timestamp in RFC3339 UTC \"Zulu\" format, accurate to nanoseconds. Example: \"2014-10-02T15:01:23.045123456Z\".\n    # \"valid_before\" - The key can be used before this timestamp. A timestamp in RFC3339 UTC \"Zulu\" format, accurate to nanoseconds. Example: \"2014-10-02T15:01:23.045123456Z\".\n}",
        "description": "Creates and manages service account key-pairs, which allow the user to establish identity of a service account outside of GCP. For more information, see [the official documentation](https://cloud.google.com/iam/docs/creating-managing-service-account-keys) and [API](https://cloud.google.com/iam/reference/rest/v1/projects.serviceAccounts.keys).",
        "prefix": "google-service-account-key"
    },
    "google-service-account-x": {
        "body": "resource \"google_service_account\" \"$1\" {\n    # account_id - (Required) The service account ID.   Changing this forces a new service account to be created.\n    account_id = \"\"\n\n    # display_name - (Optional) The display name for the service account.   Can be updated without creating a new resource.\n    display_name = \"\"\n\n    # project - (Optional) The ID of the project that the service account will be created in.   Defaults to the provider project configuration.\n    project = \"\"\n\n    # policy_data - (Optional) (DEPRECATED, Optional) The `google_iam_policy` data source that represents   the IAM policy that will be applied to the service account. The policy will be   merged with any existing policy.   This attribute has been deprecated. Use the [google_service_account_iam_* resources](google_service_account_iam.html) instead.   Deleting this removes the policy declared in Terraform. Any policy bindings   associated with the project before Terraform was used are not deleted.\n    policy_data = \"\"\n\n    # Exported Attributes\n    # \"email\" - The e-mail address of the service account. This value   should be referenced from any \"google_iam_policy\" data sources   that would grant the service account privileges.\n    # \"name\" - The fully-qualified name of the service account.\n    # \"unique_id\" - The unique id of the service account.\n}",
        "description": "Allows management of a [Google Cloud Platform service account](https://cloud.google.com/compute/docs/access/service-accounts)",
        "prefix": "google-service-account-x"
    },
    "google-sourcerepo_repository": {
        "body": "resource \"google_sourcerepo_repository\" \"$1\" {\n    # name - (Required) The name of the repository that will be created.\n    name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it\n    project = \"\"\n\n    # Exported Attributes\n    # \"size\" - The size of the repository.\n    # \"url\" - The url to clone the repository.\n}",
        "description": "For more information, see [the official\ndocumentation](https://cloud.google.com/source-repositories/) and\n[API](https://cloud.google.com/source-repositories/docs/reference/rest/v1/projects.repos)",
        "prefix": "google-sourcerepo_repository"
    },
    "google-spanner-database": {
        "body": "resource \"google_spanner_database\" \"$1\" {\n    # name - (Required) The name of the database.\n    name = \"\"\n\n    # instance - (Required) The name of the instance that will serve the new database.\n    instance = \"\"\n\n    # project - (Optional) The ID of the project in which to look for the `instance` specified. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # ddl - (Optional) An optional list of DDL statements to run inside the newly created  database. Statements can create tables, indexes, etc. These statements execute atomically  with the creation of the database: if there is an error in any statement, the database  is not created.\n    ddl = \"\"\n\n    # Exported Attributes\n    # \"state\" - The current state of the database.\n    # \"ddl\" - (Optional) An optional list of DDL statements to run inside the newly created  database. Statements can create tables, indexes, etc. These statements execute atomically  with the creation of the database: if there is an error in any statement, the database  is not created.\n}",
        "description": "Creates a Google Spanner Database within a Spanner Instance. For more information, see the [official documentation](https://cloud.google.com/spanner/), or the [JSON API](https://cloud.google.com/spanner/docs/reference/rest/v1/projects.instances.databases).",
        "prefix": "google-spanner-database"
    },
    "google-spanner-database-iam": {
        "body": "resource \"google_spanner_database_iam\" \"$1\" {\n    # role - (Required) The role that should be applied. Only one   `google_spanner_database_iam_binding` can be used per role. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # instance - (Required) The name of the Spanner instance the database belongs to.\n    instance = \"\"\n\n    # database - (Required) The name of the Spanner database.\n    database = \"\"\n\n    # policy_data - (Optional) (Required only by `google_spanner_database_iam_policy`) The policy data generated by a `google_iam_policy` data source.\n    policy_data = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the database's IAM policy.\n    # \"project\" - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n}",
        "description": "Three different resources help you manage your IAM policy for a Spanner database. Each of these resources serves a different use case: `google_spanner_database_iam_policy`: Authoritative. Sets the IAM policy for the database and replaces any existing policy already attached.  ~> **Warning:** It's entirely possibly to lock yourself out of your database using `google_spanner_database_iam_policy`. Any permissions granted by default will be removed unless you include them in your config. `google_spanner_database_iam_binding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the database are preserved.  `google_spanner_database_iam_member`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the database are preserved.  ~> **Note:** `google_spanner_database_iam_policy` **cannot** be used in conjunction with `google_spanner_database_iam_binding` and `google_spanner_database_iam_member` or they will fight over what your policy should be. ~> **Note:** `google_spanner_database_iam_binding` resources **can be** used in conjunction with `google_spanner_database_iam_member` resources **only if** they do not grant privilege to the same role.",
        "prefix": "google-spanner-database-iam"
    },
    "google-spanner-instance": {
        "body": "resource \"google_spanner_instance\" \"$1\" {\n    # display_name - (Required) The descriptive name for this instance as it appears  in UIs. Can be updated, however should be kept globally unique to avoid confusion.\n    display_name = \"\"\n\n    # config - (Required) The name of the instance's configuration (similar but not  quite the same as a region) which defines defines the geographic placement and  replication of your databases in this instance. It determines where your data  is stored. Values are typically of the form `regional-europe-west1` , `us-central` etc.  In order to obtain a valid list please consult the  [Configuration section of the docs](https://cloud.google.com/spanner/docs/instances).\n    config = \"\"\n\n    # name - (Optional) (Optional, Computed) The unique name (ID) of the instance. If the name is left   blank, Terraform will randomly generate one when the instance is first   created.\n    name = \"\"\n\n    # num_nodes - (Optional) (Optional, Computed) The number of nodes allocated to this instance.  Defaults to `1`. This can be updated after creation.\n    num_nodes = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # labels - (Optional) A mapping (key/value pairs) of labels to assign to the instance.\n    labels = \"\"\n\n    # Exported Attributes\n    # \"state\" - The current state of the instance.\n    # \"labels\" - (Optional) A mapping (key/value pairs) of labels to assign to the instance.\n}",
        "description": "Creates and manages a Google Spanner Instance. For more information, see the [official documentation](https://cloud.google.com/spanner/), or the [JSON API](https://cloud.google.com/spanner/docs/reference/rest/v1/projects.instances).",
        "prefix": "google-spanner-instance"
    },
    "google-spanner-instance-iam": {
        "body": "resource \"google_spanner_instance_iam\" \"$1\" {\n    # role - (Required) The role that should be applied. Only one   `google_spanner_instance_iam_binding` can be used per role. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # instance - (Required) The name of the instance.\n    instance = \"\"\n\n    # policy_data - (Optional) (Required only by `google_spanner_instance_iam_policy`) The policy data generated by a `google_iam_policy` data source.\n    policy_data = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the instance's IAM policy.\n    # \"project\" - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n}",
        "description": "Three different resources help you manage your IAM policy for a Spanner instance. Each of these resources serves a different use case: `google_spanner_instance_iam_policy`: Authoritative. Sets the IAM policy for the instance and replaces any existing policy already attached.  ~> **Warning:** It's entirely possibly to lock yourself out of your instance using `google_spanner_instance_iam_policy`. Any permissions granted by default will be removed unless you include them in your config. `google_spanner_instance_iam_binding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the instance are preserved.  `google_spanner_instance_iam_member`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the instance are preserved.  ~> **Note:** `google_spanner_instance_iam_policy` **cannot** be used in conjunction with `google_spanner_instance_iam_binding` and `google_spanner_instance_iam_member` or they will fight over what your policy should be. ~> **Note:** `google_spanner_instance_iam_binding` resources **can be** used in conjunction with `google_spanner_instance_iam_member` resources **only if** they do not grant privilege to the same role.",
        "prefix": "google-spanner-instance-iam"
    },
    "google-sql-database-instance": {
        "body": "resource \"google_sql_database_instance\" \"$1\" {\n    # tier - (Required) The machine tier (First Generation) or type (Second Generation) to use. See   [tiers](https://cloud.google.com/sql/docs/admin-api/v1beta4/tiers) for more details and   supported versions. Postgres supports only shared-core machine types such as `db-f1-micro`, and custom   machine types such as `db-custom-2-13312`. See the   [Custom Machine Type Documentation](https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type#create)   to learn about specifying custom machine types.\n    tier = \"\"\n\n    # settings - (Required) The settings to use for the database. The   configuration is detailed below.\n    settings = \"\"\n\n    # region - (Required) The region the instance will sit in. Note, first-generation Cloud SQL instance   regions do not line up with the Google Compute Engine (GCE) regions, and Cloud SQL is not   available in all regions - choose from one of the options listed [here](https://cloud.google.com/sql/docs/mysql/instance-locations).   A valid region must be provided to use this resource. If a region is not provided in the resource definition,   the provider region will be used instead, but this will be an apply-time error for all first-generation   instances *and* for second-generation instances if the provider region is not supported with Cloud SQL.   If you choose not to provide the `region` argument for this resource, make sure you understand this.\n    region = \"\"\n\n    # database_version - (Optional) (Optional, Default: `MYSQL_5_6`) The MySQL version to   use. Can be `MYSQL_5_6`, `MYSQL_5_7` or `POSTGRES_9_6` for second-generation   instances, or `MYSQL_5_5` or `MYSQL_5_6` for first-generation instances.   See [Second Generation Capabilities](https://cloud.google.com/sql/docs/1st-2nd-gen-differences)   for more information. `POSTGRES_9_6` support is in beta.\n    database_version = \"\"\n\n    # name - (Optional) (Optional, Computed) The name of the instance. If the name is left   blank, Terraform will randomly generate one when the instance is first   created. This is done because after a name is used, it cannot be reused for   up to [one week](https://cloud.google.com/sql/docs/delete-instance).\n    name = \"\"\n\n    # master_instance_name - (Optional) The name of the instance that will act as   the master in the replication setup. Note, this requires the master to have   `binary_log_enabled` set, as well as existing backups.\n    master_instance_name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # replica_configuration - (Optional) The configuration for replication. The   configuration is detailed below.\n    replica_configuration = \"\"\n\n    # activation_policy - (Optional) This specifies when the instance should be   active. Can be either `ALWAYS`, `NEVER` or `ON_DEMAND`.\n    activation_policy = \"\"\n\n    # authorized_gae_applications - (Optional) A list of Google App Engine (GAE)   project names that are allowed to access this instance.\n    authorized_gae_applications = \"\"\n\n    # availability_type - (Optional) This specifies whether a PostgreSQL instance   should be set up for high availability (`REGIONAL`) or single zone (`ZONAL`).\n    availability_type = \"\"\n\n    # crash_safe_replication - (Optional) Specific to read instances, indicates   when crash-safe replication flags are enabled.\n    crash_safe_replication = \"\"\n\n    # disk_autoresize - (Optional) (Optional, Second Generation, Default: `true`) Configuration to increase storage size automatically.\n    disk_autoresize = \"\"\n\n    # disk_size - (Optional) (Optional, Second Generation, Default: `10`) The size of data disk, in GB. Size of a running instance cannot be reduced but can be increased.\n    disk_size = \"\"\n\n    # disk_type - (Optional) (Optional, Second Generation, Default: `PD_SSD`) The type of data disk: PD_SSD or PD_HDD.\n    disk_type = \"\"\n\n    # pricing_plan - (Optional) (Optional, First Generation) Pricing plan for this instance, can be one of   `PER_USE` or `PACKAGE`.\n    pricing_plan = \"\"\n\n    # replication_type - (Optional) Replication type for this instance, can be one   of `ASYNCHRONOUS` or `SYNCHRONOUS`.\n    replication_type = \"\"\n\n    # user_labels - (Optional) A set of key/value user label pairs to assign to the instance.\n    user_labels = \"\"\n\n    # name - (Optional) Name of the flag.\n    name = \"\"\n\n    # value - (Optional) Value of the flag.\n    value = \"\"\n\n    # binary_log_enabled - (Optional) True if binary logging is enabled. If   `logging` is false, this must be as well. Cannot be used with Postgres.\n    binary_log_enabled = \"\"\n\n    # enabled - (Optional) True if backup configuration is enabled.\n    enabled = \"\"\n\n    # start_time - (Optional) `HH:MM` format time indicating when backup   configuration starts.\n    start_time = \"\"\n\n    # require_ssl - (Optional) True if mysqld should default to `REQUIRE X509`   for users connecting over IP.\n    require_ssl = \"\"\n\n    # private_network - (Optional) The resource link for the VPC network from which the Cloud SQL instance is accessible for private IP.\n    private_network = \"\"\n\n    # expiration_time - (Optional) The [RFC 3339](https://tools.ietf.org/html/rfc3339) formatted date time string indicating when this whitelist expires.\n    expiration_time = \"\"\n\n    # name - (Optional) A name for this whitelist entry.\n    name = \"\"\n\n    # value - (Optional) A CIDR notation IPv4 or IPv6 address that is allowed to   access this instance. Must be set even if other two attributes are not for   the whitelist to become active.\n    value = \"\"\n\n    # follow_gae_application - (Optional) A GAE application whose zone to remain   in. Must be in the same region as this instance.\n    follow_gae_application = \"\"\n\n    # zone - (Optional) The preferred compute engine   [zone](https://cloud.google.com/compute/docs/zones?hl=en).\n    zone = \"\"\n\n    # day - (Optional) Day of week (`1-7`), starting on Monday\n    day = \"\"\n\n    # hour - (Optional) Hour of day (`0-23`), ignored if `day` not set\n    hour = \"\"\n\n    # update_track - (Optional) Receive updates earlier (`canary`) or later (`stable`)\n    update_track = \"\"\n\n    # ca_certificate - (Optional) PEM representation of the trusted CA's x509   certificate.\n    ca_certificate = \"\"\n\n    # client_certificate - (Optional) PEM representation of the slave's x509   certificate.\n    client_certificate = \"\"\n\n    # client_key - (Optional) PEM representation of the slave's private key. The   corresponding public key in encoded in the `client_certificate`.\n    client_key = \"\"\n\n    # connect_retry_interval - (Optional) (Optional, Default: 60) The number of seconds   between connect retries.\n    connect_retry_interval = \"\"\n\n    # dump_file_path - (Optional) Path to a SQL file in GCS from which slave   instances are created. Format is `gs://bucket/filename`.\n    dump_file_path = \"\"\n\n    # failover_target - (Optional) Specifies if the replica is the failover target.   If the field is set to true the replica will be designated as a failover replica.   If the master instance fails, the replica instance will be promoted as   the new master instance.\n    failover_target = \"\"\n\n    # master_heartbeat_period - (Optional) Time in ms between replication   heartbeats.\n    master_heartbeat_period = \"\"\n\n    # password - (Optional) Password for the replication connection.\n    password = \"\"\n\n    # username - (Optional) Username for replication connection.\n    username = \"\"\n\n    # verify_server_certificate - (Optional) True if the master's common name   value is checked during the SSL handshake.\n    verify_server_certificate = \"\"\n\n    # Exported Attributes\n    # \"first_ip_address\" - The first IPv4 address of the addresses assigned. This is is to support accessing the [first address in the list in a terraform output](https://github.com/terraform-providers/terraform-provider-google/issues/912) when the resource is configured with a \"count\".\n    # \"connection_name\" - The connection name of the instance to be used in connection strings.\n    # \"ip_address.0.ip_address\" - The IPv4 address assigned.\n    # \"ip_address.0.time_to_retire\" - The time this IP address will be retired, in RFC   3339 format.\n    # \"self_link\" - The URI of the created resource.\n    # \"settings.version\" - Used to make sure changes to the \"settings\" block are   atomic.   \n    # \"server_ca_cert.0.cert\" - The CA Certificate used to connect to the SQL Instance via SSL.\n    # \"server_ca_cert.0.common_name\" - The CN valid for the CA Cert.\n    # \"server_ca_cert.0.create_time\" - Creation time of the CA Cert.\n    # \"server_ca_cert.0.expiration_time\" - Expiration time of the CA Cert.\n    # \"server_ca_cert.0.sha1_fingerprint\" - SHA Fingerprint of the CA Cert.\n    # \"service_account_email_address\" - The service account email address assigned to the instance. This property is applicable only to Second Generation instances.\n}",
        "description": "Creates a new Google SQL Database Instance. For more information, see the [official documentation](https://cloud.google.com/sql/),\nor the [JSON API](https://cloud.google.com/sql/docs/admin-api/v1beta4/instances). ~> **NOTE on `google_sql_database_instance`:** - Second-generation instances include a\ndefault 'root'@'%' user with no password. This user will be deleted by Terraform on\ninstance creation. You should use `google_sql_user` to define a custom user with\na restricted host and strong password.",
        "prefix": "google-sql-database-instance"
    },
    "google-sql-database-x": {
        "body": "resource \"google_sql_database\" \"$1\" {\n    # instance - (Required) The name of containing instance.\n    instance = \"\"\n\n    # name - (Required) The name of the database.\n    name = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # charset - (Optional) The charset value. See MySQL's   [Supported Character Sets and Collations](https://dev.mysql.com/doc/refman/5.7/en/charset-charsets.html)   and Postgres' [Character Set Support](https://www.postgresql.org/docs/9.6/static/multibyte.html)   for more details and supported values. Postgres databases are in beta   and have limited `charset` support; they only support a value of `UTF8` at creation time.\n    charset = \"\"\n\n    # collation - (Optional) The collation value. See MySQL's   [Supported Character Sets and Collations](https://dev.mysql.com/doc/refman/5.7/en/charset-charsets.html)   and Postgres' [Collation Support](https://www.postgresql.org/docs/9.6/static/collation.html)   for more details and supported values. Postgres databases are in beta   and have limited `collation` support; they only support a value of `en_US.UTF8` at creation time.\n    collation = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The URI of the created resource.\n    # \"collation\" - (Optional) The collation value. See MySQL's   [Supported Character Sets and Collations](https://dev.mysql.com/doc/refman/5.7/en/charset-charsets.html)   and Postgres' [Collation Support](https://www.postgresql.org/docs/9.6/static/collation.html)   for more details and supported values. Postgres databases are in beta   and have limited \"collation\" support; they only support a value of \"en_US.UTF8\" at creation time.\n}",
        "description": "Creates a new Google SQL Database on a Google SQL Database Instance. For more information, see\nthe [official documentation](https://cloud.google.com/sql/),\nor the [JSON API](https://cloud.google.com/sql/docs/admin-api/v1beta4/databases).",
        "prefix": "google-sql-database-x"
    },
    "google-sql-ssl-cert": {
        "body": "resource \"google_sql_ssl_cert\" \"$1\" {\n    # common_name - (Required) The common name to be used in the certificate to identify the    client. Constrained to [a-zA-Z.-_ ]+. Changing this forces a new resource to be created.\n    common_name = \"\"\n\n    # instance - (Required) The name of the Cloud SQL instance. Changing this   forces a new resource to be created.\n    instance = \"\"\n\n    # Exported Attributes\n    # \"sha1_fingerprint\" - The SHA1 Fingerprint of the certificate.\n    # \"common_name\" - (Required) The common name to be used in the certificate to identify the    client. Constrained to [a-zA-Z.-_ ]+. Changing this forces a new resource to be created.\n    # \"private_key\" - The private key associated with the client certificate.\n    # \"common_name\" - (Required) The common name to be used in the certificate to identify the    client. Constrained to [a-zA-Z.-_ ]+. Changing this forces a new resource to be created.\n    # \"server_ca_cert\" - The CA cert of the server this client cert was generated from.\n    # \"common_name\" - (Required) The common name to be used in the certificate to identify the    client. Constrained to [a-zA-Z.-_ ]+. Changing this forces a new resource to be created.\n    # \"cert\" - The actual certificate data for this client certificate.\n    # \"common_name\" - (Required) The common name to be used in the certificate to identify the    client. Constrained to [a-zA-Z.-_ ]+. Changing this forces a new resource to be created.\n    # \"cert_serial_number\" - The serial number extracted from the certificate data.\n    # \"common_name\" - (Required) The common name to be used in the certificate to identify the    client. Constrained to [a-zA-Z.-_ ]+. Changing this forces a new resource to be created.\n    # \"create_time\" - The time when the certificate was created in RFC 3339 format, \n    # \"common_name\" - (Required) The common name to be used in the certificate to identify the    client. Constrained to [a-zA-Z.-_ ]+. Changing this forces a new resource to be created.\n    # \"expiration_time\" - The time when the certificate expires in RFC 3339 format, \n    # \"common_name\" - (Required) The common name to be used in the certificate to identify the    client. Constrained to [a-zA-Z.-_ ]+. Changing this forces a new resource to be created.\n}",
        "description": "Creates a new Google SQL SSL Cert on a Google SQL Instance. For more information, see the [official documentation](https://cloud.google.com/sql/), or the [JSON API](https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/sslCerts). ~> **Note:** All arguments including the private key will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](/docs/state/sensitive-data.html).",
        "prefix": "google-sql-ssl-cert"
    },
    "google-sql-user": {
        "body": "resource \"google_sql_user\" \"$1\" {\n    # name - (Required) The name of the user. Changing this forces a new resource   to be created.\n    name = \"\"\n\n    # instance - (Required) The name of the Cloud SQL instance. Changing this   forces a new resource to be created.\n    instance = \"\"\n\n    # password - (Optional) The password for the user. Can be updated.\n    password = \"\"\n\n    # host - (Optional) The host the user can connect from. This is only supported   for MySQL instances. Don't set this field for PostgreSQL instances.   Can be an IP address. Changing this forces a new resource to be created.\n    host = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # Exported Attributes\n}",
        "description": "Creates a new Google SQL User on a Google SQL User Instance. For more information, see the [official documentation](https://cloud.google.com/sql/), or the [JSON API](https://cloud.google.com/sql/docs/admin-api/v1beta4/users). ~> **Note:** All arguments including the username and password will be stored in the raw state as plain-text.\n[Read more about sensitive data in state](/docs/state/sensitive-data.html). Passwords will not be retrieved when running\n\"terraform import\".",
        "prefix": "google-sql-user"
    },
    "google-storage-bucket-acl": {
        "body": "resource \"google_storage_bucket_acl\" \"$1\" {\n    # bucket - (Required) The name of the bucket it applies to.\n    bucket = \"\"\n\n    # predefined_acl - (Optional) The [canned GCS ACL](https://cloud.google.com/storage/docs/access-control/lists#predefined-acl) to apply. Must be set if `role_entity` is not.\n    predefined_acl = \"\"\n\n    # role_entity - (Optional) List of role/entity pairs in the form `ROLE:entity`. See [GCS Bucket ACL documentation](https://cloud.google.com/storage/docs/json_api/v1/bucketAccessControls)  for more details. Must be set if `predefined_acl` is not.\n    role_entity = \"\"\n\n    # default_acl - (Optional) Configure this ACL to be the default ACL.\n    default_acl = \"\"\n\n    # Exported Attributes\n}",
        "description": "Creates a new bucket ACL in Google cloud storage service (GCS). For more information see \n[the official documentation](https://cloud.google.com/storage/docs/access-control/lists) \nand \n[API](https://cloud.google.com/storage/docs/json_api/v1/bucketAccessControls).",
        "prefix": "google-storage-bucket-acl"
    },
    "google-storage-bucket-iam": {
        "body": "resource \"google_storage_bucket_iam\" \"$1\" {\n    # role - (Required) The role that should be applied. Note that custom roles must be of the format   `[projects|organizations]/{parent-name}/roles/{role-name}`.\n    role = \"\"\n\n    # bucket - (Required) The name of the bucket it applies to.\n    bucket = \"\"\n\n    # Exported Attributes\n    # \"etag\" - (Computed) The etag of the storage bucket's IAM policy.\n    # \"role\" - (Required) The role that should be applied. Note that custom roles must be of the format   \"[projects|organizations]/{parent-name}/roles/{role-name}\".\n}",
        "description": "Three different resources help you manage your IAM policy for storage bucket. Each of these resources serves a different use case: `google_storage_bucket_iam_binding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the storage bucket are preserved.  `google_storage_bucket_iam_member`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the storage bucket are preserved.  `google_storage_bucket_iam_policy`: Setting a policy removes all other permissions on the bucket, and if done incorrectly, there's a real chance you will lock yourself out of the bucket. If possible for your use case, using multiple google_storage_bucket_iam_binding resources will be much safer. See the usage example on how to work with policy correctly.  ~> **Note:** `google_storage_bucket_iam_binding` resources **can be** used in conjunction with `google_storage_bucket_iam_member` resources **only if** they do not grant privilege to the same role.",
        "prefix": "google-storage-bucket-iam"
    },
    "google-storage-bucket-object": {
        "body": "resource \"google_storage_bucket_object\" \"$1\" {\n    # name - (Required) The name of the object.\n    name = \"\"\n\n    # bucket - (Required) The name of the containing bucket.\n    bucket = \"\"\n\n    # content - (Optional) Data as `string` to be uploaded. Must be defined if   `source` is not.\n    content = \"\"\n\n    # source - (Optional) A path to the data you want to upload. Must be defined   if `content` is not.\n    source = \"\"\n\n    # cache_control - (Optional) [Cache-Control](https://tools.ietf.org/html/rfc7234#section-5.2)   directive to specify caching behavior of object data. If omitted and object is accessible to all anonymous users, the default will be public, max-age=3600\n    cache_control = \"\"\n\n    # content_disposition - (Optional) [Content-Disposition](https://tools.ietf.org/html/rfc6266) of the object data.\n    content_disposition = \"\"\n\n    # content_encoding - (Optional) [Content-Encoding](https://tools.ietf.org/html/rfc7231#section-3.1.2.2) of the object data.\n    content_encoding = \"\"\n\n    # content_language - (Optional) [Content-Language](https://tools.ietf.org/html/rfc7231#section-3.1.3.2) of the object data.\n    content_language = \"\"\n\n    # content_type - (Optional) [Content-Type](https://tools.ietf.org/html/rfc7231#section-3.1.1.5) of the object data. Defaults to \"application/octet-stream\" or \"text/plain; charset=utf-8\".\n    content_type = \"\"\n\n    # storage_class - (Optional) The [StorageClass](https://cloud.google.com/storage/docs/storage-classes) of the new bucket object.   Supported values include: `MULTI_REGIONAL`, `REGIONAL`, `NEARLINE`, `COLDLINE`. If not provided, this defaults to the bucket's default   storage class or to a [standard](https://cloud.google.com/storage/docs/storage-classes#standard) class.\n    storage_class = \"\"\n\n    # Exported Attributes\n    # \"crc32c\" - (Computed) Base 64 CRC32 hash of the uploaded data.\n    # \"md5hash\" - (Computed) Base 64 MD5 hash of the uploaded data.\n}",
        "description": "Creates a new object inside an existing bucket in Google cloud storage service (GCS). \n[ACLs](https://cloud.google.com/storage/docs/access-control/lists) can be applied using the `google_storage_object_acl` resource.\n For more information see \n[the official documentation](https://cloud.google.com/storage/docs/key-terms#objects) \nand \n[API](https://cloud.google.com/storage/docs/json_api/v1/objects).",
        "prefix": "google-storage-bucket-object"
    },
    "google-storage-bucket-x": {
        "body": "resource \"google_storage_bucket\" \"$1\" {\n    # log_bucket - (Required) The bucket that will receive log objects.\n    log_bucket = \"\"\n\n    # condition - (Required) The Lifecycle Rule's condition configuration. A single block of this type is supported. Structure is documented below.\n    condition = \"\"\n\n    # action - (Required) The Lifecycle Rule's action configuration. A single block of this type is supported. Structure is documented below.\n    action = \"\"\n\n    # name - (Required) The name of the bucket.\n    name = \"\"\n\n    # force_destroy - (Optional) (Optional, Default: false) When deleting a bucket, this   boolean option will delete all contained objects. If you try to delete a   bucket that contains objects, Terraform will fail that run.\n    force_destroy = \"\"\n\n    # location - (Optional) (Optional, Default: 'US') The [GCS location](https://cloud.google.com/storage/docs/bucket-locations)\n    location = \"\"\n\n    # project - (Optional) The ID of the project in which the resource belongs. If it   is not provided, the provider project is used.\n    project = \"\"\n\n    # storage_class - (Optional) The [Storage Class](https://cloud.google.com/storage/docs/storage-classes) of the new bucket. Supported values include: `MULTI_REGIONAL`, `REGIONAL`, `NEARLINE`, `COLDLINE`.\n    storage_class = \"\"\n\n    # lifecycle_rule - (Optional) The bucket's [Lifecycle Rules](https://cloud.google.com/storage/docs/lifecycle#configuration) configuration. Multiple blocks of this type are permitted. Structure is documented below.\n    lifecycle_rule = \"\"\n\n    # versioning - (Optional) The bucket's [Versioning](https://cloud.google.com/storage/docs/object-versioning) configuration.\n    versioning = \"\"\n\n    # website - (Optional) Configuration if the bucket acts as a website. Structure is documented below.\n    website = \"\"\n\n    # cors - (Optional) The bucket's [Cross-Origin Resource Sharing (CORS)](https://www.w3.org/TR/cors/) configuration. Multiple blocks of this type are permitted. Structure is documented below.\n    cors = \"\"\n\n    # labels - (Optional) A set of key/value label pairs to assign to the bucket.\n    labels = \"\"\n\n    # logging - (Optional) The bucket's [Access & Storage Logs](https://cloud.google.com/storage/docs/access-logs) configuration.\n    logging = \"\"\n\n    # encryption - (Optional) The bucket's encryption configuration.\n    encryption = \"\"\n\n    # type - (Optional) The type of the action of this Lifecycle Rule. Supported values include: `Delete` and `SetStorageClass`.\n    type = \"\"\n\n    # storage_class - (Optional) (Required if action type is `SetStorageClass`) The target [Storage Class](https://cloud.google.com/storage/docs/storage-classes) of objects affected by this Lifecycle Rule. Supported values include: `MULTI_REGIONAL`, `REGIONAL`, `NEARLINE`, `COLDLINE`.\n    storage_class = \"\"\n\n    # age - (Optional) Minimum age of an object in days to satisfy this condition.\n    age = \"\"\n\n    # created_before - (Optional) Creation date of an object in RFC 3339 (e.g. `2017-06-13`) to satisfy this condition.\n    created_before = \"\"\n\n    # is_live - (Optional) Defaults to `false` to match archived objects. If `true`, this condition matches live objects. Unversioned buckets have only live objects.\n    is_live = \"\"\n\n    # matches_storage_class - (Optional) [Storage Class](https://cloud.google.com/storage/docs/storage-classes) of objects to satisfy this condition. Supported values include: `MULTI_REGIONAL`, `REGIONAL`, `NEARLINE`, `COLDLINE`, `STANDARD`, `DURABLE_REDUCED_AVAILABILITY`.\n    matches_storage_class = \"\"\n\n    # num_newer_versions - (Optional) Relevant only for versioned objects. The number of newer versions of an object to satisfy this condition.\n    num_newer_versions = \"\"\n\n    # enabled - (Optional) While set to `true`, versioning is fully enabled for this bucket.\n    enabled = \"\"\n\n    # num_newer_versions - (Optional) Relevant only for versioned objects. The number of newer versions of an object to satisfy this condition.\n    num_newer_versions = \"\"\n\n    # main_page_suffix - (Optional) Behaves as the bucket's directory index where   missing objects are treated as potential directories.\n    main_page_suffix = \"\"\n\n    # not_found_page - (Optional) The custom object to return when a requested   resource is not found.\n    not_found_page = \"\"\n\n    # origin - (Optional) The list of [Origins](https://tools.ietf.org/html/rfc6454) eligible to receive CORS response headers. Note: \"*\" is permitted in the list of origins, and means \"any Origin\".\n    origin = \"\"\n\n    # method - (Optional) The list of HTTP methods on which to include CORS response headers, (GET, OPTIONS, POST, etc) Note: \"*\" is permitted in the list of methods, and means \"any method\".\n    method = \"\"\n\n    # response_header - (Optional) The list of HTTP headers other than the [simple response headers](https://www.w3.org/TR/cors/#simple-response-header) to give permission for the user-agent to share across domains.\n    response_header = \"\"\n\n    # max_age_seconds - (Optional) The value, in seconds, to return in the [Access-Control-Max-Age header](https://www.w3.org/TR/cors/#access-control-max-age-response-header) used in preflight responses.\n    max_age_seconds = \"\"\n\n    # log_object_prefix - (Optional) (Optional, Computed) The object prefix for log objects. If it's not provided,   by default GCS sets this to this bucket's name.\n    log_object_prefix = \"\"\n\n    # default_kms_key_name - (Optional) `default_kms_key_name`: A Cloud KMS key that will be used to encrypt objects inserted into this bucket, if no encryption method is specified.\n    default_kms_key_name = \"\"\n\n    # log_object_prefix - (Optional) (Optional, Computed) The object prefix for log objects. If it's not provided,   by default GCS sets this to this bucket's name.\n    log_object_prefix = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The URI of the created resource.\n    # \"url\" - The base URL of the bucket, in the format \"gs://<bucket-name>\".\n}",
        "description": "Creates a new bucket in Google cloud storage service (GCS).\nOnce a bucket has been created, its location can't be changed.\n[ACLs](https://cloud.google.com/storage/docs/access-control/lists) can be applied\nusing the [`google_storage_bucket_acl` resource](/docs/providers/google/r/storage_bucket_acl.html). For more information see\n[the official documentation](https://cloud.google.com/storage/docs/overview)\nand\n[API](https://cloud.google.com/storage/docs/json_api/v1/buckets).",
        "prefix": "google-storage-bucket-x"
    },
    "google-storage-default-object-acl": {
        "body": "resource \"google_storage_default_object_acl\" \"$1\" {\n    # role_entity - (Required) List of role/entity pairs in the form `ROLE:entity`. See [GCS Object ACL documentation](https://cloud.google.com/storage/docs/json_api/v1/objectAccessControls) for more details.\n    role_entity = \"\"\n\n    # bucket - (Required) The name of the bucket it applies to.\n    bucket = \"\"\n\n    # Exported Attributes\n}",
        "description": "Creates a new default object ACL in Google Cloud Storage service (GCS). For more information see -> Note that for each object, its creator will have the `\"OWNER\"` role in addition\nto the default ACL that has been defined. For more information see\n[the official documentation](https://cloud.google.com/storage/docs/access-control/lists) \nand \n[API](https://cloud.google.com/storage/docs/json_api/v1/defaultObjectAccessControls). -> Want fine-grained control over default object ACLs? Use `google_storage_default_object_access_control`\nto control individual role entity pairs.",
        "prefix": "google-storage-default-object-acl"
    },
    "google-storage-notification": {
        "body": "resource \"google_storage_notification\" \"$1\" {\n    # topic - (Required) The Cloud PubSub topic to which this subscription publishes. Expects either the    topic name, assumed to belong to the default GCP provider project, or the project-level name,    i.e. `projects/my-gcp-project/topics/my-topic` or `my-topic`.   \n    topic = \"\"\n\n    # payload_format - (Required) The desired content of the Payload. One of `\"JSON_API_V1\"` or `\"NONE\"`.\n    payload_format = \"\"\n\n    # bucket - (Required) The name of the bucket.\n    bucket = \"\"\n\n    # custom_attributes - (Optional)  A set of key/value attribute pairs to attach to each Cloud PubSub message published for this notification subscription\n    custom_attributes = \"\"\n\n    # event_types - (Optional) List of event type filters for this notification config. If not specified, Cloud Storage will send notifications for all event types. The valid types are: `\"OBJECT_FINALIZE\"`, `\"OBJECT_METADATA_UPDATE\"`, `\"OBJECT_DELETE\"`, `\"OBJECT_ARCHIVE\"`\n    event_types = \"\"\n\n    # object_name_prefix - (Optional) Specifies a prefix path filter for this notification config. Cloud Storage will only send notifications for objects in this bucket whose names begin with the specified prefix.\n    object_name_prefix = \"\"\n\n    # Exported Attributes\n    # \"self_link\" - The URI of the created resource.\n    # \"object_name_prefix\" - (Optional) Specifies a prefix path filter for this notification config. Cloud Storage will only send notifications for objects in this bucket whose names begin with the specified prefix.\n}",
        "description": "Creates a new notification configuration on a specified bucket, establishing a flow of event notifications from GCS to a Cloud Pub/Sub topic.\n For more information see \n[the official documentation](https://cloud.google.com/storage/docs/pubsub-notifications) \nand \n[API](https://cloud.google.com/storage/docs/json_api/v1/notifications). In order to enable notifications, a special Google Cloud Storage service account unique to the project\nmust have the IAM permission \"projects.topics.publish\" for a Cloud Pub/Sub topic in the project. To get the service\naccount's email address, use the `google_storage_project_service_account` datasource's `email_address` value, and see below\nfor an example of enabling notifications by granting the correct IAM permission. See\n[the notifications documentation](https://cloud.google.com/storage/docs/gsutil/commands/notification) for more details.",
        "prefix": "google-storage-notification"
    },
    "google-storage-object-acl": {
        "body": "resource \"google_storage_object_acl\" \"$1\" {\n    # object - (Required) The name of the object it applies to.\n    object = \"\"\n\n    # bucket - (Required) The name of the bucket it applies to.\n    bucket = \"\"\n\n    # predefined_acl - (Optional) The [canned GCS ACL](https://cloud.google.com/storage/docs/access-control#predefined-acl) to apply. Must be set if `role_entity` is not.\n    predefined_acl = \"\"\n\n    # role_entity - (Optional) List of role/entity pairs in the form `ROLE:entity`. See [GCS Object ACL documentation](https://cloud.google.com/storage/docs/json_api/v1/objectAccessControls) for more details. Must be set if `predefined_acl` is not.\n    role_entity = \"\"\n\n    # Exported Attributes\n}",
        "description": "Creates a new object ACL in Google cloud storage service (GCS). For more information see \n[the official documentation](https://cloud.google.com/storage/docs/access-control/lists) \nand \n[API](https://cloud.google.com/storage/docs/json_api/v1/objectAccessControls).",
        "prefix": "google-storage-object-acl"
    }
}